{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Men1oM4eRfAn"
   },
   "source": [
    "## Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGdtNx2iqNc-"
   },
   "source": [
    "#### Settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J75iPCI_qQkL"
   },
   "outputs": [],
   "source": [
    "start_over = False                                   # True will overwrite saved models with new models / False to Lock settings here.\n",
    "amount_of_symbols_per_action_sample = 3              # Symbols to propose per coin.\n",
    "# 3^\n",
    "aggregate_loss_history_epochs = 200                  # Calculate aggregated loss based on last X epochs\n",
    "minimum_prediction_prob_trade = 0.5      # Minimum 50% prediciton probability before taking action\n",
    "trade_when_below_loss = 0.5\n",
    "binary_target_minimum_increase_min = 0.001  #                 Minimum 0.1 % increase.\n",
    "seconds_inbetween = 12                        # Seconds between handling training data.\n",
    "# 9^, 9\n",
    "seconds_inbetween_pibeline = 3               # Seconds between cycling the pibeline.\n",
    "\n",
    "pred_epoch = 20                              # =  4.5  min    | Predict in how many epochs.\n",
    "# 30^, 10\n",
    "interval_columns = 120                       # = 22.5  min    | Amount of epochs in history per sample.\n",
    "# 150^, 50\n",
    "\n",
    "\n",
    "is_google_colab, is_google_cloud = False, True\n",
    "datasets_dir = 'datasets12'\n",
    "\n",
    "\n",
    "real_wallet_dont_use_euro = 20\n",
    "do_real_money_trade = True                       # prod: True\n",
    "do_training = True                               # prod: True\n",
    "do_gather_dataset = False                        # prod: False\n",
    "do_plots = True\n",
    "model_name_for_trading = 'NNAction'\n",
    "use_models = {\n",
    "    'NN': 1, # Neural Network\n",
    "    'CatBoost': 0,\n",
    "}\n",
    "\n",
    "\n",
    "nn_epochs = 5  # Dynamic\n",
    "nn_learning_rate = 0.000003\n",
    "\n",
    "catboost_iterations = 7\n",
    "catboost_depth = 10\n",
    "catboost_learning_rate = 0.10\n",
    "catboost_one_hot_max_size = 0\n",
    "catboost_ctr_target_border_count = 50\n",
    "catboost_model_size_reg = 0\n",
    "catboost_max_ctr_complexity = 0\n",
    "catboost_l2_leaf_reg = None\n",
    "catboost_min_data_in_leaf = None\n",
    "catboost_random_strength = None\n",
    "catboost_bootstrap_type = 'Bernoulli'\n",
    "catboost_subsample = 0.5\n",
    "catboost_bagging_temperature = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1rbiuNnTOAt"
   },
   "source": [
    "### load_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqr5zV0_TOyj"
   },
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    global models\n",
    "\n",
    "    if not exists(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    if not exists(root_dir + '/' + datasets_dir):\n",
    "        os.mkdir(root_dir + '/' + datasets_dir)\n",
    "\n",
    "    if use_models[\"CatBoost\"] == 1:\n",
    "        if not exists(root_dir + '/catboost'):\n",
    "            os.mkdir(root_dir + '/catboost')\n",
    "\n",
    "        for filename in os.listdir(root_dir + '/catboost/'):\n",
    "            if 'ipynb_checkpoints' in filename:\n",
    "                continue\n",
    "            models[filename] = joblib.load(root_dir + '/catboost/' + filename)\n",
    "\n",
    "    if use_models[\"NN\"] == 1:\n",
    "        if not exists(root_dir + '/nn'):\n",
    "            os.mkdir(root_dir + '/nn')\n",
    "            \n",
    "        for filename in os.listdir(root_dir + '/nn/'):\n",
    "            if 'ipynb_checkpoints' in filename:\n",
    "                continue\n",
    "            models[filename] = tf.keras.models.load_model(root_dir + '/nn/' + filename)\n",
    "\n",
    "\n",
    "    models = sorted(models.items(), key=lambda x: x[0], reverse=False)\n",
    "    models = {k: v for k, v in models}\n",
    "\n",
    "    for model_name, _ in models.items():\n",
    "        print(model_name + ' loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getInitiateFeatures():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInitiateFeatures():\n",
    "    all_inputs, all_inputs_encoded = [], []\n",
    "\n",
    "    # vocab = ['BIGGEST_DOWN', 'BIGGER_DOWN', 'BIG_DOWN', 'HALF_DOWN', 'DOWNER', 'DOWN_DOWN', 'DOWN', 'NULL', 'NEUTRAL', 'UP', 'UP_UP', 'HALF_UP', 'BIG_UP', 'BIGGER_UP', 'BIGGEST_UP']\n",
    "    # normalizer_direction = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "    normalizer_coin = tf.keras.layers.StringLookup(vocabulary=list(avaiable_coins.keys()), output_mode='one_hot')\n",
    "    normalizer_symbol = tf.keras.layers.StringLookup(vocabulary=avaiable_symbols_list, output_mode='one_hot')\n",
    "    normalizer_numeric = tf.keras.layers.Normalization(input_shape=[1,], axis=None)\n",
    "    normalizer_numeric.adapt([-1, 0, 1])                   # TODO: Optimize\n",
    "\n",
    "    for feature in features_list:        \n",
    "        dtype, normalizer = None, None\n",
    "\n",
    "        # if 'direction_' in feature:\n",
    "        #     dtype, normalizer = \"string\", normalizer_direction\n",
    "        if 'symbol' in feature:\n",
    "            dtype, normalizer = \"string\", normalizer_symbol\n",
    "        elif 'coin' in feature:\n",
    "            dtype, normalizer = \"string\", normalizer_coin\n",
    "        else:\n",
    "            dtype, normalizer = \"float32\", normalizer_numeric\n",
    "        \n",
    "        column = keras.Input(shape=(1,), name = feature, dtype=dtype)\n",
    "        all_inputs.append(column)\n",
    "        all_inputs_encoded.append(normalizer(column))\n",
    "    \n",
    "    return all_inputs, all_inputs_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOlkyfhOWYPz"
   },
   "source": [
    "### create_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkttSkCNWZ2z"
   },
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    global did_fit, do_predictions, losses_agregated, losses_agregated_positives\n",
    "\n",
    "    if len(models.keys()) == 0 or start_over:\n",
    "        if use_models[\"NN\"] == 1:\n",
    "            model_name, model = create_model_nn('NNAction')\n",
    "            models[model_name] = model\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "            \n",
    "            # model.summary()\n",
    "            keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "            print(model_name + ' model created!')\n",
    "\n",
    "        if use_models[\"CatBoost\"] == 1:\n",
    "            model_name, model = create_model_catboost('CatBoostAction')\n",
    "            models[model_name] = model\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "            print(model_name + ' model created!')\n",
    "\n",
    "        did_fit = False\n",
    "        do_predictions = False\n",
    "    else:\n",
    "        for model_name in models.keys():\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "\n",
    "\n",
    "def create_model_nn(name):\n",
    "    all_inputs, all_inputs_encoded = getInitiateFeatures()\n",
    "    \n",
    "    # model = Sequential()\n",
    "    # model.add(Input(input_shape = (1, amount_of_symbols_per_action_sample, all_features.shape[1])))\n",
    "    # model.add(Activation('relu'))\n",
    "    # model.add(Dense(units = 32))\n",
    "    # model.add(Dropout(0.2))\n",
    "    # model.add(Dense(units = 10))\n",
    "    # model.add(Dropout(0.1))\n",
    "    # model.add(Activation('softmax'))\n",
    "    # model.add(Dense(units = amount_of_symbols_per_action_sample + 1))\n",
    "    \n",
    "    x = layers.concatenate(all_inputs_encoded)\n",
    "    x = layers.Dense(1024, activation = \"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(1024)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    # x = layers.LSTM(64, activation = \"relu\", input_shape = (1, all_features.shape[1]), return_sequences = True)(all_features)\n",
    "\n",
    "    output = layers.Dense(1, activation = 'sigmoid')(x) # softmax\n",
    "\n",
    "    # output = tf.keras.layers.CategoryEncoding(num_tokens=amount_of_symbols_per_action_sample + 1, output_mode=\"multi_hot\")(x)\n",
    "    model = keras.Model(all_inputs, output, name=name)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            learning_rate = nn_learning_rate\n",
    "        ),\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(), # SparseCategoricalCrossentropy\n",
    "    )\n",
    "    \n",
    "    return name, model\n",
    "\n",
    "def create_model_catboost(name):\n",
    "    param = {\n",
    "        \"iterations\": catboost_iterations,\n",
    "        \"depth\": catboost_depth,\n",
    "        'learning_rate': catboost_learning_rate,\n",
    "        \"one_hot_max_size\": catboost_one_hot_max_size,\n",
    "        \"ctr_target_border_count\": catboost_ctr_target_border_count,\n",
    "        \"model_size_reg\": catboost_model_size_reg,\n",
    "        \"max_ctr_complexity\": catboost_max_ctr_complexity,\n",
    "        'l2_leaf_reg': catboost_l2_leaf_reg,\n",
    "        'min_data_in_leaf': catboost_min_data_in_leaf,\n",
    "        'random_strength': catboost_random_strength,\n",
    "        \"bootstrap_type\": catboost_bootstrap_type,\n",
    "\n",
    "        \"objective\": \"MultiClass\",\n",
    "        \"allow_const_label\": True,\n",
    "        \"task_type\": \"GPU\", \n",
    "        \"has_time\": True, \n",
    "        \"class_names\": possible_labels,\n",
    "        \"random_state\": 420,\n",
    "        \"allow_writing_files\": False,\n",
    "        \"boosting_type\": \"Plain\",\n",
    "    }\n",
    "    if catboost_bootstrap_type == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = catboost_bagging_temperature\n",
    "    elif catboost_bootstrap_type == \"Bernoulli\":\n",
    "        param[\"subsample\"] = catboost_subsample\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "\n",
    "    return name, model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGyza51MbQ8i",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### populate_coins_to_pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMaypnE0AUsi"
   },
   "outputs": [],
   "source": [
    "def validateActiveTickerSymbol(ticker):\n",
    "    if float(ticker['lastPrice']) < 0.0000001 or float(ticker['bidPrice']) < 0.0000001 or float(ticker['askPrice']) < 0.0000001:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def populate_coins_to_pairs():\n",
    "    global avaiable_coins, avaiable_symbols_list\n",
    "    avaiable_coins = {}\n",
    "    avaiable_symbols_list = []\n",
    "\n",
    "    balances = binance.get_account()['balances']\n",
    "    tickers = binance.get_ticker() # All symbol info\n",
    "\n",
    "\n",
    "    for balance in balances:\n",
    "        coin = balance['asset']\n",
    "        avaiable_coins[coin] = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if not validateActiveTickerSymbol(ticker):\n",
    "            continue\n",
    "        symbol = ticker['symbol']\n",
    "\n",
    "        found = False\n",
    "        for balance in balances:\n",
    "            coin = balance['asset']\n",
    "            if isCoinPairMatching(coin, symbol):\n",
    "              avaiable_coins[coin].append(symbol)\n",
    "              found = True\n",
    "        if found:\n",
    "            avaiable_symbols_list.append(symbol)\n",
    "\n",
    "def isCoinPairMatching(coin, symbol):\n",
    "    if coin not in symbol:\n",
    "        return False\n",
    "    \n",
    "    symbols = [\"BTCUP\", \"BTCDOWN\", \"ADAUP\", \"ADADOWN\", \"ETHUP\", \"ETHDOWN\", \"DOTUP\", \"DOTDOWN\", \"TRXUP\", \"TRXDOWN\", \"LINKUP\", \"LINKDOWN\", \\\n",
    "                \"BNBUP\", \"BNBDOWN\", \"CRH\"]\n",
    "    if any(x in symbol for x in symbols):\n",
    "        return False\n",
    "\n",
    "    if coin == 'AMB':\n",
    "        similars = [\"CREAMBUSD\", \"BEAM\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False \n",
    "    elif coin == 'AUD':\n",
    "        similars = [\"AUDIO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TRU':\n",
    "        similars = [\"ASTRUSDT\", \"USDTRUB\", \"DOT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TUSD':\n",
    "        similars = [\"TUSDT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GAL':\n",
    "        similars = [\"GALA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'BTC':\n",
    "        similars = [\"BTCST\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'OG':\n",
    "        similars = [\"DOGE\", \"OGN\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'COS':\n",
    "        similars = [\"COCOS\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'RUB':\n",
    "        similars = [\"TRUBTC\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'SHIB':\n",
    "        similars = [\"SUSHIBTC\", \"SUSHIBUSD\", \"SUSHIBNB\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'FET':\n",
    "        similars = [\"ELFETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'YFI':\n",
    "        similars = [\"YFII\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TRB':\n",
    "        similars = [\"ASTRBTC\", \"ASTRBUSD\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'BAR':\n",
    "        similars = [\"HBAR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'SC':\n",
    "        similars = [\"SCRT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'REP':\n",
    "        similars = [\"DREP\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GO':\n",
    "        similars = [\"AERGO\", \"ALGO\", \"DEGO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AST':\n",
    "        similars = [\"ASTR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AST':\n",
    "        similars = [\"CRVETH\", \"SSVETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ONE':\n",
    "        similars = [\"AIONETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GLM':\n",
    "        similars = [\"GLMR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'DAR':\n",
    "        similars = [\"ADARUB\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'VET':\n",
    "        similars = [\"CRVETH\", \"SSVETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OXT':\n",
    "        similars = [\"MBOXTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'ACA':\n",
    "        similars = [\"ALPACA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ONT':\n",
    "        similars = [\"FRONT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TCT':\n",
    "        similars = [\"BTCTUSD\", \"BTTCTRY\", \"BTCTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'AMP':\n",
    "        similars = [\"RAMP\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'WBTC':\n",
    "        similars = [\"FLOWBTC\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'LPT':\n",
    "        similars = [\"SLPTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'PHA':\n",
    "        similars = [\"ALPHA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AVA':\n",
    "        similars = [\"KAVA\", \"AVAX\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'MOB':\n",
    "        similars = [\"TOMO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'ORN':\n",
    "        similars = [\"TORN\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OM':\n",
    "        similars = [\"OMG\", \"ATOM\", \"COMP\", \"LOOM\", \"TOMO\", \"PROM\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'AR':\n",
    "        similars = [\"ARDR\", \"ARK\", \"ARPA\", \"BAR\", \"FARM\", \"HARD\", \"HBAR\", \"NEAR\", \"RARE\", \"DAR\", \"SPARTA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ATA':\n",
    "        similars = [\"DATA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ANT':\n",
    "        similars = [\"SANTOS\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'WIN':\n",
    "        similars = [\"WING\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'BUSD':\n",
    "        similars = [\"BNBUSDC\", \"TRBUSDT\", \"MOBUSDT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OP':\n",
    "        similars = [\"PEOPLE\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'FOR':\n",
    "        similars = [\"FORTH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'CKB':\n",
    "        similars = [\"DOCK\", \"QUICK\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin in ['BETH', 'BDOT', 'T']:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8t4j-VCVPv_",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### initBinanceInfo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwLwVhYLVRg9"
   },
   "outputs": [],
   "source": [
    "def initBinanceInfo():\n",
    "    global binance_symbols\n",
    "\n",
    "    get_exchange_info = binance.get_exchange_info()\n",
    "    for symbol in get_exchange_info['symbols']:\n",
    "        if symbol['symbol'] in avaiable_symbols_list:\n",
    "            stepSize = 0\n",
    "            stepSizeInteger = 0\n",
    "            tickSize = 0\n",
    "            minNotional = 0\n",
    "            for filter in symbol['filters']:\n",
    "                if filter['filterType'] == 'LOT_SIZE':\n",
    "                    stepSize = float(filter['stepSize'])\n",
    "                    if filter['stepSize'] == '0.10000000':\n",
    "                        stepSizeInteger = 1\n",
    "                    elif filter['stepSize'] == '0.01000000':\n",
    "                        stepSizeInteger = 2\n",
    "                    elif filter['stepSize'] == '0.00100000':\n",
    "                        stepSizeInteger = 3\n",
    "                    elif filter['stepSize'] == '0.00010000':\n",
    "                        stepSizeInteger = 4\n",
    "                    elif filter['stepSize'] == '0.00001000':\n",
    "                        stepSizeInteger = 5\n",
    "                    elif filter['stepSize'] == '0.00000100':\n",
    "                        stepSizeInteger = 6\n",
    "                    elif filter['stepSize'] == '0.00000010':\n",
    "                        stepSizeInteger = 7\n",
    "                    elif filter['stepSize'] == '0.00000001':\n",
    "                        stepSizeInteger = 8\n",
    "                elif filter['filterType'] == 'PRICE_FILTER':\n",
    "                    if filter['tickSize'] == '0.10000000':\n",
    "                        tickSize = 1\n",
    "                    elif filter['tickSize'] == '0.01000000':\n",
    "                        tickSize = 2\n",
    "                    elif filter['tickSize'] == '0.00100000':\n",
    "                        tickSize = 3\n",
    "                    elif filter['tickSize'] == '0.00010000':\n",
    "                        tickSize = 4\n",
    "                    elif filter['tickSize'] == '0.00001000':\n",
    "                        tickSize = 5\n",
    "                    elif filter['tickSize'] == '0.00000100':\n",
    "                        tickSize = 6\n",
    "                    elif filter['tickSize'] == '0.00000010':\n",
    "                        tickSize = 7\n",
    "                    elif filter['tickSize'] == '0.00000001':\n",
    "                        tickSize = 8\n",
    "                elif filter['filterType'] == 'MIN_NOTIONAL':\n",
    "                    minNotional = float(filter['minNotional'])\n",
    "\n",
    "            binance_symbols[symbol['symbol']] = {\n",
    "                'stepSize': stepSize,\n",
    "                'stepSizeInteger': stepSizeInteger,\n",
    "                'tickSize': tickSize,\n",
    "                'minNotional': minNotional,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZMtPNjERlzE"
   },
   "source": [
    "### init_meta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J-bgr9_RQOz",
    "outputId": "3bbd267c-d865-4946-e2b2-59e3eeb38f20"
   },
   "outputs": [],
   "source": [
    "root_dir = 'models' \n",
    "categorial_features = ['symbol', 'coin']    # 'direction_', \n",
    "\n",
    "if is_google_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    root_dir = 'drive/MyDrive/tradebot'\n",
    "\n",
    "if is_google_colab or is_google_cloud:\n",
    "    !pip install catboost\n",
    "    !pip install python-binance\n",
    "    !pip install tensorflow\n",
    "\n",
    "import os, psutil\n",
    "from os.path import exists\n",
    "\n",
    "from catboost import *\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from binance import Client\n",
    "from binance.enums import *\n",
    "\n",
    "import sched, time\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from threading import Thread, Lock\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = {}\n",
    "categorial_features_indices = None\n",
    "holding_coins = None\n",
    "features_list = None\n",
    "features_dtypes = None\n",
    "avaiable_coins = None\n",
    "avaiable_symbols_list = None\n",
    "\n",
    "possible_labels = ['NONE']\n",
    "for i in range(0, amount_of_symbols_per_action_sample):\n",
    "    possible_labels.append(str(i))\n",
    "\n",
    "binance_api_key = 'AoVFfn3JvetSRHpffstx9tg0Zlmzc6WHeAdVjVUnLfbzOTslBanPUMFa7bP4CqtU'\n",
    "binance_api_secret = 'zNGuMcE2UcycFQeVhTi5o9psM6GjZHvg7gEcTu1f8pazQg42EAMgvma5G583wv4G'\n",
    "binance = Client(binance_api_key, binance_api_secret)\n",
    "\n",
    "##### :\n",
    "epoch, part_epoch, total_part_epochs = 1, 1, 0\n",
    "memory_data = []\n",
    "memory_symbols = {}\n",
    "predictions_saved = []\n",
    "deleted_symbol_data = 0\n",
    "print_trained_string = '---'\n",
    "loss_string = '-'\n",
    "model_training_lock = None\n",
    "model_df_buffer_lock = None\n",
    "handleTickers_lock = None\n",
    "binance_symbols = {} #\n",
    "dont_update_holding_coins = []\n",
    "dont_update_holding_coins_buffer = {}\n",
    "cancel_orders = False\n",
    "temp_tickers = {}\n",
    "do_predictions = True\n",
    "saved_df_buffer = pd.DataFrame()\n",
    "saved_y_buffer = []\n",
    "init_time = None\n",
    "did_fit = True\n",
    "losses_agregated = {}\n",
    "losses_agregated_positives = {}\n",
    "median_loss = 1\n",
    "median_loss_positives = 1\n",
    "time_train = seconds_inbetween - 2\n",
    "time_big = seconds_inbetween - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NN:\n",
    "\n",
    "categorical_encoder = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (categorical_encoder, make_column_selector(dtype_include=object)),\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XiN8nxrY1HI",
    "outputId": "d04b8f43-43d0-40dd-cfb1-614f5cc0813e"
   },
   "outputs": [],
   "source": [
    "populate_coins_to_pairs()\n",
    "initBinanceInfo()\n",
    "load_models()\n",
    "# create_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AzHvj-pYFMJ"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjsTJIZxAlzA"
   },
   "source": [
    "### Init:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuFLPr_78efB"
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    global holding_coins, do_predictions, model_training_lock, model_df_buffer_lock, \\\n",
    "    epoch, part_epoch, total_part_epochs, memory_data, memory_symbols, predictions_saved, \\\n",
    "    deleted_symbol_data, print_trained_string, loss_string, saved_y_buffer, \\\n",
    "    dont_update_holding_coins, dont_update_holding_coins_buffer, \\\n",
    "    cancel_orders, temp_tickers, saved_df_buffer, \\\n",
    "    handleTickers_lock, init_time\n",
    "\n",
    "    initBinanceInfo()\n",
    "\n",
    "    epoch, part_epoch, total_part_epochs = 1, 1, 0\n",
    "    memory_data = []\n",
    "    memory_symbols = {}\n",
    "    predictions_saved = []\n",
    "    deleted_symbol_data = 0\n",
    "    print_trained_string = '---'\n",
    "    loss_string = '-'\n",
    "    model_training_lock = None\n",
    "    model_df_buffer_lock = None\n",
    "    handleTickers_lock = None\n",
    "    dont_update_holding_coins = []\n",
    "    dont_update_holding_coins_buffer = {}\n",
    "    cancel_orders = False\n",
    "    temp_tickers = {}\n",
    "    do_predictions = True\n",
    "    saved_df_buffer = pd.DataFrame()\n",
    "    saved_y_buffer = []\n",
    "    init_time = time.time()\n",
    "\n",
    "    holding_coins = {\n",
    "        'DEFAULT': {\n",
    "            'balance': 0,\n",
    "            'balance_eur': 1,\n",
    "            'price': 0,\n",
    "            'counting_epochs': 0,\n",
    "            'symbol': '',\n",
    "            'date': time.strftime(\"%H:%M:%S\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_training_lock = Lock()\n",
    "    model_df_buffer_lock = Lock()\n",
    "    handleTickers_lock = Lock()\n",
    "\n",
    "    print(\"\"\"\\\n",
    "                        ._ o o\n",
    "                        \\_`-)|_\n",
    "                      ,\"\"       \\ \n",
    "                    ,\"  ## |   = ಠ. \n",
    "                  ,\" ##   ,-\\__    `.\n",
    "                ,\"       /     `--._;)\n",
    "              ,\"     ## /\n",
    "            ,\"   ##    /\n",
    "███████╗████████╗ ██████╗ ███╗   ██╗██╗  ██╗██████╗  ██████╗ ████████╗\n",
    "██╔════╝╚══██╔══╝██╔═══██╗████╗  ██║██║ ██╔╝██╔══██╗██╔═══██╗╚══██╔══╝\n",
    "███████╗   ██║   ██║   ██║██╔██╗ ██║█████╔╝ ██████╔╝██║   ██║   ██║   \n",
    "╚════██║   ██║   ██║   ██║██║╚██╗██║██╔═██╗ ██╔══██╗██║   ██║   ██║   \n",
    "███████║   ██║   ╚██████╔╝██║ ╚████║██║  ██╗██████╔╝╚██████╔╝   ██║   \n",
    "╚══════╝   ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚═╝  ╚═╝╚═════╝  ╚═════╝    ╚═╝   v0.3\n",
    "                                                                      \n",
    "                    \"\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwAVJm55CSR5"
   },
   "source": [
    "### Runner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uZ0wly0CZA9"
   },
   "outputs": [],
   "source": [
    "def runner():\n",
    "    global schedule, epoch, part_epoch, total_part_epochs, init_time\n",
    "    time_now = time.time()\n",
    "    \n",
    "    getTickers(part_epoch)\n",
    "\n",
    "    if part_epoch == (seconds_inbetween / seconds_inbetween_pibeline) - 1:\n",
    "        thread = Thread(target = updateBinanceBalances)\n",
    "        thread.start()\n",
    "\n",
    "    if seconds_inbetween / seconds_inbetween_pibeline <= part_epoch:\n",
    "        processTickers()\n",
    "        thread = Thread(target = handleTickers, args = (time_now, epoch, memory_symbols,))\n",
    "        thread.start()\n",
    "        epoch += 1\n",
    "        part_epoch = 0\n",
    "    part_epoch += 1\n",
    "    total_part_epochs += 1\n",
    "    # 459: 6 sec break..\n",
    "    if total_part_epochs == 460:\n",
    "        sleepy = (seconds_inbetween_pibeline * total_part_epochs) - (time.time() - init_time) - seconds_inbetween_pibeline + 2.5\n",
    "        if sleepy < 0:\n",
    "          sleepy = 0\n",
    "        print('sleepy', sleepy)\n",
    "        time.sleep(sleepy)\n",
    "        init_time = time.time()\n",
    "        total_part_epochs = 0\n",
    "        return\n",
    "\n",
    "    schedule.enter((seconds_inbetween_pibeline * total_part_epochs) - (time.time() - init_time) - seconds_inbetween_pibeline, 1, runner)\n",
    "    schedule.run()\n",
    "\n",
    "def getTickers(part_epoch):\n",
    "  global temp_tickers\n",
    "\n",
    "  try:\n",
    "      tickers = binance.get_ticker() # All symbol info\n",
    "  except:\n",
    "      print('binance.get_ticker() FAILED 1/2.')\n",
    "      try:\n",
    "          tickers = binance.get_ticker() # All symbol info\n",
    "      except:\n",
    "          print('binance.get_ticker() FAILED 2/2.')\n",
    "          return\n",
    "  \n",
    "  if part_epoch == 1:\n",
    "      for symbol in tickers:\n",
    "          if symbol['symbol'] not in avaiable_symbols_list:\n",
    "              continue\n",
    "          temp_tickers[symbol['symbol']] = {\n",
    "              'symbol': symbol['symbol'],\n",
    "              'bidPrice_low': float(symbol['bidPrice']),\n",
    "              'bidPrice_high': float(symbol['bidPrice']),\n",
    "              'askPrice_low': float(symbol['askPrice']),\n",
    "              'askPrice_high': float(symbol['askPrice']),\n",
    "              'volume': float(symbol['volume']),\n",
    "              'quoteVolume': float(symbol['quoteVolume']),\n",
    "              'tradeCount': int(symbol['count']),\n",
    "              'lastPrice': float(symbol['lastPrice']),\n",
    "          }\n",
    "        \n",
    "  else:\n",
    "      for symbol in tickers:\n",
    "          if symbol['symbol'] not in avaiable_symbols_list:\n",
    "              continue\n",
    "        \n",
    "          new_bidPrice = float(symbol['bidPrice'])\n",
    "          new_askPrice = float(symbol['askPrice'])\n",
    "          \n",
    "          temp_tickers[symbol['symbol']] = {\n",
    "              'symbol': symbol['symbol'],\n",
    "              'bidPrice_low': new_bidPrice if temp_tickers[symbol['symbol']]['bidPrice_low'] > new_bidPrice else temp_tickers[symbol['symbol']]['bidPrice_low'],\n",
    "              'bidPrice_high': new_bidPrice if temp_tickers[symbol['symbol']]['bidPrice_high'] < new_bidPrice else temp_tickers[symbol['symbol']]['bidPrice_high'],\n",
    "              'askPrice_low': new_askPrice if temp_tickers[symbol['symbol']]['askPrice_low'] > new_askPrice else temp_tickers[symbol['symbol']]['askPrice_low'],\n",
    "              'askPrice_high': new_askPrice if temp_tickers[symbol['symbol']]['askPrice_high'] < new_askPrice else temp_tickers[symbol['symbol']]['askPrice_high'],\n",
    "              'volume': float(symbol['volume']),\n",
    "              'quoteVolume': float(symbol['quoteVolume']),\n",
    "              'tradeCount': int(symbol['count']),\n",
    "              'lastPrice': float(symbol['lastPrice']),\n",
    "          }\n",
    "        \n",
    "          # if new_bidPrice == 0 or new_askPrice == 0:\n",
    "          #     print(symbol)\n",
    "          #     del temp_tickers[symbol['symbol']]\n",
    "          #     del memory_symbols[symbol['symbol']]\n",
    "          #     avaiable_symbols_list.remove(symbol['symbol'])\n",
    "          #     print(symbol['symbol'], 'removed.', symbol['bidPrice'], symbol['askPrice'])\n",
    "\n",
    "def processTickers():\n",
    "    global memory_symbols\n",
    "    for coin in temp_tickers.values():\n",
    "        if coin['symbol'] not in memory_symbols:\n",
    "            memory_symbols[coin['symbol']] = {\n",
    "                'bidPrice_low': [],\n",
    "                'bidPrice_high': [],\n",
    "                'askPrice_low': [],\n",
    "                'askPrice_high': [],\n",
    "                'volume': [],\n",
    "                'quoteVolume': [],\n",
    "                'tradeCount': [],\n",
    "                'lastPrice': [],\n",
    "            }\n",
    "        memory_symbols[coin['symbol']]['bidPrice_low'].append(coin['bidPrice_low'])\n",
    "        memory_symbols[coin['symbol']]['bidPrice_high'].append(coin['bidPrice_high'])\n",
    "        memory_symbols[coin['symbol']]['askPrice_low'].append(coin['askPrice_low'])\n",
    "        memory_symbols[coin['symbol']]['askPrice_high'].append(coin['askPrice_high'])\n",
    "        memory_symbols[coin['symbol']]['volume'].append(coin['volume'])\n",
    "        memory_symbols[coin['symbol']]['quoteVolume'].append(coin['quoteVolume'])\n",
    "        memory_symbols[coin['symbol']]['tradeCount'].append(coin['tradeCount'])\n",
    "        memory_symbols[coin['symbol']]['lastPrice'].append(coin['lastPrice'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1uHH3AlgtLF"
   },
   "source": [
    "### MAIN Thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JA60IEuagyml"
   },
   "outputs": [],
   "source": [
    "def handleTickers(time_now_big, epoch, memory_symbols):\n",
    "    global memory_data, deleted_symbol_data, print_trained_string, do_predictions, do_predictions, \\\n",
    "    predictions_saved, handleTickers_Lock, categorial_features_indices, features_dtypes, features_list, \\\n",
    "    time_big\n",
    "\n",
    "    memory_data_symbol = None\n",
    "    predictions_byModel = [\n",
    "        {},\n",
    "        '0',\n",
    "    ]\n",
    "    \n",
    "    handleTickers_lock.acquire() #\n",
    "    print('--------  Epoch: ', epoch, '  [' + str(time.strftime(\"%H:%M:%S\")) + ']')\n",
    "    print()\n",
    "\n",
    "    # Proccess coin data\n",
    "    proccessTickers_time = ''\n",
    "    if epoch > 1:\n",
    "        # Get list of symbols to check:\n",
    "        use_symbols = []\n",
    "        for coin in holding_coins.keys():\n",
    "            use_symbols += avaiable_coins[coin]\n",
    "            \n",
    "        time_big_itcp = time.time() - time_now_big\n",
    "        time_now = time.time()\n",
    "        memory_data_symbol = proccessTickers(epoch, memory_symbols, True, use_symbols)\n",
    "        proccessTickers_time = str(round(time_big_itcp, 2)) + ' + ' + str(round(time.time() - time_now, 2))\n",
    "\n",
    "    if epoch > pred_epoch:\n",
    "        # Process Action Data\n",
    "        time_now = time.time()\n",
    "        saved, coins = processActionData(memory_data_symbol, True)\n",
    "        proccessTickers_time += ' + ' + str(round(time.time() - time_now, 2))\n",
    "\n",
    "        ## Init Set features_dtypes & categorial_features_indices ##\n",
    "        if epoch == pred_epoch + 1:\n",
    "            features_list = list(saved[0].keys())\n",
    "            features_dtypes = {}\n",
    "            categorial_features_indices = []\n",
    "            i = 0\n",
    "            for feature in features_list:\n",
    "                if any(x in feature for x in categorial_features):\n",
    "                    categorial_features_indices.append(i)\n",
    "                i += 1\n",
    "                if 'symbol' in feature or 'coin' in feature:    #  or 'direction_' in feature\n",
    "                    features_dtypes[feature] = 'string'\n",
    "                else:\n",
    "                    features_dtypes[feature] = 'float32'\n",
    "        ####\n",
    "\n",
    "        if do_predictions:\n",
    "            # Do Predictions:\n",
    "            predictions_byModel = proccessPredictions(saved, coins)\n",
    "\n",
    "\n",
    "    # Balances and euro:\n",
    "    print_eur_string = convert_wallet_to_euro(holding_coins, memory_symbols, epoch)\n",
    "    print('[ ' + print_eur_string + ' ]   _ Balances:')\n",
    "    for coin, inner in holding_coins.items():\n",
    "        print(coin, str(round(inner['balance'], 4)), '', str(round(inner['balance_eur'], 2)) + ' €', '   |  Price: ' + str(inner['price']) + ' ' + inner['symbol'] + '  | Epoch: ' + str(inner['counting_epochs']) + '       [' + inner['date'] + ']')\n",
    "    print()\n",
    "    \n",
    "    # Trade coins:\n",
    "    if do_predictions and epoch > interval_columns + pred_epoch + 20:\n",
    "        processTrading(predictions_byModel[0], epoch, memory_symbols)\n",
    "    #\n",
    "\n",
    "    time_now_12 = time.time()\n",
    "\n",
    "    # Now build data for the rest of the coins and symbols:\n",
    "    if epoch > 1:\n",
    "        memory_data_symbol = proccessTickers(epoch, memory_symbols, False, None)\n",
    "\n",
    "        # Start updating symbol priority list into avaiable_coins:\n",
    "        thread = Thread(target = updateSymbolPriorityList, args = (memory_data_symbol,))\n",
    "        thread.start()\n",
    "\n",
    "    if epoch > pred_epoch:\n",
    "        memory_data.append(processActionData(memory_data_symbol, False)[0])\n",
    "    #\n",
    "    \n",
    "    if epoch % pred_epoch == 0 and epoch > pred_epoch + interval_columns:\n",
    "        do_predictions = True\n",
    "        \n",
    "    if epoch > pred_epoch:\n",
    "        predictions_saved.append(predictions_byModel[0])\n",
    "\n",
    "        if epoch == pred_epoch + 1:\n",
    "            print('Attempting to create models now...')\n",
    "            thread = Thread(target = create_models)\n",
    "            thread.start()\n",
    "        else:\n",
    "            # Do Validation on Past predictions:\n",
    "            training_list, y_train, validated_list_targets = validatePredictions(epoch, memory_symbols)\n",
    "            if do_predictions and epoch > interval_columns:\n",
    "                validatePastPredictions(validated_list_targets)\n",
    "            \n",
    "        if epoch == pred_epoch + interval_columns - 5:\n",
    "            # Do warmup:\n",
    "            print('Attempting to do warmup now...')\n",
    "            thread = Thread(target = do_warmup, args = (training_list, y_train,))\n",
    "            thread.start()\n",
    "\n",
    "        elif epoch > pred_epoch + interval_columns:\n",
    "            # Do training:\n",
    "            thread = Thread(target = trainModels, args = (training_list, y_train,))\n",
    "            thread.start()\n",
    "\n",
    "            if do_plots and nn_epochs > 0 and epoch % 3 == 0:\n",
    "                time_now_13 = time.time()\n",
    "                processPlotting(coins)\n",
    "    \n",
    "    print('timeo:', round(time.time() - time_now_12, 2), '', 'processPlotting:', round(time.time() - time_now_13, 2))\n",
    "\n",
    "    # Cleanup:\n",
    "    if epoch > interval_columns:\n",
    "        for _, value in memory_symbols.items():\n",
    "            del value['bidPrice_high'][0]\n",
    "            del value['bidPrice_low'][0]\n",
    "            del value['askPrice_high'][0]\n",
    "            del value['askPrice_low'][0]\n",
    "            del value['volume'][0]\n",
    "            del value['quoteVolume'][0]\n",
    "            del value['tradeCount'][0]\n",
    "            del value['lastPrice'][0]\n",
    "        deleted_symbol_data += 1\n",
    "    if len(memory_data) == pred_epoch:\n",
    "        del memory_data[0]\n",
    "        del predictions_saved[0]\n",
    "    ##\n",
    "    time_big = round(time.time()-time_now_big, 2)\n",
    "    print('---------------- ', total_part_epochs, '[', time_big, 's ==', 't: ' + proccessTickers_time, '| p:', predictions_byModel[1], ']', \\\n",
    "          ' || ', print_trained_string, '|  Loss:', loss_string, ' |  RAM:', round(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2), 'mb')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    handleTickers_lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processPlotting():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPlotting(coins):\n",
    "    plt.figure(1)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 3)\n",
    "    found = False\n",
    "    \n",
    "    for model_name, losses_agregat in losses_agregated.items():\n",
    "        if len(losses_agregat) > 0:\n",
    "            found = True\n",
    "            plt.plot(losses_agregat, label=model_name + ' Loss', marker='.', linestyle='--', color='b')\n",
    "    for model_name, losses_agregat in losses_agregated_positives.items():\n",
    "        if len(losses_agregat) > 0:\n",
    "            found = True\n",
    "            plt.plot(losses_agregat, label=model_name + ' Positives', marker='.', linestyle='--', color='orange')\n",
    "    if found == False:\n",
    "        return\n",
    "\n",
    "    plt.axhline(y = 0.5, color = 'gray', linestyle = 'dotted')\n",
    "    plt.title(\"Losses last \" + str(aggregate_loss_history_epochs) + \" epochs for: \" + ' - '.join(coins))\n",
    "    plt.xlabel('Epoch', fontsize=10)\n",
    "    plt.ylabel('Loss', fontsize=10)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhk559ZXlIPx"
   },
   "source": [
    "### proccessTickers():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN5wC6Eni6s8"
   },
   "outputs": [],
   "source": [
    "def proccessTickers(epoch, memory_symbols, only_use_holding_symbols, use_symbols):\n",
    "    global highest, lowest\n",
    "\n",
    "    memory_data_symbol = {}\n",
    "\n",
    "    for symbol, inner in memory_symbols.items():\n",
    "        if only_use_holding_symbols and symbol not in use_symbols:\n",
    "            continue\n",
    "\n",
    "        dat = {\n",
    "              'symbol': symbol,                               # categorical\n",
    "              # 'weekday': str(currentime.weekday() + 1),     # categorical\n",
    "              # 'hour': str(currentime.hour + 1),             # categorical\n",
    "        }\n",
    "\n",
    "        temp_bidPrice_low = inner['bidPrice_low'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_bidPrice_high = inner['bidPrice_high'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_askPrice_low = inner['askPrice_low'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_askPrice_high = inner['askPrice_high'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_volume = inner['volume'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_volume == 0:\n",
    "            temp_volume = 0.0000001\n",
    "        temp_quoteVolume = inner['quoteVolume'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_quoteVolume == 0:\n",
    "            temp_quoteVolume = 0.0000001\n",
    "        temp_tradeCount = inner['tradeCount'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_tradeCount == 0:\n",
    "            temp_tradeCount = 0.0000001\n",
    "        temp_lastPrice = inner['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_lastPrice == 0:\n",
    "            temp_lastPrice = 0.0000001\n",
    "\n",
    "        seconds_ago = seconds_inbetween\n",
    "\n",
    "        for i in range(1, interval_columns + 1):\n",
    "            seconds_ago_string = str(seconds_ago)\n",
    "            if (epoch > i):\n",
    "                index = epoch - i - 1 - deleted_symbol_data\n",
    "                \n",
    "                bidPrice_low = inner['bidPrice_low'][index] # Reverse + Pick i element.\n",
    "                if bidPrice_low == 0:\n",
    "                    dat['bidPrice_low_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                else:\n",
    "                    dat['bidPrice_low_' + seconds_ago_string + '_secAgo'] = (temp_bidPrice_low - bidPrice_low) / bidPrice_low\n",
    "                    \n",
    "\n",
    "                bidPrice_high = inner['bidPrice_high'][index] # Reverse + Pick i element.\n",
    "                if bidPrice_high == 0:\n",
    "                    dat['bidPrice_high_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                else:\n",
    "                    dat['bidPrice_high_' + seconds_ago_string + '_secAgo'] = (temp_bidPrice_high - bidPrice_high) / bidPrice_high\n",
    "\n",
    "                askPrice_low = inner['askPrice_low'][index] # Reverse + Pick i element.\n",
    "                if askPrice_low == 0:\n",
    "                    dat['askPrice_low_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                else:\n",
    "                    dat['askPrice_low_' + seconds_ago_string + '_secAgo'] = (temp_askPrice_low - askPrice_low) / askPrice_low\n",
    "\n",
    "                askPrice_high = inner['askPrice_high'][index] # Reverse + Pick i element.\n",
    "                if askPrice_high == 0:\n",
    "                    dat['askPrice_high_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                else:\n",
    "                    dat['askPrice_high_' + seconds_ago_string + '_secAgo'] = (temp_askPrice_high - askPrice_high) / askPrice_high\n",
    "\n",
    "                volume = inner['volume'][index] # Reverse + Pick i element.\n",
    "                if volume == 0:\n",
    "                    volume = 0.0000001\n",
    "                dat['volume_' + seconds_ago_string + '_secAgo'] = (temp_volume - volume) / volume\n",
    "\n",
    "                quoteVolume = inner['quoteVolume'][index] # Reverse + Pick i element.\n",
    "                if quoteVolume == 0:\n",
    "                    quoteVolume = 0.0000001\n",
    "                dat['quoteVolume_' + seconds_ago_string + '_secAgo'] = (temp_quoteVolume - quoteVolume) / quoteVolume\n",
    "\n",
    "                tradeCount = inner['tradeCount'][index] # Reverse + Pick i element.\n",
    "                if tradeCount == 0:\n",
    "                    tradeCount = 0.0000001\n",
    "                dat['tradeCount_' + seconds_ago_string + '_secAgo'] = (temp_tradeCount - tradeCount) / tradeCount\n",
    "\n",
    "                lastPrice = inner['lastPrice'][index] # Reverse + Pick i element.\n",
    "                if lastPrice == 0:\n",
    "                    lastPrice = 0.0000001\n",
    "                dat['lastPrice_' + seconds_ago_string + '_secAgo'] = (temp_lastPrice - lastPrice) / lastPrice\n",
    "\n",
    "            else:\n",
    "                dat['bidPrice_low_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['bidPrice_high_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['askPrice_low_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['askPrice_high_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['volume_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['quoteVolume_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['tradeCount_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['lastPrice_' + seconds_ago_string + '_secAgo'] = 0\n",
    "\n",
    "            # direction = 'BIGGEST_DOWN'\n",
    "            # lastPrice = dat['lastPrice_' + seconds_ago_string + '_secAgo']\n",
    "            # if lastPrice > 3:\n",
    "            #   direction = 'BIGGEST_UP'\n",
    "            # elif lastPrice > 2:\n",
    "            #   direction = 'BIGGER_UP'\n",
    "            # elif lastPrice > 1:\n",
    "            #   direction = 'BIG_UP'\n",
    "            # elif lastPrice > 0.5:\n",
    "            #   direction = 'HALF_UP'\n",
    "            # elif lastPrice > binary_target_minimum_increase_min * 2:\n",
    "            #   direction = 'UP_UP'\n",
    "            # elif lastPrice > binary_target_minimum_increase_min:\n",
    "            #   direction = 'UP'\n",
    "            # elif lastPrice > 0:\n",
    "            #   direction = 'NEUTRAL'\n",
    "            # elif lastPrice == 0:\n",
    "            #   direction = 'NULL'\n",
    "            # elif lastPrice > -binary_target_minimum_increase_min:\n",
    "            #   direction = 'DOWN'\n",
    "            # elif lastPrice > -binary_target_minimum_increase_min * 2:\n",
    "            #   direction = 'DOWN_DOWN'\n",
    "            # elif lastPrice > -0.5:\n",
    "            #   direction = 'DOWNER'\n",
    "            # elif lastPrice > -1:\n",
    "            #   direction = 'HALF_DOWN'\n",
    "            # elif lastPrice > -2:\n",
    "            #   direction = 'BIG_DOWN'\n",
    "            # elif lastPrice > -3:\n",
    "            #   direction = 'BIGGER_DOWN'\n",
    "            # dat['direction_' + seconds_ago_string + '_secAgo'] = direction\n",
    "\n",
    "            seconds_ago += seconds_inbetween\n",
    "            \n",
    "\n",
    "        memory_data_symbol[symbol] = dat\n",
    "\n",
    "    return memory_data_symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HtKD9Wrmxi0"
   },
   "source": [
    "### processActionData():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flVCYZidm5aB"
   },
   "outputs": [],
   "source": [
    "def processActionData(memory_data_symbol, only_use_holding_symbols):\n",
    "    global holding_coins, memory_data, categorial_features_indices, features_list, saved_df_buffer\n",
    "\n",
    "    saved, coins = [], []\n",
    "\n",
    "    if only_use_holding_symbols:\n",
    "        for coin in holding_coins.keys():\n",
    "            i = 0\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                if i > amount_of_symbols_per_action_sample - 1:\n",
    "                    break\n",
    "                saved.append(getActionSampleRow(symbol, coin, memory_data_symbol))\n",
    "                i += 1\n",
    "\n",
    "            coins.append(coin)\n",
    "    else:\n",
    "        for coin in avaiable_coins.keys():\n",
    "            i = 0\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                if i > amount_of_symbols_per_action_sample - 1:\n",
    "                    break\n",
    "                saved.append(getActionSampleRow(symbol, coin, memory_data_symbol))\n",
    "                i += 1\n",
    "\n",
    "        coins.append(coin)\n",
    "\n",
    "    return saved, coins\n",
    "\n",
    "\n",
    "def getActionSampleRow(symbol, coin, memory_data_symbol):\n",
    "    data = {\n",
    "        'coin': coin\n",
    "    }\n",
    "\n",
    "    if symbol.startswith(coin):\n",
    "        for attr, value in memory_data_symbol[symbol].items():\n",
    "            if 'Price_' in attr or 'olume_' in attr or 'tradeCount_' in attr:\n",
    "                if value != 0:\n",
    "                    data[attr] = value * -1\n",
    "                else:\n",
    "                    data[attr] = value\n",
    "            # elif 'direction_' in attr:\n",
    "            #     data[str(i) + attr] = changeDirection(value)\n",
    "            else:\n",
    "                data[attr] = value\n",
    "    else:\n",
    "        for attr, value in memory_data_symbol[symbol].items():\n",
    "            data[attr] = value\n",
    "    \n",
    "\n",
    "    return data\n",
    "\n",
    "def changeDirection(value):\n",
    "    if value == 'BIGGEST_DOWN':\n",
    "        return 'BIGGEST_UP'\n",
    "    if value == 'BIGGER_DOWN':\n",
    "        return 'BIGGER_UP'\n",
    "    if value == 'BIG_DOWN':\n",
    "        return 'BIG_UP'\n",
    "    if value == 'HALF_DOWN':\n",
    "        return 'HALF_UP'\n",
    "    if value == 'DOWNER':\n",
    "        return 'UP_UP'\n",
    "    if value == 'DOWN_DOWN':\n",
    "        return 'UP_UP'\n",
    "    if value == 'DOWN':\n",
    "        return 'UP'\n",
    "    if value == 'NEUTRAL':\n",
    "        return 'DOWN'\n",
    "    if value == 'UP':\n",
    "        return 'DOWN'\n",
    "    if value == 'UP_UP':\n",
    "        return 'DOWN_DOWN'\n",
    "    if value == 'HALF_UP':\n",
    "        return 'HALF_DOWN'\n",
    "    if value == 'BIG_UP':\n",
    "        return 'BIG_DOWN'\n",
    "    if value == 'BIGGER_UP':\n",
    "        return 'BIGGER_DOWN'\n",
    "    if value == 'BIGGEST_UP':\n",
    "        return 'BIGGEST_DOWN'\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WPpdhuugYQd"
   },
   "source": [
    "### updateBinanceBalances + updateSymbolPriorityList:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXnUSgd2gUxg"
   },
   "outputs": [],
   "source": [
    "def updateBinanceBalances():\n",
    "    global holding_coins, dont_update_holding_coins, cancel_orders\n",
    "\n",
    "    if cancel_orders:\n",
    "        cancel_orders = False\n",
    "        orders = binance.get_open_orders()\n",
    "        for order in orders:\n",
    "            print('cancel_order:', binance.cancel_order(\n",
    "                symbol = order['symbol'],\n",
    "                orderId = order['orderId']))\n",
    "\n",
    "    balances = binance.get_account()['balances']\n",
    "\n",
    "    ### DEBUG:\n",
    "    balances.append(\n",
    "        {\n",
    "            \"asset\": \"BTC\",\n",
    "            \"free\": \"0.03\",\n",
    "    })\n",
    "    balances.append(\n",
    "        {\n",
    "            \"asset\": \"DOGE\",\n",
    "            \"free\": \"1000\",\n",
    "    })\n",
    "    balances.append(\n",
    "        {\n",
    "            \"asset\": \"EUR\",\n",
    "            \"free\": \"440\",\n",
    "    })\n",
    "\n",
    "    found_assets = []\n",
    "    for balance in balances:\n",
    "        balance_number = float(balance['free'])\n",
    "        if balance_number > 0.0001:\n",
    "            if balance['asset'] not in holding_coins.keys():\n",
    "                if 'DEFAULT' in holding_coins.keys():\n",
    "                    holding_coins[balance['asset']] = holding_coins['DEFAULT'].copy()\n",
    "                else:\n",
    "                    continue\n",
    "            if balance['asset'] == 'EUR':\n",
    "                balance_number -= real_wallet_dont_use_euro\n",
    "                if balance_number < 1:\n",
    "                    continue\n",
    "            if balance['asset'] == 'BNB':\n",
    "                balance_number -= 0.01  # 2.76eur 15.09.22\n",
    "            if balance_number < 0.0001:\n",
    "                continue\n",
    "            if balance['asset'] not in dont_update_holding_coins:\n",
    "                holding_coins[balance['asset']]['balance'] = balance_number\n",
    "            found_assets.append(balance['asset'])\n",
    "    for coin in list(holding_coins.keys()):\n",
    "        if coin not in found_assets or holding_coins[coin]['balance_eur'] < 1:\n",
    "            if coin in dont_update_holding_coins:\n",
    "                dont_update_holding_coins.remove(coin)\n",
    "                del dont_update_holding_coins_buffer[coin]\n",
    "            del holding_coins[coin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deEBL0RsYvti"
   },
   "outputs": [],
   "source": [
    "def updateSymbolPriorityList(memory_data_symbol):\n",
    "    global avaiable_coins\n",
    "\n",
    "    symbol_changes = {}\n",
    "    for symbol, details in memory_data_symbol.items():\n",
    "        symbol_changes[symbol] = getPositiveChange(details['bidPrice_high_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        symbol_changes[symbol] += getPositiveChange(details['askPrice_high_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        # symbol_changes[symbol] += getPositiveChange(details['volume_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        # symbol_changes[symbol] += getPositiveChange(details['quoteVolume_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        # symbol_changes[symbol] += getPositiveChange(details['tradeCount_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        symbol_changes[symbol] += getPositiveChange(details['lastPrice_' + str(seconds_inbetween) + '_secAgo'])\n",
    "    symbol_changes = list(dict(sorted(symbol_changes.items(), key=lambda item: item[1], reverse = True)).keys())\n",
    "\n",
    "    new_avaiable_coins = {}\n",
    "    for coin, symbols in avaiable_coins.items():\n",
    "        new_avaiable_coins[coin] = []\n",
    "        for symbol in symbol_changes:\n",
    "            if symbol in symbols:\n",
    "                new_avaiable_coins[coin].append(symbol)\n",
    "\n",
    "    avaiable_coins = new_avaiable_coins\n",
    "\n",
    "\n",
    "def getPositiveChange(number):\n",
    "    if number < 0:\n",
    "        return number * -1\n",
    "    else:\n",
    "        return number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFk0gn6wjwRx"
   },
   "source": [
    "### proccessPredictions():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9W3xKw0j30q"
   },
   "outputs": [],
   "source": [
    "def runModelPredictions(model_name, model, df, coins):\n",
    "  \n",
    "    if model_name == 'NNAction':\n",
    "        results = model.predict(dict(df), verbose = 0)\n",
    "    elif model_name == 'CatBoostAction':\n",
    "        results = model.predict_proba(df)\n",
    "\n",
    "    predictions_byModel = {}\n",
    "\n",
    "    i = 0\n",
    "    for coin in coins:\n",
    "        predictions_byModel[coin] = {}\n",
    "        \n",
    "        array = []\n",
    "        sorted_array = []\n",
    "\n",
    "        for a in range(0, amount_of_symbols_per_action_sample):\n",
    "            array.append(results[i][0])\n",
    "            i += 1\n",
    "\n",
    "        sorted_array = np.argsort(array)\n",
    "\n",
    "        for a in range(0, amount_of_symbols_per_action_sample):\n",
    "            predictions_byModel[coin][a] = {\n",
    "                'symbol': df['symbol'][i - sorted_array[-1 - a] - 1],\n",
    "                'value': array[sorted_array[-1 - a]],\n",
    "            }\n",
    "    \n",
    "    return predictions_byModel\n",
    "\n",
    "def proccessPredictions(saved, coins):\n",
    "    time_now = time.time()\n",
    "    list_data = []\n",
    "    predictions_byModel = {}\n",
    "    \n",
    "    for sample in saved:\n",
    "        list_data.append(list(sample.values()))\n",
    "\n",
    "    df = pd.DataFrame(list_data, columns = features_list)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        predictions_byModel[model_name] = runModelPredictions(model_name, model, df, coins)\n",
    "\n",
    "    pred_time = str(round(time.time() - time_now, 2))\n",
    "\n",
    "    return predictions_byModel, pred_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKOMrV86wxf6"
   },
   "source": [
    "### validatePredictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mKv-Feew7vS"
   },
   "outputs": [],
   "source": [
    "def validatePredictions(current_epoch, memory_symbols):\n",
    "    global memory_data, predictions_saved\n",
    "    \n",
    "    list_data = []\n",
    "    y_train = []\n",
    "    validated_list = {}\n",
    "    validated_list_targets = {}\n",
    "\n",
    "    for symbol, inner in memory_symbols.items():\n",
    "        old_lastPrice = inner['lastPrice'][0]\n",
    "        if old_lastPrice == 0:\n",
    "            old_lastPrice = 0.0001\n",
    "        new_lastPrice = inner['lastPrice'][current_epoch - 1 - deleted_symbol_data]\n",
    "\n",
    "        validated_list[symbol] = (new_lastPrice - old_lastPrice) / old_lastPrice\n",
    "        \n",
    "    for sample in memory_data[0]:\n",
    "        coin = sample['coin']\n",
    "        symbol = sample['symbol']\n",
    "\n",
    "        if coin not in validated_list_targets.keys():\n",
    "            validated_list_targets[coin] = []\n",
    "\n",
    "        reg_target = validated_list[symbol]\n",
    "        if symbol.startswith(coin):\n",
    "            reg_target *= -1\n",
    "        if reg_target > binary_target_minimum_increase_min:\n",
    "            y_result = 1\n",
    "            validated_list_targets[coin].append(symbol)\n",
    "        else:\n",
    "            y_result = 0\n",
    "\n",
    "        list_data.append(sample)\n",
    "        y_train.append(y_result)\n",
    "\n",
    "    for coin, symbols in validated_list_targets.items():\n",
    "        if len(symbols) == 0:\n",
    "            validated_list_targets[coin].append('NONE')\n",
    "\n",
    "    return list_data, y_train, validated_list_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX4Yb1Cqm7km"
   },
   "outputs": [],
   "source": [
    "def validatePastPredictions(validated_list_targets):\n",
    "    global loss_string, median_loss, median_loss_positives\n",
    "\n",
    "    loss_string = ''\n",
    "\n",
    "    for model_name, inner in predictions_saved[0].items():\n",
    "        # Calculate Loss:\n",
    "        losses, count = 0, 0\n",
    "        losses_positives, count_positives = 0, 0\n",
    "\n",
    "        print('_PAST:')\n",
    "        for coin, detail in inner.items():\n",
    "            targets = validated_list_targets[coin]\n",
    "\n",
    "            print(coin, 'targets:', targets)\n",
    "            print(coin, 'pred: ', detail[0]['symbol'], round(detail[0]['value'], 2), ' ', detail[1]['symbol'], round(detail[1]['value'], 2), ' ', detail[2]['symbol'], round(detail[2]['value'], 2))\n",
    "            \n",
    "            found_positive = False\n",
    "            loss, loss_positive = 1, 1\n",
    "\n",
    "            if 'NONE' in targets:\n",
    "                # Loss:\n",
    "                loss = detail[0]['value']\n",
    "\n",
    "                # Positives:\n",
    "                if loss > 0.5:\n",
    "                    loss_positive = loss\n",
    "                    found_positive = True\n",
    "            else:\n",
    "                loss_positives_temp = 3\n",
    "\n",
    "                for i in range(0, amount_of_symbols_per_action_sample):\n",
    "                    if detail[i]['symbol'] in targets:\n",
    "                        # Loss:\n",
    "                        loss_positives_temp -= detail[i]['value']\n",
    "\n",
    "                loss = loss_positives_temp / amount_of_symbols_per_action_sample\n",
    "                loss_positive = loss\n",
    "                found_positive = True\n",
    "                \n",
    "            if found_positive:\n",
    "                count_positives += 1\n",
    "                losses_positives += loss_positive\n",
    "            count += 1\n",
    "            losses += loss\n",
    "        print()\n",
    "        \n",
    "        losses /= count\n",
    "\n",
    "        losses_agregated[model_name].append(losses)\n",
    "\n",
    "        length_losses_agregated = len(losses_agregated[model_name])\n",
    "        length_losses_agregated_positives = len(losses_agregated_positives[model_name])\n",
    "\n",
    "        if count_positives > 0:\n",
    "            losses_positives /= count_positives\n",
    "        elif length_losses_agregated_positives > 0:\n",
    "            losses_positives = losses_agregated_positives[model_name][length_losses_agregated_positives - 1]\n",
    "        else:\n",
    "            losses_positives = losses\n",
    "        losses_agregated_positives[model_name].append(losses_positives)\n",
    "        length_losses_agregated_positives += 1\n",
    "\n",
    "        if length_losses_agregated > aggregate_loss_history_epochs:\n",
    "            del losses_agregated[model_name][0]\n",
    "\n",
    "        if length_losses_agregated_positives > aggregate_loss_history_epochs:\n",
    "            del losses_agregated_positives[model_name][0]\n",
    "        \n",
    "        median_loss = round(sum(losses_agregated[model_name]) / length_losses_agregated, 3)\n",
    "        median_loss_positives = round(sum(losses_agregated_positives[model_name]) / length_losses_agregated_positives, 3)\n",
    "\n",
    "        loss_string += str(median_loss) + ' (P: ' + str(median_loss_positives) + ' )  '\n",
    "        #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEkAlPZfk7cZ"
   },
   "source": [
    "### convert_wallet_to_euro():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGuJiuABk8Uh"
   },
   "outputs": [],
   "source": [
    "def convert_wallet_to_euro(holding_coins, memory_symbols, epoch):\n",
    "    global dont_update_holding_coins, dont_update_holding_coins_buffer\n",
    "\n",
    "    euro = 0\n",
    "\n",
    "    for coin, data in holding_coins.items():\n",
    "        found = False\n",
    "        if coin == 'EUR':\n",
    "            euro += data['balance']\n",
    "            holding_coins[coin]['balance_eur'] = data['balance']\n",
    "            found = True\n",
    "            continue\n",
    "\n",
    "        if coin == 'DEFAULT':\n",
    "            continue\n",
    "        \n",
    "        for symbol, inner in memory_symbols.items():\n",
    "            if symbol in avaiable_coins[coin] and 'EUR' in symbol:\n",
    "                lastPrice = inner['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "                balance = 0\n",
    "                if symbol.endswith(coin):\n",
    "                    balance = data['balance'] / lastPrice\n",
    "                else:\n",
    "                    balance = data['balance'] * lastPrice\n",
    "                    \n",
    "                euro += balance\n",
    "                holding_coins[coin]['balance_eur'] = balance\n",
    "                found = True\n",
    "                break\n",
    "        else:\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                lastPrice = memory_symbols[symbol]['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "                similars = [\"BTC\", \"ETH\", \"BNB\", \"USDT\", \"BUSD\"]\n",
    "                if any(x in symbol for x in similars):\n",
    "                    new_currency = 0\n",
    "                    if symbol.endswith(coin):\n",
    "                        new_currency = data['balance'] / lastPrice\n",
    "                    else:\n",
    "                        new_currency = data['balance'] * lastPrice\n",
    "                    new_coin = symbol.replace(coin, '')\n",
    "                    \n",
    "                    # print(symbol, coin, new_coin) \n",
    "                    for symbol2 in memory_symbols.keys():\n",
    "                        if symbol2 in avaiable_coins[new_coin] and 'EUR' in symbol2:\n",
    "                            lastPrice = memory_symbols[symbol2]['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "                            balance = 0\n",
    "                            if symbol2.endswith(coin):\n",
    "                                balance = new_currency / lastPrice\n",
    "                            else:\n",
    "                                balance = new_currency * lastPrice\n",
    "                                \n",
    "                            euro += balance\n",
    "                            holding_coins[coin]['balance_eur'] = balance\n",
    "                            found = True\n",
    "                            break\n",
    "                    else:\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "        if found == False:            \n",
    "          print('ALEED!!: convert_wallet_to_euro() | Couldnt resolve coin for trading euro:', coin)\n",
    "\n",
    "    return str(round(euro, 2)) + ' €'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiBXDbMQlU49"
   },
   "source": [
    "### processTrading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtAGU3cjlZLG"
   },
   "outputs": [],
   "source": [
    "def processTrading(predictions_byModel, current_epoch, memory_symbols):\n",
    "    global holding_coins, dont_update_holding_coins, dont_update_holding_coins_buffer, cancel_orders\n",
    "\n",
    "    print('_TRADING:')\n",
    "    for inner in predictions_byModel.values():\n",
    "        for coin, details in inner.items():\n",
    "            if coin in holding_coins.keys():\n",
    "                print(coin, details[0]['symbol'], str(round(details[0]['value'] * 100, 2)) + '%')\n",
    "    print()\n",
    "\n",
    "\n",
    "    for coin in list(holding_coins.keys()):\n",
    "        if median_loss > trade_when_below_loss:\n",
    "            continue\n",
    "        symbol = predictions_byModel[model_name_for_trading][coin][0]['symbol']\n",
    "        if holding_coins[coin]['counting_epochs'] > 99:\n",
    "            print('Will trade ' + coin + ' now because counting_epochs > 99.')\n",
    "        elif predictions_byModel[model_name_for_trading][coin][0]['value'] < minimum_prediction_prob_trade:\n",
    "            continue\n",
    "\n",
    "        buying_coin = symbol.replace(coin, '')\n",
    "\n",
    "        buying_quantity = None\n",
    "        price = None\n",
    "\n",
    "        if symbol.startswith(coin):\n",
    "            bidPrice_low = memory_symbols[symbol]['bidPrice_low'][current_epoch - 1 - deleted_symbol_data]\n",
    "            price = bidPrice_low\n",
    "            buying_quantity = holding_coins[coin]['balance'] * price\n",
    "        else:\n",
    "            askPrice_high = memory_symbols[symbol]['askPrice_high'][current_epoch - 1 - deleted_symbol_data]\n",
    "            price = askPrice_high\n",
    "            buying_quantity = holding_coins[coin]['balance'] / price\n",
    "\n",
    "        price = round(price, binance_symbols[symbol]['tickSize'])\n",
    "        buying_quantity = round(buying_quantity, 7)\n",
    "\n",
    "        trade = '--> Attempt Trading ' + str(holding_coins[coin]['balance']) + ' ' + coin + ' to ' + str(buying_quantity) + ' ' + buying_coin + \\\n",
    "                ' for ' + str(price) + '        [' + time.strftime(\"%H:%M:%S\") + ']'\n",
    "        print(trade)\n",
    "\n",
    "        #########################################################\n",
    "        #########################################################\n",
    "        #########################################################\n",
    "        \n",
    "        if do_real_money_trade:\n",
    "              \n",
    "            side = SIDE_BUY\n",
    "            order_quantity = buying_quantity\n",
    "            order_notional = holding_coins[coin]['balance']\n",
    "            if symbol.endswith(buying_coin):\n",
    "                side = SIDE_SELL\n",
    "                order_quantity = holding_coins[coin]['balance']\n",
    "                order_notional = buying_quantity\n",
    "\n",
    "            order_quantity = round(order_quantity, binance_symbols[symbol]['stepSizeInteger'])\n",
    "\n",
    "            if binance_symbols[symbol]['minNotional'] >= order_notional:\n",
    "                print('minNotional err', coin, binance_symbols[symbol]['minNotional'], order_quantity)\n",
    "                del holding_coins[coin]\n",
    "                if coin in dont_update_holding_coins:\n",
    "                    dont_update_holding_coins.remove(coin)\n",
    "                    del dont_update_holding_coins_buffer[coin]\n",
    "                print(coin + ' deleted from trading wallet.')\n",
    "                continue\n",
    "\n",
    "            limit_price = format(price, '.' + str(binance_symbols[symbol]['tickSize']) + 'f')\n",
    "            order_quantity = format(order_quantity, '.' + str(binance_symbols[symbol]['stepSizeInteger']) + 'f')\n",
    "\n",
    "            print(symbol, side, order_quantity, limit_price)\n",
    "        \n",
    "            success = False\n",
    "            try:\n",
    "                cancel_orders = True\n",
    "                order = binance.create_order(\n",
    "                    symbol=symbol,\n",
    "                    side=side,\n",
    "                    type=ORDER_TYPE_LIMIT,\n",
    "                    timeInForce=TIME_IN_FORCE_GTC,\n",
    "                    quantity=order_quantity,\n",
    "                    price=limit_price)\n",
    "                print(order)\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print('create_order err:', e.message)\n",
    "                if 'insufficient balance' in e.message or 'MIN_NOTIONAL' in e.message:\n",
    "                    if coin not in dont_update_holding_coins:\n",
    "                        if coin not in dont_update_holding_coins_buffer.keys():\n",
    "                            dont_update_holding_coins_buffer[coin] = 1\n",
    "                        else:\n",
    "                            dont_update_holding_coins_buffer[coin] += 1\n",
    "                            if dont_update_holding_coins_buffer[coin] > 2:\n",
    "                                dont_update_holding_coins.append(coin)\n",
    "                    else:\n",
    "                        holding_coins[coin]['balance'] -= binance_symbols[symbol]['stepSize']\n",
    "            ###\n",
    "            ########################################################\n",
    "\n",
    "            if success:\n",
    "                balance = buying_quantity\n",
    "                if buying_coin in holding_coins.keys():\n",
    "                    balance += holding_coins[buying_coin]['balance']\n",
    "\n",
    "                # Set the new acquired coin:\n",
    "                holding_coins[buying_coin] = {\n",
    "                    'balance': balance,\n",
    "                    'balance_eur': 1, \n",
    "                    'price': limit_price,\n",
    "                    'counting_epochs': 0,\n",
    "                    'symbol': symbol, \n",
    "                    'date': time.strftime('%H:%M:%S')\n",
    "                }\n",
    "\n",
    "                if coin in dont_update_holding_coins:\n",
    "                    dont_update_holding_coins.remove(coin)\n",
    "                    del dont_update_holding_coins_buffer[coin]\n",
    "\n",
    "        print()\n",
    "\n",
    "    for coin in holding_coins.keys():\n",
    "        holding_coins[coin]['counting_epochs'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2TD04LYP0V2"
   },
   "source": [
    "### trainModels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data_for_training_NN(training_list, y_train):\n",
    "    df = pd.DataFrame(training_list)\n",
    "    df = df.astype(dtype = features_dtypes)\n",
    "\n",
    "    # new_data = []\n",
    "    # for data in training_list:\n",
    "    #     append = []\n",
    "    #     for value in data.values():\n",
    "    #         append.append(value)\n",
    "    #     new_data.append(append)\n",
    "\n",
    "    # y_train = pd.get_dummies(y_train)\n",
    "    # y_train = tf.keras.utils.to_categorical(y_train, num_classes = amount_of_symbols_per_action_sample + 1)\n",
    "\n",
    "    # print('y_train', y_train)\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((dict(df), y_train))\n",
    "    \n",
    "    train_ds = train_ds.batch(10000)        # TODO: Remove this shit\n",
    "\n",
    "    return train_ds\n",
    "\n",
    "def do_warmup(training_list, y_train):\n",
    "\n",
    "    if use_models[\"NN\"] == 1:\n",
    "        time_now = time.time()\n",
    "        print(0)\n",
    "        model_name, model = create_model_nn('NNAction')\n",
    "        print(1)\n",
    "        train_ds = clean_data_for_training_NN(training_list, y_train)\n",
    "        print(2)\n",
    "        model.fit(train_ds,\n",
    "                epochs = nn_epochs,\n",
    "                verbose = 1)\n",
    "        print(model_name, 'Did warmup:', time.time() - time_now)\n",
    "\n",
    "    if use_models[\"CatBoost\"] == 1:\n",
    "        time_now = time.time()\n",
    "        print(0)\n",
    "        _, model = create_model_catboost('CatBoostAction')\n",
    "        print(1)\n",
    "        df = pd.DataFrame(training_list)\n",
    "        print(2)\n",
    "        model.fit(df, \n",
    "                y_train, \n",
    "                cat_features = categorial_features_indices, \n",
    "                verbose = True)\n",
    "        print(model_name, 'Did warmup:', time.time() - time_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3o7BpD-ZP1ce"
   },
   "outputs": [],
   "source": [
    "def trainModels(training_list, y_train):\n",
    "    global print_trained_string, saved_df_buffer, saved_y_buffer, time_train, nn_epochs\n",
    "\n",
    "    time_now = time.time()\n",
    "\n",
    "    df = pd.DataFrame(training_list)\n",
    "\n",
    "    if do_gather_dataset:\n",
    "        model_df_buffer_lock.acquire()\n",
    "        saved_df_buffer = pd.concat([saved_df_buffer, df])\n",
    "        saved_y_buffer += y_train\n",
    "        model_df_buffer_lock.release()\n",
    "\n",
    "    time_df = time.time() - time_now\n",
    "\n",
    "    model_training_lock.acquire()\n",
    "    time_now = time.time()\n",
    "\n",
    "    if time_train < seconds_inbetween - 1 and time_big < seconds_inbetween - 1:\n",
    "        nn_epochs += 1\n",
    "    elif (time_train > seconds_inbetween - 0.5 or time_big > seconds_inbetween - 0.5) and nn_epochs > 0:\n",
    "        nn_epochs -= 2\n",
    "\n",
    "    if do_training and nn_epochs > 0:\n",
    "        if use_models[\"NN\"] == 1:\n",
    "            train_ds = clean_data_for_training_NN(training_list, y_train)\n",
    "            for model_name, model in models.items():\n",
    "                if \"NN\" in model_name:\n",
    "                    model.fit(train_ds,\n",
    "                            epochs = nn_epochs,\n",
    "                            verbose = 0)\n",
    "        if use_models[\"CatBoost\"] == 1:\n",
    "            for model_name, model in models.items():\n",
    "                if \"CatBoost\" in model_name:\n",
    "                    model.fit(df, \n",
    "                            y_train, \n",
    "                            cat_features = categorial_features_indices, \n",
    "                            verbose = False)\n",
    "\n",
    "    time_train = time.time() - time_now\n",
    "\n",
    "    model_training_lock.release()\n",
    "\n",
    "    # if epoch % 23 == 0:\n",
    "    #     save() # Save models\n",
    "\n",
    "    print_trained_string = '[Trained ' + str(len(y_train)) + ' [' + str(round(time_df, 2)) + ' + ' + str(round(time_train, 2)) + ' s]  ' + str(nn_epochs) + ' epochs ]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnK91M6QN-0Z"
   },
   "source": [
    "### save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kvDVMCMZBof"
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    global saved_df_buffer, saved_y_buffer\n",
    "    time_now = time.time()\n",
    "\n",
    "    if do_training:\n",
    "        for model_name, model in models.items():\n",
    "            if \"NN\" in model_name and use_models[\"NN\"] == 1:\n",
    "                try:\n",
    "                    model.save(root_dir + '/nn/' + model_name)\n",
    "                except Exception as e:\n",
    "                    print('SAVE FAILED:', model_name)\n",
    "                    print(e)\n",
    "            if \"CatBoost\" in model_name and use_models[\"CatBoost\"] == 1:\n",
    "                joblib.dump(model, root_dir + '/catboost/' + model_name)\n",
    "\n",
    "    if do_gather_dataset:\n",
    "        if model_df_buffer_lock.locked():\n",
    "            model_df_buffer_lock.acquire() #\n",
    "            saved_df_buffer = pd.DataFrame()\n",
    "            saved_y_buffer = []\n",
    "            model_df_buffer_lock.release() #\n",
    "            print('Aborted save df.', round(time.time() - time_now, 2), 's')\n",
    "        else:\n",
    "            time_string = str(round(time.time()))\n",
    "            model_df_buffer_lock.acquire() #\n",
    "            df_import = saved_df_buffer\n",
    "            saved_df_buffer = pd.DataFrame()\n",
    "            y_import = saved_y_buffer\n",
    "            saved_y_buffer = []\n",
    "            model_df_buffer_lock.release() #\n",
    "            df_import.to_csv(root_dir + '/' + datasets_dir + '/' + time_string + '.csv', index = False)\n",
    "            joblib.dump(y_import, root_dir + '/' + datasets_dir + '/' + time_string + '.csv.y')\n",
    "            print('Saved df to', datasets_dir, '. ', round(time.time() - time_now, 2), 's', '', df_import.shape[0], len(y_import))\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cy1D3bhURrj7"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFIUOLfp79nD",
    "outputId": "a5dcc5f5-10a6-4135-f415-f962b432341d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "init()\n",
    "schedule = sched.scheduler(time.time, time.sleep)\n",
    "while(1):\n",
    "    runner()\n",
    "    print('Next episode')\n",
    "\n",
    "\n",
    "# Last folder size: 26.2mb\n",
    "\n",
    "# TODO:\n",
    "# Add volatility indicator per coin/symbol \n",
    "#"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "f1rbiuNnTOAt",
    "jOlkyfhOWYPz",
    "xGyza51MbQ8i",
    "F8t4j-VCVPv_",
    "TZMtPNjERlzE",
    "sjsTJIZxAlzA",
    "rwAVJm55CSR5",
    "f1uHH3AlgtLF",
    "Zhk559ZXlIPx",
    "6HtKD9Wrmxi0",
    "9WPpdhuugYQd",
    "dFk0gn6wjwRx",
    "wKOMrV86wxf6",
    "lEkAlPZfk7cZ",
    "eiBXDbMQlU49",
    "C2TD04LYP0V2",
    "OnK91M6QN-0Z"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m97"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff03dcfaa4ea4c7dbcc7a6acd2b5152b484988a1b13020911f06ea29377d1915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
