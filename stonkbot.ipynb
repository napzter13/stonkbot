{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Men1oM4eRfAn"
   },
   "source": [
    "## Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGdtNx2iqNc-"
   },
   "source": [
    "#### Settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "J75iPCI_qQkL"
   },
   "outputs": [],
   "source": [
    "\n",
    "start_over = False                                  # True will overwrite saved models with new models / False to Lock settings here.\n",
    "\n",
    "amount_of_symbols_per_coin_pred = 6                 # Symbols to predict per coin.\n",
    "aggregate_loss_history_epochs = 100                 # Calculate aggregated loss based on last X epochs\n",
    "\n",
    "minimum_prediction_prob_trade = 0.4                # Minimum 50% prediciton probability before taking trade action. \n",
    "decrease_prob_trade_per_epoch_below_30_epochs = 0.005\n",
    "decrease_prob_trade_per_epoch_above_30_epochs = 0.002\n",
    "\n",
    "trade_when_below_loss = 0.1\n",
    "binary_target_minimum_increase_min = 0.001          # Minimum 0.1 % increase.\n",
    "upscale_to_maximum_data_point_input = 0.03                # Upscale all model input data to be in real range: -3% to 3%.\n",
    "upscale_to_maximum_data_point_output = 0.01               # Upscale all model output data to be in real range: -1% to 1%.\n",
    "\n",
    "seconds_inbetween = 9                               # Seconds between handling training data.\n",
    "seconds_inbetween_pibeline = 3                      # Seconds between cycling the pibeline.\n",
    "\n",
    "pred_epoch = 20                                     # =  3   min    | Predict in how many epochs.\n",
    "interval_columns = 250                              # = 45   min    | Amount of epochs in history per sample.\n",
    "save_models_every_epochs = 300\n",
    "\n",
    "\n",
    "is_google_colab = False\n",
    "do_install_dependencies = False\n",
    "datasets_dir = 'datasets'\n",
    "\n",
    "\n",
    "\n",
    "real_wallet_dont_use_euro = 40\n",
    "\n",
    "do_real_money_trade = False   # prod: True\n",
    "do_training = True           # prod: True\n",
    "do_gather_dataset = False    # prod: False\n",
    "do_plots = True\n",
    "do_training_verbose = False\n",
    "\n",
    "\n",
    "use_models = {\n",
    "    'NN': True,\n",
    "    'CatBoost': False,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "nn_learning_rate = 0.000001\n",
    "nn_batch_size = 200\n",
    "\n",
    "\n",
    "# 0.077\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1rbiuNnTOAt"
   },
   "source": [
    "### load_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqr5zV0_TOyj"
   },
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    global models, model_name_for_trading\n",
    "\n",
    "    if not exists(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    if not exists(root_dir + '/' + datasets_dir):\n",
    "        os.mkdir(root_dir + '/' + datasets_dir)\n",
    "\n",
    "    if use_models[\"CatBoost\"] == 1:\n",
    "        model_name_for_trading = 'CatBoostAction'\n",
    "        if not exists(root_dir + '/catboost'):\n",
    "            os.mkdir(root_dir + '/catboost')\n",
    "\n",
    "        for filename in os.listdir(root_dir + '/catboost/'):\n",
    "            if 'ipynb_checkpoints' in filename:\n",
    "                continue\n",
    "            if filename not in models.keys():\n",
    "                models[filename] = joblib.load(root_dir + '/catboost/' + filename)\n",
    "                model_name_for_trading = filename\n",
    "\n",
    "    if use_models[\"NN\"] == 1:\n",
    "        model_name_for_trading = 'NNAction'\n",
    "        if not exists(root_dir + '/nn'):\n",
    "            os.mkdir(root_dir + '/nn')\n",
    "            \n",
    "        for filename in os.listdir(root_dir + '/nn/'):\n",
    "            if 'ipynb_checkpoints' in filename:\n",
    "                continue\n",
    "            if filename not in models.keys():\n",
    "                models[filename] = tf.keras.models.load_model(root_dir + '/nn/' + filename)\n",
    "                model_name_for_trading = filename\n",
    "\n",
    "\n",
    "    models = sorted(models.items(), key=lambda x: x[0], reverse=False)\n",
    "    models = {k: v for k, v in models}\n",
    "\n",
    "    for model_name, _ in models.items():\n",
    "        print('The holy ' + model_name + ' model has loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOlkyfhOWYPz"
   },
   "source": [
    "### create_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkttSkCNWZ2z"
   },
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    global did_fit, do_predictions, losses_agregated, losses_agregated_positives, model_name_for_trading\n",
    "\n",
    "    if len(models.keys()) == 0 or start_over:\n",
    "        if use_models[\"NN\"] == 1:\n",
    "            model_name, model = create_model_nn('NNAction')\n",
    "            models[model_name] = model\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "            \n",
    "            # model.summary()\n",
    "            keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "            model_name_for_trading = model_name\n",
    "            print(model_name + ' model created!')\n",
    "\n",
    "        if use_models[\"CatBoost\"] == 1:\n",
    "            model_name, model = create_model_catboost('CatBoostAction')\n",
    "            models[model_name] = model\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "            model_name_for_trading = model_name\n",
    "            print(model_name + ' model created!')\n",
    "\n",
    "        did_fit = False\n",
    "        do_predictions = False\n",
    "    else:\n",
    "        for model_name in models.keys():\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "\n",
    "\n",
    "def create_model_nn(name):\n",
    "    coin_input = keras.Input(batch_shape=(nn_batch_size, 1,), name = 'coin', dtype='string')\n",
    "    symbol_input = keras.Input(batch_shape=(nn_batch_size, 1,), name = 'symbol', dtype='string')\n",
    "    time_numbers_input = keras.Input(batch_shape=(nn_batch_size, interval_columns, 8), name = 'time_numbers_input')\n",
    "    inputs = [\n",
    "        coin_input,\n",
    "        symbol_input,\n",
    "        time_numbers_input\n",
    "    ]\n",
    "\n",
    "    normalizer = layers.StringLookup(vocabulary=list(avaiable_coins.keys()), output_mode='one_hot')\n",
    "    coin = normalizer(coin_input)\n",
    "    \n",
    "    normalizer = layers.StringLookup(vocabulary=avaiable_symbols_list, output_mode='one_hot')\n",
    "    symbol = normalizer(symbol_input)\n",
    "\n",
    "\n",
    "    lstm = layers.LSTM(100, stateful = True, return_sequences = True)(time_numbers_input)\n",
    "    lstm = layers.Dropout(0.3)(lstm)\n",
    "    lstm = layers.LSTM(100, stateful = True, return_sequences = False)(lstm)\n",
    "    lstm = layers.Dropout(0.3)(lstm)\n",
    "    lstm = keras.Model(time_numbers_input, lstm)\n",
    "    \n",
    "    time_numbers_input_flattened = layers.Flatten()(time_numbers_input)\n",
    "    dense = layers.concatenate([time_numbers_input_flattened, coin, symbol])\n",
    "    dense = layers.Dense(100, kernel_constraint = max_norm(4))(dense)\n",
    "    dense = layers.Dropout(0.3)(dense)\n",
    "    dense = keras.Model(inputs, dense)\n",
    "    \n",
    "    main = layers.concatenate([lstm.output, dense.output])\n",
    "    main = layers.Dense(100, kernel_constraint = max_norm(3))(main)\n",
    "    main = layers.Dropout(0.3)(main)\n",
    "    main = layers.Dense(100, kernel_constraint = max_norm(3))(main)\n",
    "    main = layers.Dropout(0.3)(main)\n",
    "    main = layers.Dense(100, kernel_constraint = max_norm(2))(main)\n",
    "\n",
    "    output = layers.Dense(1, activation = 'tanh')(main)\n",
    "\n",
    "\n",
    "    model = keras.Model(inputs, output, name=name)\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            learning_rate = nn_learning_rate\n",
    "        ),\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    )\n",
    "    \n",
    "    return name, model\n",
    "\n",
    "def create_model_catboost(name):\n",
    "\n",
    "    catboost_iterations = 7\n",
    "    catboost_depth = 10\n",
    "    catboost_learning_rate = 0.10\n",
    "    catboost_one_hot_max_size = 0\n",
    "    catboost_ctr_target_border_count = 50\n",
    "    catboost_model_size_reg = 0\n",
    "    catboost_max_ctr_complexity = 0\n",
    "    catboost_l2_leaf_reg = None\n",
    "    catboost_min_data_in_leaf = None\n",
    "    catboost_random_strength = None\n",
    "    catboost_bootstrap_type = 'Bernoulli'\n",
    "    catboost_subsample = 0.5\n",
    "    catboost_bagging_temperature = None\n",
    "\n",
    "    param = {\n",
    "        \"iterations\": catboost_iterations,\n",
    "        \"depth\": catboost_depth,\n",
    "        'learning_rate': catboost_learning_rate,\n",
    "        \"one_hot_max_size\": catboost_one_hot_max_size,\n",
    "        \"ctr_target_border_count\": catboost_ctr_target_border_count,\n",
    "        \"model_size_reg\": catboost_model_size_reg,\n",
    "        \"max_ctr_complexity\": catboost_max_ctr_complexity,\n",
    "        'l2_leaf_reg': catboost_l2_leaf_reg,\n",
    "        'min_data_in_leaf': catboost_min_data_in_leaf,\n",
    "        'random_strength': catboost_random_strength,\n",
    "        \"bootstrap_type\": catboost_bootstrap_type,\n",
    "\n",
    "        \"objective\": \"MultiClass\",\n",
    "        \"allow_const_label\": True,\n",
    "        \"task_type\": \"GPU\", \n",
    "        \"has_time\": True, \n",
    "        \"class_names\": possible_labels,\n",
    "        \"random_state\": 420,\n",
    "        \"allow_writing_files\": False,\n",
    "        \"boosting_type\": \"Plain\",\n",
    "    }\n",
    "    if catboost_bootstrap_type == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = catboost_bagging_temperature\n",
    "    elif catboost_bootstrap_type == \"Bernoulli\":\n",
    "        param[\"subsample\"] = catboost_subsample\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "\n",
    "    return name, model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGyza51MbQ8i",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### populate_coins_to_pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMaypnE0AUsi"
   },
   "outputs": [],
   "source": [
    "def validateActiveTickerSymbol(ticker):\n",
    "    if float(ticker['lastPrice']) < 0.0000001 or float(ticker['bidPrice']) < 0.0000001 or float(ticker['askPrice']) < 0.0000001:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def populate_coins_to_pairs():\n",
    "    global avaiable_coins, avaiable_symbols_list\n",
    "    avaiable_coins = {}\n",
    "    avaiable_symbols_list = []\n",
    "\n",
    "    balances = binance.get_account()['balances']\n",
    "    tickers = binance.get_ticker() # All symbol info\n",
    "\n",
    "\n",
    "    for balance in balances:\n",
    "        coin = balance['asset']\n",
    "        avaiable_coins[coin] = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if not validateActiveTickerSymbol(ticker):\n",
    "            continue\n",
    "        symbol = ticker['symbol']\n",
    "\n",
    "        found = False\n",
    "        for balance in balances:\n",
    "            coin = balance['asset']\n",
    "            if isCoinPairMatching(coin, symbol):\n",
    "              avaiable_coins[coin].append(symbol)\n",
    "              found = True\n",
    "        if found:\n",
    "            avaiable_symbols_list.append(symbol)\n",
    "\n",
    "def isCoinPairMatching(coin, symbol):\n",
    "    if coin not in symbol:\n",
    "        return False\n",
    "    \n",
    "    symbols = [\"BTCUP\", \"BTCDOWN\", \"ADAUP\", \"ADADOWN\", \"ETHUP\", \"ETHDOWN\", \"DOTUP\", \"DOTDOWN\", \"TRXUP\", \"TRXDOWN\", \"LINKUP\", \"LINKDOWN\", \\\n",
    "                \"BNBUP\", \"BNBDOWN\", \"CRH\"]\n",
    "    if any(x in symbol for x in symbols):\n",
    "        return False\n",
    "\n",
    "    if coin == 'AMB':\n",
    "        similars = [\"CREAMBUSD\", \"BEAM\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False \n",
    "    elif coin == 'AUD':\n",
    "        similars = [\"AUDIO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TRU':\n",
    "        similars = [\"ASTRUSDT\", \"USDTRUB\", \"DOT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TUSD':\n",
    "        similars = [\"TUSDT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GAL':\n",
    "        similars = [\"GALA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'BTC':\n",
    "        similars = [\"BTCST\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'OG':\n",
    "        similars = [\"DOGE\", \"OGN\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'COS':\n",
    "        similars = [\"COCOS\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'RUB':\n",
    "        similars = [\"TRUBTC\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'SHIB':\n",
    "        similars = [\"SUSHIBTC\", \"SUSHIBUSD\", \"SUSHIBNB\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'FET':\n",
    "        similars = [\"ELFETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'YFI':\n",
    "        similars = [\"YFII\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TRB':\n",
    "        similars = [\"ASTRBTC\", \"ASTRBUSD\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'BAR':\n",
    "        similars = [\"HBAR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'SC':\n",
    "        similars = [\"SCRT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'REP':\n",
    "        similars = [\"DREP\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GO':\n",
    "        similars = [\"AERGO\", \"ALGO\", \"DEGO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AST':\n",
    "        similars = [\"ASTR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AST':\n",
    "        similars = [\"CRVETH\", \"SSVETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ONE':\n",
    "        similars = [\"AIONETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GLM':\n",
    "        similars = [\"GLMR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'DAR':\n",
    "        similars = [\"ADARUB\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'VET':\n",
    "        similars = [\"CRVETH\", \"SSVETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OXT':\n",
    "        similars = [\"MBOXTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'ACA':\n",
    "        similars = [\"ALPACA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ONT':\n",
    "        similars = [\"FRONT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TCT':\n",
    "        similars = [\"BTCTUSD\", \"BTTCTRY\", \"BTCTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'AMP':\n",
    "        similars = [\"RAMP\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'WBTC':\n",
    "        similars = [\"FLOWBTC\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'LPT':\n",
    "        similars = [\"SLPTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'PHA':\n",
    "        similars = [\"ALPHA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AVA':\n",
    "        similars = [\"KAVA\", \"AVAX\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'MOB':\n",
    "        similars = [\"TOMO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'ORN':\n",
    "        similars = [\"TORN\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OM':\n",
    "        similars = [\"OMG\", \"ATOM\", \"COMP\", \"LOOM\", \"TOMO\", \"PROM\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'AR':\n",
    "        similars = [\"ARDR\", \"ARK\", \"ARPA\", \"BAR\", \"FARM\", \"HARD\", \"HBAR\", \"NEAR\", \"RARE\", \"DAR\", \"SPARTA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ATA':\n",
    "        similars = [\"DATA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ANT':\n",
    "        similars = [\"SANTOS\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'WIN':\n",
    "        similars = [\"WING\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'BUSD':\n",
    "        similars = [\"BNBUSDC\", \"TRBUSDT\", \"MOBUSDT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OP':\n",
    "        similars = [\"PEOPLE\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'FOR':\n",
    "        similars = [\"FORTH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'CKB':\n",
    "        similars = [\"DOCK\", \"QUICK\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin in ['BETH', 'BDOT', 'T']:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8t4j-VCVPv_",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### initBinanceInfo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwLwVhYLVRg9"
   },
   "outputs": [],
   "source": [
    "def initBinanceInfo():\n",
    "    global binance_symbols\n",
    "\n",
    "    get_exchange_info = binance.get_exchange_info()\n",
    "    for symbol in get_exchange_info['symbols']:\n",
    "        if symbol['symbol'] in avaiable_symbols_list:\n",
    "            stepSize = 0\n",
    "            stepSizeInteger = 0\n",
    "            tickSize = 0\n",
    "            minNotional = 0\n",
    "            for filter in symbol['filters']:\n",
    "                if filter['filterType'] == 'LOT_SIZE':\n",
    "                    stepSize = float(filter['stepSize'])\n",
    "                    if filter['stepSize'] == '0.10000000':\n",
    "                        stepSizeInteger = 1\n",
    "                    elif filter['stepSize'] == '0.01000000':\n",
    "                        stepSizeInteger = 2\n",
    "                    elif filter['stepSize'] == '0.00100000':\n",
    "                        stepSizeInteger = 3\n",
    "                    elif filter['stepSize'] == '0.00010000':\n",
    "                        stepSizeInteger = 4\n",
    "                    elif filter['stepSize'] == '0.00001000':\n",
    "                        stepSizeInteger = 5\n",
    "                    elif filter['stepSize'] == '0.00000100':\n",
    "                        stepSizeInteger = 6\n",
    "                    elif filter['stepSize'] == '0.00000010':\n",
    "                        stepSizeInteger = 7\n",
    "                    elif filter['stepSize'] == '0.00000001':\n",
    "                        stepSizeInteger = 8\n",
    "                elif filter['filterType'] == 'PRICE_FILTER':\n",
    "                    if filter['tickSize'] == '0.10000000':\n",
    "                        tickSize = 1\n",
    "                    elif filter['tickSize'] == '0.01000000':\n",
    "                        tickSize = 2\n",
    "                    elif filter['tickSize'] == '0.00100000':\n",
    "                        tickSize = 3\n",
    "                    elif filter['tickSize'] == '0.00010000':\n",
    "                        tickSize = 4\n",
    "                    elif filter['tickSize'] == '0.00001000':\n",
    "                        tickSize = 5\n",
    "                    elif filter['tickSize'] == '0.00000100':\n",
    "                        tickSize = 6\n",
    "                    elif filter['tickSize'] == '0.00000010':\n",
    "                        tickSize = 7\n",
    "                    elif filter['tickSize'] == '0.00000001':\n",
    "                        tickSize = 8\n",
    "                elif filter['filterType'] == 'MIN_NOTIONAL':\n",
    "                    minNotional = float(filter['minNotional'])\n",
    "\n",
    "            binance_symbols[symbol['symbol']] = {\n",
    "                'stepSize': stepSize,\n",
    "                'stepSizeInteger': stepSizeInteger,\n",
    "                'tickSize': tickSize,\n",
    "                'minNotional': minNotional,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZMtPNjERlzE"
   },
   "source": [
    "### init_meta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J-bgr9_RQOz",
    "outputId": "3bbd267c-d865-4946-e2b2-59e3eeb38f20"
   },
   "outputs": [],
   "source": [
    "root_dir = 'models' \n",
    "categorial_features = ['symbol', 'coin']    # 'direction_', \n",
    "\n",
    "if is_google_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    root_dir = 'drive/MyDrive/tradebot'\n",
    "\n",
    "if is_google_colab or do_install_dependencies:\n",
    "    !pip install catboost\n",
    "    !pip install python-binance\n",
    "    !pip install tensorflow\n",
    "\n",
    "import os, psutil\n",
    "from os.path import exists\n",
    "\n",
    "from catboost import *\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from binance import Client\n",
    "from binance.enums import *\n",
    "\n",
    "import sched, time\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from threading import Thread, Lock\n",
    "import numpy as np\n",
    "\n",
    "import fractions as frac\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "models = {}\n",
    "categorial_features_indices = None\n",
    "holding_coins = None\n",
    "holding_coins_DEFAULT = {\n",
    "    'balance': 0,\n",
    "    'balance_eur': 1,\n",
    "    'price': 0,\n",
    "    'counting_epochs': 0,\n",
    "    'symbol': '',\n",
    "    'date': time.strftime(\"%H:%M:%S\")\n",
    "}\n",
    "features_list = None\n",
    "features_dtypes = None\n",
    "avaiable_coins = None\n",
    "avaiable_symbols_list = None\n",
    "\n",
    "possible_labels = ['NONE']\n",
    "for i in range(0, amount_of_symbols_per_coin_pred):\n",
    "    possible_labels.append(str(i))\n",
    "\n",
    "binance_api_key = 'AoVFfn3JvetSRHpffstx9tg0Zlmzc6WHeAdVjVUnLfbzOTslBanPUMFa7bP4CqtU'\n",
    "binance_api_secret = 'zNGuMcE2UcycFQeVhTi5o9psM6GjZHvg7gEcTu1f8pazQg42EAMgvma5G583wv4G'\n",
    "binance = Client(binance_api_key, binance_api_secret)\n",
    "\n",
    "##### :\n",
    "epoch, part_epoch, total_part_epochs = 1, 1, 0\n",
    "memory_data = []\n",
    "memory_symbols = {}\n",
    "predictions_saved = []\n",
    "deleted_symbol_data = 0\n",
    "print_trained_string = '---'\n",
    "loss_string = '-'\n",
    "model_training_lock = None\n",
    "model_df_buffer_lock = None\n",
    "handleTickers_lock = None\n",
    "model_saving_lock = None\n",
    "binance_symbols = {} #\n",
    "dont_update_holding_coins = []\n",
    "dont_update_holding_coins_buffer = {}\n",
    "cancel_orders = False\n",
    "temp_tickers = {}\n",
    "do_predictions = True\n",
    "saved_df_buffer = pd.DataFrame()\n",
    "saved_y_buffer = []\n",
    "init_time = None\n",
    "did_fit = True\n",
    "losses_agregated = {}\n",
    "losses_agregated_positives = {}\n",
    "eur_balance_agregated = []\n",
    "trades_history = {}\n",
    "median_loss = 1\n",
    "median_loss_positives = 1\n",
    "time_train = seconds_inbetween - 2\n",
    "time_big = seconds_inbetween - 2\n",
    "model_name_for_trading = ''\n",
    "nn_epochs = 1  # Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NN:\n",
    "\n",
    "categorical_encoder = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (categorical_encoder, make_column_selector(dtype_include=object)),\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XiN8nxrY1HI",
    "outputId": "d04b8f43-43d0-40dd-cfb1-614f5cc0813e"
   },
   "outputs": [],
   "source": [
    "populate_coins_to_pairs()\n",
    "initBinanceInfo()\n",
    "# create_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AzHvj-pYFMJ"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjsTJIZxAlzA"
   },
   "source": [
    "### Init:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuFLPr_78efB"
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    global holding_coins, do_predictions, model_training_lock, model_df_buffer_lock, \\\n",
    "    epoch, part_epoch, total_part_epochs, memory_data, memory_symbols, predictions_saved, \\\n",
    "    deleted_symbol_data, print_trained_string, loss_string, saved_y_buffer, \\\n",
    "    dont_update_holding_coins, dont_update_holding_coins_buffer, \\\n",
    "    cancel_orders, temp_tickers, saved_df_buffer, \\\n",
    "    handleTickers_lock, model_saving_lock, init_time\n",
    "\n",
    "    initBinanceInfo()\n",
    "\n",
    "    epoch, part_epoch, total_part_epochs = 1, 1, 0\n",
    "    memory_data = []\n",
    "    memory_symbols = {}\n",
    "    predictions_saved = []\n",
    "    deleted_symbol_data = 0\n",
    "    print_trained_string = '---'\n",
    "    loss_string = '-'\n",
    "    model_training_lock = None\n",
    "    model_df_buffer_lock = None\n",
    "    handleTickers_lock = None\n",
    "    dont_update_holding_coins = []\n",
    "    dont_update_holding_coins_buffer = {}\n",
    "    cancel_orders = False\n",
    "    temp_tickers = {}\n",
    "    do_predictions = True\n",
    "    saved_df_buffer = pd.DataFrame()\n",
    "    saved_y_buffer = []\n",
    "    init_time = time.time()\n",
    "    holding_coins = {}\n",
    "\n",
    "    model_training_lock = Lock()\n",
    "    model_df_buffer_lock = Lock()\n",
    "    handleTickers_lock = Lock()\n",
    "    model_saving_lock = Lock()\n",
    "\n",
    "    print(\"\"\"\\\n",
    "                        ._ o o\n",
    "                        \\_`-)|_\n",
    "                      ,\"\"       \\ \n",
    "                    ,\"  ## |   = ಠ. \n",
    "                  ,\" ##   ,-\\__    `.\n",
    "                ,\"       /     `--._;)\n",
    "              ,\"     ## /\n",
    "            ,\"   ##    /\n",
    "███████╗████████╗ ██████╗ ███╗   ██╗██╗  ██╗██████╗  ██████╗ ████████╗\n",
    "██╔════╝╚══██╔══╝██╔═══██╗████╗  ██║██║ ██╔╝██╔══██╗██╔═══██╗╚══██╔══╝\n",
    "███████╗   ██║   ██║   ██║██╔██╗ ██║█████╔╝ ██████╔╝██║   ██║   ██║   \n",
    "╚════██║   ██║   ██║   ██║██║╚██╗██║██╔═██╗ ██╔══██╗██║   ██║   ██║   \n",
    "███████║   ██║   ╚██████╔╝██║ ╚████║██║  ██╗██████╔╝╚██████╔╝   ██║   \n",
    "╚══════╝   ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚═╝  ╚═╝╚═════╝  ╚═════╝    ╚═╝   v0.4\n",
    "                                                                      \n",
    "                    \"\"\")\n",
    "    print()\n",
    "    load_models()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwAVJm55CSR5"
   },
   "source": [
    "### Runner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uZ0wly0CZA9"
   },
   "outputs": [],
   "source": [
    "def runner():\n",
    "    global schedule, epoch, part_epoch, total_part_epochs, init_time\n",
    "    time_now = time.time()\n",
    "    \n",
    "    getTickers(part_epoch)\n",
    "\n",
    "    if part_epoch == (seconds_inbetween / seconds_inbetween_pibeline) - 1:\n",
    "        thread = Thread(target = updateBinanceBalances)\n",
    "        thread.start()\n",
    "\n",
    "    if seconds_inbetween / seconds_inbetween_pibeline <= part_epoch:\n",
    "        processTickers()\n",
    "        thread = Thread(target = handleTickers, args = (time_now, epoch, memory_symbols,))\n",
    "        thread.start()\n",
    "        epoch += 1\n",
    "        part_epoch = 0\n",
    "    part_epoch += 1\n",
    "    total_part_epochs += 1\n",
    "    # 459: 6 sec break..\n",
    "    if total_part_epochs == 460:\n",
    "        sleepy = (seconds_inbetween_pibeline * total_part_epochs) - (time.time() - init_time) - seconds_inbetween_pibeline + 2.5\n",
    "        if sleepy < 0:\n",
    "          sleepy = 0\n",
    "        print('sleepy', sleepy)\n",
    "        time.sleep(sleepy)\n",
    "        init_time = time.time()\n",
    "        total_part_epochs = 0\n",
    "        return\n",
    "\n",
    "    schedule.enter((seconds_inbetween_pibeline * total_part_epochs) - (time.time() - init_time) - seconds_inbetween_pibeline, 1, runner)\n",
    "    schedule.run()\n",
    "\n",
    "def getTickers(part_epoch):\n",
    "  global temp_tickers\n",
    "\n",
    "  try:\n",
    "      tickers = binance.get_ticker() # All symbol info\n",
    "  except:\n",
    "      print('binance.get_ticker() FAILED 1/2.')\n",
    "      try:\n",
    "          tickers = binance.get_ticker() # All symbol info\n",
    "      except:\n",
    "          print('binance.get_ticker() FAILED 2/2.')\n",
    "          return\n",
    "  \n",
    "  if part_epoch == 1:\n",
    "      for symbol in tickers:\n",
    "          if symbol['symbol'] not in avaiable_symbols_list:\n",
    "              continue\n",
    "          temp_tickers[symbol['symbol']] = {\n",
    "              'bidPrice_low': float(symbol['bidPrice']),\n",
    "              'bidPrice_high': float(symbol['bidPrice']),\n",
    "              'askPrice_low': float(symbol['askPrice']),\n",
    "              'askPrice_high': float(symbol['askPrice']),\n",
    "              'volume': float(symbol['volume']),\n",
    "              'quoteVolume': float(symbol['quoteVolume']),\n",
    "              'tradeCount': int(symbol['count']),\n",
    "              'lastPrice': float(symbol['lastPrice']),\n",
    "          }\n",
    "        \n",
    "  else:\n",
    "      for symbol in tickers:\n",
    "          if symbol['symbol'] not in avaiable_symbols_list:\n",
    "              continue\n",
    "        \n",
    "          new_bidPrice = float(symbol['bidPrice'])\n",
    "          new_askPrice = float(symbol['askPrice'])\n",
    "          \n",
    "          temp_tickers[symbol['symbol']] = {\n",
    "              'bidPrice_low': new_bidPrice if temp_tickers[symbol['symbol']]['bidPrice_low'] > new_bidPrice else temp_tickers[symbol['symbol']]['bidPrice_low'],\n",
    "              'bidPrice_high': new_bidPrice if temp_tickers[symbol['symbol']]['bidPrice_high'] < new_bidPrice else temp_tickers[symbol['symbol']]['bidPrice_high'],\n",
    "              'askPrice_low': new_askPrice if temp_tickers[symbol['symbol']]['askPrice_low'] > new_askPrice else temp_tickers[symbol['symbol']]['askPrice_low'],\n",
    "              'askPrice_high': new_askPrice if temp_tickers[symbol['symbol']]['askPrice_high'] < new_askPrice else temp_tickers[symbol['symbol']]['askPrice_high'],\n",
    "              'volume': float(symbol['volume']),\n",
    "              'quoteVolume': float(symbol['quoteVolume']),\n",
    "              'tradeCount': int(symbol['count']),\n",
    "              'lastPrice': float(symbol['lastPrice']),\n",
    "          }\n",
    "\n",
    "def processTickers():\n",
    "    global memory_symbols\n",
    "    for symbol, values in temp_tickers.items():\n",
    "        if symbol not in memory_symbols:\n",
    "            memory_symbols[symbol] = {\n",
    "                'bidPrice_low': [],\n",
    "                'bidPrice_high': [],\n",
    "                'askPrice_low': [],\n",
    "                'askPrice_high': [],\n",
    "                'volume': [],\n",
    "                'quoteVolume': [],\n",
    "                'tradeCount': [],\n",
    "                'lastPrice': [],\n",
    "            }\n",
    "        memory_symbols[symbol]['bidPrice_low'].append(values['bidPrice_low'])\n",
    "        memory_symbols[symbol]['bidPrice_high'].append(values['bidPrice_high'])\n",
    "        memory_symbols[symbol]['askPrice_low'].append(values['askPrice_low'])\n",
    "        memory_symbols[symbol]['askPrice_high'].append(values['askPrice_high'])\n",
    "        memory_symbols[symbol]['volume'].append(values['volume'])\n",
    "        memory_symbols[symbol]['quoteVolume'].append(values['quoteVolume'])\n",
    "        memory_symbols[symbol]['tradeCount'].append(values['tradeCount'])\n",
    "        memory_symbols[symbol]['lastPrice'].append(values['lastPrice'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1uHH3AlgtLF"
   },
   "source": [
    "### MAIN Thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JA60IEuagyml"
   },
   "outputs": [],
   "source": [
    "def handleTickers(time_now_big, epoch, memory_symbols):\n",
    "    global memory_data, deleted_symbol_data, print_trained_string, do_predictions, \\\n",
    "    predictions_saved, handleTickers_Lock, categorial_features_indices, features_dtypes, features_list, \\\n",
    "    time_big\n",
    "\n",
    "    memory_data_symbol = None\n",
    "    predictions_byModel = (\n",
    "        {},\n",
    "        '0',\n",
    "    )\n",
    "    \n",
    "    handleTickers_lock.acquire() #\n",
    "    if do_plots and epoch % 4 == 0:\n",
    "        clear_output(wait=True)\n",
    "    print('--------  Epoch: ', epoch, '  [' + str(time.strftime(\"%H:%M:%S\")) + ']')\n",
    "    print()\n",
    "\n",
    "    # Proccess coin data\n",
    "    proccessTickers_time = ''\n",
    "    if epoch > 1:\n",
    "        # Get list of symbols to check:\n",
    "        use_symbols = []\n",
    "        for coin in holding_coins.keys():\n",
    "            use_symbols += avaiable_coins[coin]\n",
    "            \n",
    "        time_big_itcp = time.time() - time_now_big\n",
    "        time_now = time.time()\n",
    "        memory_data_symbol = proccessTickers(epoch, memory_symbols, True, use_symbols)\n",
    "        proccessTickers_time = str(round(time_big_itcp, 2)) + ' + ' + str(round(time.time() - time_now, 2))\n",
    "\n",
    "    # Balances and euro:\n",
    "    print_eur_string = convert_wallet_to_euro(holding_coins, memory_symbols, epoch)\n",
    "    print('[ ' + print_eur_string + ' ]   _ Balances:')\n",
    "    for coin, inner in holding_coins.items():\n",
    "        print(coin, str(round(inner['balance'], 4)), '', str(round(inner['balance_eur'], 2)) + ' €', '   |  Price: ' + str(inner['price']) + ' ' + inner['symbol'] + '  | Epoch: ' + str(inner['counting_epochs']) + '       [' + inner['date'] + ']')\n",
    "    print()\n",
    "\n",
    "    if epoch > pred_epoch:\n",
    "        # Process Action Data\n",
    "        time_now = time.time()\n",
    "        saved, coins = processActionData(memory_data_symbol, True)\n",
    "        proccessTickers_time += ' + ' + str(round(time.time() - time_now, 2))\n",
    "\n",
    "        ## Init Set features_dtypes & categorial_features_indices ##\n",
    "        if epoch == pred_epoch + 1:\n",
    "            features_list = list(saved[0].keys())\n",
    "            features_dtypes = {}\n",
    "            categorial_features_indices = []\n",
    "            i = 0\n",
    "            for feature in features_list:\n",
    "                if any(x in feature for x in categorial_features):\n",
    "                    categorial_features_indices.append(i)\n",
    "                i += 1\n",
    "                if 'symbol' in feature or 'coin' in feature:    #  or 'direction_' in feature\n",
    "                    features_dtypes[feature] = 'string'\n",
    "                else:\n",
    "                    features_dtypes[feature] = 'float32'\n",
    "        ####\n",
    "\n",
    "        if do_predictions and len(holding_coins.keys()) > 0:\n",
    "            # Do Predictions:\n",
    "            predictions_byModel = proccessPredictions(saved, coins)\n",
    "    \n",
    "            # Trade coins:\n",
    "            if do_predictions and epoch > interval_columns + pred_epoch + 20:\n",
    "                processTrading(predictions_byModel[0], epoch, memory_symbols)\n",
    "            #\n",
    "\n",
    "    # Now build data for the rest of the coins and symbols:\n",
    "    if epoch > 1:\n",
    "        time_now_proccessTickers = time.time()\n",
    "        memory_data_symbol = proccessTickers(epoch, memory_symbols, False, None)\n",
    "        proccessTickers_time += ' + pT:' + str(round(time.time() - time_now_proccessTickers, 2))\n",
    "\n",
    "        # Start updating symbol priority list into avaiable_coins:\n",
    "        thread = Thread(target = updateSymbolPriorityList, args = (memory_data_symbol,))\n",
    "        thread.start()\n",
    "\n",
    "    if epoch > pred_epoch:\n",
    "        time_now_processActionData = time.time()\n",
    "        memory_data.append(processActionData(memory_data_symbol, False)[0])\n",
    "        proccessTickers_time += ' + pA:' + str(round(time.time() - time_now_processActionData, 2))\n",
    "    #\n",
    "    \n",
    "    if epoch % pred_epoch == 0 and epoch > pred_epoch + interval_columns:\n",
    "        do_predictions = True\n",
    "        \n",
    "    if epoch > pred_epoch:\n",
    "        predictions_saved.append(predictions_byModel[0])\n",
    "\n",
    "        if epoch == pred_epoch + 1:\n",
    "            print('Attempting to create models now...')\n",
    "            thread = Thread(target = create_models)\n",
    "            thread.start()\n",
    "        else:\n",
    "            # Do Validation on Past predictions:\n",
    "            training_list, y_train, validated_list_targets = validatePredictions(epoch, memory_symbols)\n",
    "            if do_predictions and epoch > interval_columns:\n",
    "                validatePastPredictions(validated_list_targets)\n",
    "            \n",
    "            if epoch == pred_epoch + interval_columns - 5:\n",
    "                # Do warmup:\n",
    "                print('Attempting to do warmup now...')\n",
    "                thread = Thread(target = do_warmup, args = (training_list, y_train,))\n",
    "                thread.start()\n",
    "\n",
    "            elif epoch > pred_epoch + interval_columns:\n",
    "                # Do training:\n",
    "                thread = Thread(target = trainModels, args = (epoch, training_list, y_train,))\n",
    "                thread.start()\n",
    "\n",
    "                if do_plots and nn_epochs > 1 and epoch % 4 == 0 and len(holding_coins.keys()) > 0:\n",
    "                    processPlotting(coins)\n",
    "    \n",
    "\n",
    "    # Cleanup:\n",
    "    if epoch > interval_columns:\n",
    "        for _, value in memory_symbols.items():\n",
    "            del value['bidPrice_high'][0]\n",
    "            del value['bidPrice_low'][0]\n",
    "            del value['askPrice_high'][0]\n",
    "            del value['askPrice_low'][0]\n",
    "            del value['volume'][0]\n",
    "            del value['quoteVolume'][0]\n",
    "            del value['tradeCount'][0]\n",
    "            del value['lastPrice'][0]\n",
    "        deleted_symbol_data += 1\n",
    "    if len(memory_data) == pred_epoch:\n",
    "        del memory_data[0]\n",
    "        del predictions_saved[0]\n",
    "\n",
    "    for text in trades_history.keys():\n",
    "        if trades_history[text]['x'] == 0:\n",
    "            del trades_history[text]\n",
    "            break\n",
    "    for text in trades_history.keys():\n",
    "        trades_history[text]['x'] -= 1\n",
    "    \n",
    "\n",
    "    if len(eur_balance_agregated) >= aggregate_loss_history_epochs:\n",
    "        del eur_balance_agregated[0]\n",
    "        \n",
    "    ##\n",
    "    time_big = round(time.time()-time_now_big, 2)\n",
    "    print('---------------- ', total_part_epochs, '[', time_big, 's ==', 't: ' + proccessTickers_time, '| p:', predictions_byModel[1], ']', \\\n",
    "          ' || ', print_trained_string, '|  Loss:', loss_string, ' |  RAM:', round(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2), 'mb')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    handleTickers_lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processPlotting():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPlotting(coins):\n",
    "    plt.figure(1)\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 5)\n",
    "    \n",
    "\n",
    "    ### Loss plot:\n",
    "    plt.subplot(211)\n",
    "    ax = plt.gca()\n",
    "    found = False\n",
    "    \n",
    "    for model_name, losses_agregat in losses_agregated.items():\n",
    "        plt.plot(losses_agregat, label=model_name + ' Loss', marker='.', linestyle='-', color='b')\n",
    "    for model_name, losses_agregat in losses_agregated_positives.items():\n",
    "        if len(losses_agregat) > 0:\n",
    "            found = True\n",
    "            plt.plot(losses_agregat, label=model_name + ' Positives', marker='.', linestyle='--', color='orange')\n",
    "    if found == False:\n",
    "        return\n",
    "\n",
    "    for trade in trades_history.values():\n",
    "        if trade['x'] <= aggregate_loss_history_epochs - pred_epoch:\n",
    "            ax.annotate(trade['text'], (trade['x'] + pred_epoch, 0.9), fontsize = 7)\n",
    "\n",
    "    plt.axhline(y = 0.5, color = 'gray', linestyle = 'dotted')\n",
    "    plt.title(\"Losses last \" + str(aggregate_loss_history_epochs) + \" epochs. Now: \" + ', '.join(coins))\n",
    "    plt.ylabel('Loss', fontsize=8)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim(0, 0.3)\n",
    "    \n",
    "\n",
    "    ### EUR profit plot:\n",
    "    plt.subplot(212)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for trade in trades_history.values():\n",
    "        ax.annotate(trade['text'], (trade['x'], trade['y']), fontsize = 7)\n",
    "\n",
    "    if eur_balance_agregated[0] <= eur_balance_agregated[-1]:\n",
    "        plt.plot(eur_balance_agregated, marker='.', linestyle='-', color='green')\n",
    "    else:\n",
    "        plt.plot(eur_balance_agregated, marker='.', linestyle='-', color='red')\n",
    "\n",
    "    plt.title(\"EUR balance last \" + str(aggregate_loss_history_epochs) + \" epochs\")\n",
    "    plt.xlabel('Epoch', fontsize=8)\n",
    "    plt.ylabel('EUR €', fontsize=8)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhk559ZXlIPx"
   },
   "source": [
    "### proccessTickers():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN5wC6Eni6s8"
   },
   "outputs": [],
   "source": [
    "def proccessTickers(epoch, memory_symbols, only_use_holding_symbols, use_symbols):\n",
    "    global highest, lowest\n",
    "\n",
    "    memory_data_symbol = {}\n",
    "\n",
    "    for symbol, inner in memory_symbols.items():\n",
    "        if only_use_holding_symbols and symbol not in use_symbols:\n",
    "            continue\n",
    "\n",
    "        dat = []\n",
    "\n",
    "        temp_bidPrice_low = inner['bidPrice_low'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_bidPrice_high = inner['bidPrice_high'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_askPrice_low = inner['askPrice_low'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_askPrice_high = inner['askPrice_high'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_volume = inner['volume'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_volume == 0:\n",
    "            temp_volume = 0.0000001\n",
    "        temp_quoteVolume = inner['quoteVolume'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_quoteVolume == 0:\n",
    "            temp_quoteVolume = 0.0000001\n",
    "        temp_tradeCount = inner['tradeCount'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_tradeCount == 0:\n",
    "            temp_tradeCount = 0.0000001\n",
    "        temp_lastPrice = inner['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_lastPrice == 0:\n",
    "            temp_lastPrice = 0.0000001\n",
    "\n",
    "\n",
    "        for i in range(1, interval_columns + 1):\n",
    "            if (epoch > i):\n",
    "                index = epoch - i - 1 - deleted_symbol_data\n",
    "\n",
    "                arr = []\n",
    "                \n",
    "                bidPrice_low = inner['bidPrice_low'][index] # Reverse + Pick i element.\n",
    "                if bidPrice_low == 0:\n",
    "                    arr.append(0)\n",
    "                else:\n",
    "                    bidPrice_low_change = (temp_bidPrice_low - bidPrice_low) / bidPrice_low\n",
    "                    if bidPrice_low_change > upscale_to_maximum_data_point_input:\n",
    "                        bidPrice_low_change = 1\n",
    "                    elif bidPrice_low_change < -upscale_to_maximum_data_point_input:\n",
    "                        bidPrice_low_change = -1\n",
    "                    else:\n",
    "                        bidPrice_low_change /= upscale_to_maximum_data_point_input\n",
    "                    arr.append(bidPrice_low_change)\n",
    "                    \n",
    "                bidPrice_high = inner['bidPrice_high'][index] # Reverse + Pick i element.\n",
    "                if bidPrice_high == 0:\n",
    "                    arr.append(0)\n",
    "                else:\n",
    "                    bidPrice_high_change = (temp_bidPrice_high - bidPrice_high) / bidPrice_high\n",
    "                    if bidPrice_high_change > upscale_to_maximum_data_point_input:\n",
    "                        bidPrice_high_change = 1\n",
    "                    elif bidPrice_high_change < -upscale_to_maximum_data_point_input:\n",
    "                        bidPrice_high_change = -1\n",
    "                    else:\n",
    "                        bidPrice_high_change /= upscale_to_maximum_data_point_input\n",
    "                    bidPrice_high_change /= upscale_to_maximum_data_point_input\n",
    "                    arr.append(bidPrice_high_change)\n",
    "\n",
    "                askPrice_low = inner['askPrice_low'][index] # Reverse + Pick i element.\n",
    "                if askPrice_low == 0:\n",
    "                    arr.append(0)\n",
    "                else:\n",
    "                    askPrice_low_change = (temp_askPrice_low - askPrice_low) / askPrice_low\n",
    "                    if askPrice_low_change > upscale_to_maximum_data_point_input:\n",
    "                        askPrice_low_change = 1\n",
    "                    elif askPrice_low_change < -upscale_to_maximum_data_point_input:\n",
    "                        askPrice_low_change = -1\n",
    "                    else:\n",
    "                        askPrice_low_change /= upscale_to_maximum_data_point_input\n",
    "                    arr.append(askPrice_low_change)\n",
    "\n",
    "                askPrice_high = inner['askPrice_high'][index] # Reverse + Pick i element.\n",
    "                if askPrice_high == 0:\n",
    "                    arr.append(0)\n",
    "                else:\n",
    "                    askPrice_high_change = (temp_askPrice_high - askPrice_high) / askPrice_high\n",
    "                    if askPrice_high_change > upscale_to_maximum_data_point_input:\n",
    "                        askPrice_high_change = 1\n",
    "                    elif askPrice_high_change < -upscale_to_maximum_data_point_input:\n",
    "                        askPrice_high_change = -1\n",
    "                    else:\n",
    "                        askPrice_high_change /= upscale_to_maximum_data_point_input\n",
    "                    arr.append(askPrice_high_change)\n",
    "\n",
    "                volume = inner['volume'][index] # Reverse + Pick i element.\n",
    "                if volume == 0:\n",
    "                    volume = 0.0000001\n",
    "                volume_change = (temp_volume - volume) / volume\n",
    "                if volume_change > upscale_to_maximum_data_point_input:\n",
    "                    volume_change = 1\n",
    "                elif volume_change < -upscale_to_maximum_data_point_input:\n",
    "                    volume_change = -1\n",
    "                else:\n",
    "                    volume_change /= upscale_to_maximum_data_point_input\n",
    "                arr.append(volume_change)\n",
    "\n",
    "                quoteVolume = inner['quoteVolume'][index] # Reverse + Pick i element.\n",
    "                if quoteVolume == 0:\n",
    "                    quoteVolume = 0.0000001\n",
    "                quoteVolume_change = (temp_quoteVolume - quoteVolume) / quoteVolume\n",
    "                if quoteVolume_change > upscale_to_maximum_data_point_input:\n",
    "                    quoteVolume_change = 1\n",
    "                elif quoteVolume_change < -upscale_to_maximum_data_point_input:\n",
    "                    quoteVolume_change = -1\n",
    "                else:\n",
    "                    quoteVolume_change /= upscale_to_maximum_data_point_input\n",
    "                arr.append(quoteVolume_change)\n",
    "\n",
    "                tradeCount = inner['tradeCount'][index] # Reverse + Pick i element.\n",
    "                if tradeCount == 0:\n",
    "                    tradeCount = 0.0000001\n",
    "                tradeCount_change = (temp_tradeCount - tradeCount) / tradeCount\n",
    "                if tradeCount_change > upscale_to_maximum_data_point_input:\n",
    "                    tradeCount_change = 1\n",
    "                elif tradeCount_change < -upscale_to_maximum_data_point_input:\n",
    "                    tradeCount_change = -1\n",
    "                else:\n",
    "                    tradeCount_change /= upscale_to_maximum_data_point_input\n",
    "                arr.append(tradeCount_change)\n",
    "\n",
    "                lastPrice = inner['lastPrice'][index] # Reverse + Pick i element.\n",
    "                if lastPrice == 0:\n",
    "                    lastPrice = 0.0000001\n",
    "                lastPrice_change = (temp_lastPrice - lastPrice) / lastPrice\n",
    "                if lastPrice_change > upscale_to_maximum_data_point_input:\n",
    "                    lastPrice_change = 1\n",
    "                elif lastPrice_change < -upscale_to_maximum_data_point_input:\n",
    "                    lastPrice_change = -1\n",
    "                else:\n",
    "                    lastPrice_change /= upscale_to_maximum_data_point_input\n",
    "                arr.append(lastPrice_change)\n",
    "\n",
    "\n",
    "                dat.insert(0, arr)\n",
    "\n",
    "\n",
    "                temp_bidPrice_low = bidPrice_low\n",
    "                temp_bidPrice_high = bidPrice_high\n",
    "                temp_askPrice_low = askPrice_low\n",
    "                temp_askPrice_high = askPrice_high\n",
    "                temp_volume = volume\n",
    "                temp_quoteVolume = quoteVolume\n",
    "                temp_tradeCount = tradeCount\n",
    "                temp_lastPrice = lastPrice\n",
    "\n",
    "            else:\n",
    "                dat.insert(0, [0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            \n",
    "\n",
    "        memory_data_symbol[symbol] = dat\n",
    "\n",
    "    return memory_data_symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HtKD9Wrmxi0"
   },
   "source": [
    "### processActionData():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flVCYZidm5aB"
   },
   "outputs": [],
   "source": [
    "def processActionData(memory_data_symbol, only_use_holding_symbols):\n",
    "    global holding_coins, memory_data, categorial_features_indices, features_list, saved_df_buffer\n",
    "\n",
    "    saved, coins = [], []\n",
    "\n",
    "    if only_use_holding_symbols:\n",
    "        for coin in list(holding_coins.keys()):\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                saved.append(getActionSampleRow(symbol, coin, memory_data_symbol))\n",
    "\n",
    "            coins.append(coin)\n",
    "    else:\n",
    "        for coin in avaiable_coins.keys():\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                saved.append(getActionSampleRow(symbol, coin, memory_data_symbol))\n",
    "\n",
    "            coins.append(coin)\n",
    "\n",
    "    return saved, coins\n",
    "\n",
    "\n",
    "def getActionSampleRow(symbol, coin, memory_data_symbol):\n",
    "    data = {\n",
    "        'coin': coin,\n",
    "        'symbol': symbol,\n",
    "        'time_numbers_input': []\n",
    "    }\n",
    "\n",
    "    if symbol.startswith(coin):\n",
    "        for arr in memory_data_symbol[symbol]:\n",
    "            arr_input = [x * -1 for x in arr]\n",
    "            data['time_numbers_input'].append(arr_input)\n",
    "    else:\n",
    "        for arr in memory_data_symbol[symbol]:\n",
    "            data['time_numbers_input'].append(arr)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WPpdhuugYQd"
   },
   "source": [
    "### updateBinanceBalances + updateSymbolPriorityList:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXnUSgd2gUxg"
   },
   "outputs": [],
   "source": [
    "def updateBinanceBalances():\n",
    "    global holding_coins, dont_update_holding_coins, cancel_orders\n",
    "\n",
    "    if cancel_orders:\n",
    "        cancel_orders = False\n",
    "        orders = binance.get_open_orders()\n",
    "        for order in orders:\n",
    "            print('cancel_order:', binance.cancel_order(\n",
    "                symbol = order['symbol'],\n",
    "                orderId = order['orderId']))\n",
    "\n",
    "    balances = binance.get_account()['balances']\n",
    "\n",
    "    # ### DEBUG:\n",
    "    # balances.append(\n",
    "    #     {\n",
    "    #         \"asset\": \"DOGE\",\n",
    "    #         \"free\": \"1000\",\n",
    "    # })\n",
    "    # balances.append(\n",
    "    #     {\n",
    "    #         \"asset\": \"EUR\",\n",
    "    #         \"free\": \"440\",\n",
    "    # })\n",
    "\n",
    "    found_assets = []\n",
    "    for balance in balances:\n",
    "        balance_number = float(balance['free'])\n",
    "        if balance_number > 0.0001:\n",
    "            if balance['asset'] not in holding_coins.keys():\n",
    "                holding_coins[balance['asset']] = holding_coins_DEFAULT.copy()\n",
    "            if balance['asset'] == 'EUR':\n",
    "                balance_number -= real_wallet_dont_use_euro\n",
    "                if balance_number < 1:\n",
    "                    continue\n",
    "            if balance['asset'] == 'BNB':\n",
    "                balance_number -= 0.01  # 2.76eur 15.09.22\n",
    "            if balance_number < 0.0001:\n",
    "                continue\n",
    "            if balance['asset'] not in dont_update_holding_coins:\n",
    "                holding_coins[balance['asset']]['balance'] = balance_number\n",
    "            found_assets.append(balance['asset'])\n",
    "    \n",
    "    for coin in list(holding_coins.keys()):\n",
    "        if coin not in found_assets or holding_coins[coin]['balance_eur'] < 1:\n",
    "            if coin in dont_update_holding_coins:\n",
    "                dont_update_holding_coins.remove(coin)\n",
    "                del dont_update_holding_coins_buffer[coin]\n",
    "            del holding_coins[coin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deEBL0RsYvti"
   },
   "outputs": [],
   "source": [
    "def updateSymbolPriorityList(memory_data_symbol):\n",
    "    global avaiable_coins\n",
    "\n",
    "    symbol_changes = {}\n",
    "    for symbol, details in memory_data_symbol.items():\n",
    "        symbol_changes[symbol] = getPositiveChange(details[0][7]) # lastPrice\n",
    "    symbol_changes = list(dict(sorted(symbol_changes.items(), key=lambda item: item[1], reverse = True)).keys())\n",
    "\n",
    "    new_avaiable_coins = {}\n",
    "    for coin, symbols in avaiable_coins.items():\n",
    "        new_avaiable_coins[coin] = []\n",
    "        for symbol in symbol_changes:\n",
    "            if symbol in symbols:\n",
    "                new_avaiable_coins[coin].append(symbol)\n",
    "\n",
    "    avaiable_coins = new_avaiable_coins\n",
    "\n",
    "\n",
    "def getPositiveChange(number):\n",
    "    if number < 0:\n",
    "        return number * -1\n",
    "    else:\n",
    "        return number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFk0gn6wjwRx"
   },
   "source": [
    "### proccessPredictions():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9W3xKw0j30q"
   },
   "outputs": [],
   "source": [
    "def runModelPredictions(model_name, model, symbols, ds, list_data, coins):\n",
    "    \n",
    "    model_saving_lock.acquire()\n",
    "  \n",
    "    try:\n",
    "        if model_name == 'NNAction':\n",
    "            results = model.predict(ds, verbose = 0)\n",
    "        elif model_name == 'CatBoostAction':\n",
    "            results = model.predict_proba(list_data)\n",
    "    except Exception as e:\n",
    "        print('Model.Predict() Failed.')\n",
    "        print(e)\n",
    "        model_saving_lock.release()\n",
    "        return {}\n",
    "\n",
    "    model_saving_lock.release()\n",
    "\n",
    "    predictions_byModel = {}\n",
    "\n",
    "    i = 0\n",
    "    for coin in coins:\n",
    "        predictions_byModel[coin] = {}\n",
    "        \n",
    "        array = []\n",
    "        found = 0\n",
    "\n",
    "        for a in range(0, amount_of_symbols_per_coin_pred):\n",
    "            if len(symbols) < i + 1:\n",
    "                break\n",
    "            if not symbols[i].startswith(coin) and not symbols[i].endswith(coin):\n",
    "                break\n",
    "            \n",
    "            array.append(results[i][0])\n",
    "            i += 1\n",
    "            found += 1\n",
    "\n",
    "        for b in range(found, amount_of_symbols_per_coin_pred):\n",
    "            array.append(0)\n",
    "\n",
    "        sorted_indices_array = np.argsort(array)[::-1][:amount_of_symbols_per_coin_pred] # highest first\n",
    "\n",
    "        for a in range(0, found):\n",
    "            predictions_byModel[coin][a] = {\n",
    "                'symbol': symbols[i - found + sorted_indices_array[a]],\n",
    "                'value': array[sorted_indices_array[a]],\n",
    "            }\n",
    "        \n",
    "        for b in range(found, amount_of_symbols_per_coin_pred):\n",
    "            predictions_byModel[coin][b] = {\n",
    "                'symbol': '0',\n",
    "                'value': 0,\n",
    "            }\n",
    "    \n",
    "    return predictions_byModel\n",
    "\n",
    "def proccessPredictions(saved, coins):\n",
    "    time_now = time.time()\n",
    "    \n",
    "    list_data = {\n",
    "        'coin': [],\n",
    "        'symbol': [],\n",
    "        'time_numbers_input': [],\n",
    "    }\n",
    "    predictions_byModel = {}\n",
    "\n",
    "    coin_count = {}\n",
    "    symbols = []\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for sample in saved:\n",
    "        if sample['coin'] not in coin_count.keys():\n",
    "            coin_count[sample['coin']] = 1\n",
    "        elif coin_count[sample['coin']] >= amount_of_symbols_per_coin_pred:\n",
    "            continue\n",
    "        else:\n",
    "            coin_count[sample['coin']] += 1\n",
    "\n",
    "        # duplicate 42\n",
    "\n",
    "        list_data['coin'].append(sample['coin'])\n",
    "        list_data['symbol'].append(sample['symbol'])\n",
    "        list_data['time_numbers_input'].append(sample['time_numbers_input'])\n",
    "\n",
    "        # list_data.append(list(sample.values()))\n",
    "        total_predictions += 1\n",
    "\n",
    "        symbols.append(sample['symbol'])\n",
    "\n",
    "    ds = clean_data_for_NN(list_data)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        predictions_byModel[model_name] = runModelPredictions(model_name, model, symbols, ds, list_data, coins)\n",
    "\n",
    "    pred_time = str(round(time.time() - time_now, 2)) + 's/' + str(total_predictions) + 'e'\n",
    "\n",
    "    return predictions_byModel, pred_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKOMrV86wxf6"
   },
   "source": [
    "### validatePredictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mKv-Feew7vS"
   },
   "outputs": [],
   "source": [
    "def validatePredictions(current_epoch, memory_symbols):\n",
    "    global memory_data, predictions_saved\n",
    "    \n",
    "    list_data = {\n",
    "        'coin': [],\n",
    "        'symbol': [],\n",
    "        'time_numbers_input': [],\n",
    "    }\n",
    "    y_train = []\n",
    "    validated_list = {}\n",
    "    validated_list_targets = {}\n",
    "\n",
    "    for symbol, inner in memory_symbols.items():\n",
    "        old_lastPrice = inner['lastPrice'][0]\n",
    "        if old_lastPrice == 0:\n",
    "            old_lastPrice = 0.0001\n",
    "        new_lastPrice = inner['lastPrice'][current_epoch - 1 - deleted_symbol_data]\n",
    "\n",
    "        validated_list[symbol] = (new_lastPrice - old_lastPrice) / old_lastPrice\n",
    "        \n",
    "    for sample in memory_data[0]:\n",
    "        coin = sample['coin']\n",
    "        symbol = sample['symbol']\n",
    "        time_numbers_input = sample['time_numbers_input']\n",
    "\n",
    "        if coin not in validated_list_targets.keys():\n",
    "            validated_list_targets[coin] = []\n",
    "\n",
    "        reg_target = validated_list[symbol]\n",
    "\n",
    "        if symbol.startswith(coin):\n",
    "            reg_target *= -1\n",
    "\n",
    "        if reg_target > binary_target_minimum_increase_min:\n",
    "            validated_list_targets[coin].append(symbol)\n",
    "\n",
    "        if reg_target > upscale_to_maximum_data_point_output:\n",
    "            reg_target = 1\n",
    "        elif reg_target < -upscale_to_maximum_data_point_output:\n",
    "            reg_target = -1\n",
    "        else:\n",
    "            reg_target /= upscale_to_maximum_data_point_output\n",
    "\n",
    "\n",
    "        # duplicate 43: for fitting\n",
    "\n",
    "        list_data['coin'].append(coin)\n",
    "        list_data['symbol'].append(symbol)\n",
    "        list_data['time_numbers_input'].append(time_numbers_input)\n",
    "\n",
    "        y_train.append(reg_target)\n",
    "\n",
    "    return list_data, y_train, validated_list_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX4Yb1Cqm7km"
   },
   "outputs": [],
   "source": [
    "def validatePastPredictions(validated_list_targets):\n",
    "    global loss_string, median_loss, median_loss_positives\n",
    "\n",
    "    loss_string = ''\n",
    "\n",
    "    for model_name, inner in predictions_saved[0].items():\n",
    "        # Calculate Loss:\n",
    "        losses, count = 0, 0\n",
    "        losses_positives, count_positives = 0, 0\n",
    "\n",
    "        print('_PAST:')\n",
    "        for coin, detail in inner.items():\n",
    "            symbols = ['NONE']\n",
    "            for i in range(0, amount_of_symbols_per_coin_pred):\n",
    "                if detail[i]['symbol'] == '0':\n",
    "                    break\n",
    "                symbols.append(detail[i]['symbol'])\n",
    "            targets = validated_list_targets[coin]\n",
    "            targets = list(filter(lambda x: x in symbols, targets))\n",
    "            if len(targets) == 0:\n",
    "                targets = ['NONE']\n",
    "\n",
    "            pred_streng = ''\n",
    "            for i in range(0, amount_of_symbols_per_coin_pred):\n",
    "                if detail[i]['symbol'] == '0':\n",
    "                    break\n",
    "                pred_streng += detail[i]['symbol'] + ' ' + str(round(detail[i]['value'], 2)) + '    '\n",
    "\n",
    "            print(coin, '_targets:', '  '.join(targets), '  ', '  ', '  ', '_pred:   ', pred_streng)\n",
    "            \n",
    "            found_positive = False\n",
    "            loss, loss_positive = 0, 1\n",
    "\n",
    "            if 'NONE' in targets:\n",
    "                # Loss:\n",
    "                loss = detail[0]['value']\n",
    "\n",
    "                # Positives:\n",
    "                if loss > 0:\n",
    "                    found_positive = True\n",
    "            else:\n",
    "                if detail[0]['symbol'] in targets:\n",
    "                    loss = 0.1 - detail[0]['value']\n",
    "                else:\n",
    "                    loss = 0.1 + detail[0]['value']\n",
    "                found_positive = True\n",
    "\n",
    "            if loss > 0.3:\n",
    "                loss = 0.3\n",
    "            elif loss < 0:\n",
    "                loss = 0\n",
    "                \n",
    "            if found_positive:\n",
    "                count_positives += 1\n",
    "                losses_positives += loss\n",
    "            count += 1\n",
    "            losses += loss\n",
    "        print()\n",
    "\n",
    "        if count == 0:\n",
    "            return\n",
    "        \n",
    "        losses /= count\n",
    "\n",
    "        losses_agregated[model_name].append(losses)\n",
    "\n",
    "        length_losses_agregated = len(losses_agregated[model_name])\n",
    "        length_losses_agregated_positives = len(losses_agregated_positives[model_name])\n",
    "\n",
    "        if count_positives > 0:\n",
    "            losses_positives /= count_positives\n",
    "        elif length_losses_agregated_positives > 0:\n",
    "            losses_positives = losses_agregated_positives[model_name][length_losses_agregated_positives - 1]\n",
    "        else:\n",
    "            losses_positives = losses\n",
    "        losses_agregated_positives[model_name].append(losses_positives)\n",
    "        length_losses_agregated_positives += 1\n",
    "\n",
    "        if length_losses_agregated > aggregate_loss_history_epochs:\n",
    "            length_losses_agregated -= 1\n",
    "            del losses_agregated[model_name][0]\n",
    "\n",
    "        if length_losses_agregated_positives > aggregate_loss_history_epochs:\n",
    "            length_losses_agregated_positives -= 1\n",
    "            del losses_agregated_positives[model_name][0]\n",
    "        \n",
    "        median_loss = round(sum(losses_agregated[model_name]) / length_losses_agregated, 3)\n",
    "        median_loss_positives = round(sum(losses_agregated_positives[model_name]) / length_losses_agregated_positives, 3)\n",
    "\n",
    "        loss_string += str(median_loss) + ' (P: ' + str(median_loss_positives) + ' )  '\n",
    "        #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEkAlPZfk7cZ"
   },
   "source": [
    "### convert_wallet_to_euro():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGuJiuABk8Uh"
   },
   "outputs": [],
   "source": [
    "def convert_wallet_to_euro(holding_coins, memory_symbols, epoch):\n",
    "    global dont_update_holding_coins, dont_update_holding_coins_buffer, eur_balance_agregated\n",
    "\n",
    "    euro = 0\n",
    "\n",
    "    for coin, data in holding_coins.items():\n",
    "        found = False\n",
    "        if coin == 'EUR':\n",
    "            euro += data['balance']\n",
    "            holding_coins[coin]['balance_eur'] = data['balance']\n",
    "            found = True\n",
    "            continue\n",
    "        \n",
    "        for symbol, inner in memory_symbols.items():\n",
    "            if symbol in avaiable_coins[coin] and 'EUR' in symbol:\n",
    "                balance = 0\n",
    "                if symbol.endswith(coin):\n",
    "                    price = (inner['askPrice_high'][epoch - 1 - deleted_symbol_data] + inner['askPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                    balance = data['balance'] / price\n",
    "                else:\n",
    "                    price = (inner['bidPrice_high'][epoch - 1 - deleted_symbol_data] + inner['bidPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                    balance = data['balance'] * price\n",
    "                    \n",
    "                euro += balance\n",
    "                holding_coins[coin]['balance_eur'] = balance\n",
    "                found = True\n",
    "                break\n",
    "        else:\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                similars = [\"BTC\", \"ETH\", \"BNB\", \"USDT\", \"BUSD\"]\n",
    "                if any(x in symbol for x in similars):\n",
    "                    new_currency = 0\n",
    "                    if symbol.endswith(coin):\n",
    "                        price = (memory_symbols[symbol]['askPrice_high'][epoch - 1 - deleted_symbol_data] + memory_symbols[symbol]['askPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                        new_currency = data['balance'] / price\n",
    "                    else:\n",
    "                        price = (memory_symbols[symbol]['bidPrice_high'][epoch - 1 - deleted_symbol_data] + memory_symbols[symbol]['bidPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                        new_currency = data['balance'] * price\n",
    "                    new_coin = symbol.replace(coin, '')\n",
    "                    \n",
    "                    # print(symbol, coin, new_coin) \n",
    "                    for symbol2 in memory_symbols.keys():\n",
    "                        if new_coin in avaiable_coins.keys():\n",
    "                            if symbol2 in avaiable_coins[new_coin] and 'EUR' in symbol2:\n",
    "                                balance = 0\n",
    "                                if symbol2.endswith(coin):\n",
    "                                    price = (memory_symbols[symbol2]['askPrice_high'][epoch - 1 - deleted_symbol_data] + memory_symbols[symbol2]['askPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                                    balance = new_currency / price\n",
    "                                else:\n",
    "                                    price = (memory_symbols[symbol2]['bidPrice_high'][epoch - 1 - deleted_symbol_data] + memory_symbols[symbol2]['bidPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                                    balance = new_currency * price\n",
    "                                    \n",
    "                                euro += balance\n",
    "                                holding_coins[coin]['balance_eur'] = balance\n",
    "                                found = True\n",
    "                                break\n",
    "                    else:\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "        if found == False:            \n",
    "          print('ALEED!!: convert_wallet_to_euro() | Couldnt resolve coin for trading euro:', coin)\n",
    "\n",
    "    # Cleanup low balances:\n",
    "    for coin in list(holding_coins.keys()):\n",
    "        if holding_coins[coin]['balance_eur'] < 5:\n",
    "            euro -= holding_coins[coin]['balance_eur']\n",
    "            del holding_coins[coin]\n",
    "\n",
    "    # For EUR profit plot:\n",
    "    eur_balance_agregated.append(euro)\n",
    "\n",
    "    return str(round(euro, 2)) + ' €'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiBXDbMQlU49"
   },
   "source": [
    "### processTrading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtAGU3cjlZLG"
   },
   "outputs": [],
   "source": [
    "def processTrading(predictions_byModel, current_epoch, memory_symbols):\n",
    "    global holding_coins, dont_update_holding_coins, dont_update_holding_coins_buffer, cancel_orders\n",
    "\n",
    "    coin_list = list(holding_coins.keys())\n",
    "    coins_minimum_limit = {}\n",
    "\n",
    "    for coin in coin_list:\n",
    "        if holding_coins[coin]['counting_epochs'] < 30:\n",
    "            coins_minimum_limit[coin] = minimum_prediction_prob_trade - (decrease_prob_trade_per_epoch_below_30_epochs * holding_coins[coin]['counting_epochs'])\n",
    "        else:\n",
    "            counting_epochs = holding_coins[coin]['counting_epochs'] - 30\n",
    "            if counting_epochs > 120:\n",
    "                coins_minimum_limit[coin] = 0\n",
    "            else:\n",
    "                coins_minimum_limit[coin] = minimum_prediction_prob_trade - (decrease_prob_trade_per_epoch_below_30_epochs * 30) - (decrease_prob_trade_per_epoch_above_30_epochs * counting_epochs)\n",
    "\n",
    "    print('_TRADING:')\n",
    "    for inner in predictions_byModel.values():\n",
    "        for coin, details in inner.items():\n",
    "            if coin in holding_coins.keys():\n",
    "                print(coin, details[0]['symbol'], str(round(details[0]['value'] * 100, 3)) + '%', '  ', '(>', str(round(100 * coins_minimum_limit[coin], 2)) + '%)')\n",
    "    print()\n",
    "\n",
    "    for coin in coin_list:\n",
    "        if coin not in predictions_byModel[model_name_for_trading].keys():\n",
    "            continue\n",
    "        if median_loss > trade_when_below_loss:\n",
    "            continue\n",
    "        if predictions_byModel[model_name_for_trading][coin][0]['value'] < coins_minimum_limit[coin]:\n",
    "            continue\n",
    "\n",
    "        symbol = predictions_byModel[model_name_for_trading][coin][0]['symbol']\n",
    "        buying_coin = symbol.replace(coin, '')\n",
    "\n",
    "        buying_quantity = None\n",
    "        price = None\n",
    "\n",
    "        if symbol.startswith(coin):\n",
    "            bidPrice_low = memory_symbols[symbol]['bidPrice_low'][current_epoch - 1 - deleted_symbol_data]\n",
    "            price = bidPrice_low\n",
    "            buying_quantity = holding_coins[coin]['balance'] * price\n",
    "        else:\n",
    "            askPrice_high = memory_symbols[symbol]['askPrice_high'][current_epoch - 1 - deleted_symbol_data]\n",
    "            price = askPrice_high\n",
    "            buying_quantity = holding_coins[coin]['balance'] / price\n",
    "\n",
    "        price = round_down(price, int(binance_symbols[symbol]['tickSize']))\n",
    "        buying_quantity = round_down(buying_quantity, 7)\n",
    "\n",
    "\n",
    "        trade = '--> Attempt Trading ' + str(holding_coins[coin]['balance']) + ' ' + coin + ' to ' + str(buying_quantity) + ' ' + buying_coin + \\\n",
    "                ' for ' + str(price) + '        [' + time.strftime(\"%H:%M:%S\") + ']'\n",
    "        print(trade)\n",
    "\n",
    "        trades_history[coin + '->' + buying_coin] = {\n",
    "            'text': coin + '->' + buying_coin,\n",
    "            'x': len(eur_balance_agregated) - 1,\n",
    "            'y': eur_balance_agregated[-1],\n",
    "        }\n",
    "\n",
    "\n",
    "        if do_real_money_trade:\n",
    "            #########################################################\n",
    "            #########################################################\n",
    "            #########################################################\n",
    "              \n",
    "            side = SIDE_BUY\n",
    "            order_quantity = buying_quantity\n",
    "            order_notional = holding_coins[coin]['balance']\n",
    "            if symbol.endswith(buying_coin):\n",
    "                side = SIDE_SELL\n",
    "                order_quantity = holding_coins[coin]['balance']\n",
    "                order_notional = buying_quantity\n",
    "\n",
    "            order_quantity = round_down(order_quantity, int(binance_symbols[symbol]['stepSizeInteger']))\n",
    "\n",
    "            if binance_symbols[symbol]['minNotional'] >= order_notional:\n",
    "                print('minNotional err', coin, binance_symbols[symbol]['minNotional'], order_quantity)\n",
    "                del holding_coins[coin]\n",
    "                if coin in dont_update_holding_coins:\n",
    "                    dont_update_holding_coins.remove(coin)\n",
    "                    del dont_update_holding_coins_buffer[coin]\n",
    "                print(coin + ' deleted from trading wallet.')\n",
    "                continue\n",
    "\n",
    "            limit_price = format(price, '.' + str(binance_symbols[symbol]['tickSize']) + 'f')\n",
    "            order_quantity = format(order_quantity, '.' + str(binance_symbols[symbol]['stepSizeInteger']) + 'f')\n",
    "\n",
    "            print(symbol, side, order_quantity, limit_price)\n",
    "        \n",
    "            success = False\n",
    "            try:\n",
    "                cancel_orders = True\n",
    "                order = binance.create_order(\n",
    "                    symbol=symbol,\n",
    "                    side=side,\n",
    "                    type=ORDER_TYPE_LIMIT,\n",
    "                    timeInForce=TIME_IN_FORCE_GTC,\n",
    "                    quantity=order_quantity,\n",
    "                    price=limit_price)\n",
    "                print(order)\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print('create_order err:', e.message)\n",
    "                if 'insufficient balance' in e.message or 'MIN_NOTIONAL' in e.message:\n",
    "                    if coin not in dont_update_holding_coins:\n",
    "                        if coin not in dont_update_holding_coins_buffer.keys():\n",
    "                            dont_update_holding_coins_buffer[coin] = 1\n",
    "                        else:\n",
    "                            dont_update_holding_coins_buffer[coin] += 1\n",
    "                            if dont_update_holding_coins_buffer[coin] > 2:\n",
    "                                dont_update_holding_coins.append(coin)\n",
    "                    else:\n",
    "                        holding_coins[coin]['balance'] -= binance_symbols[symbol]['stepSize']\n",
    "            ###\n",
    "            ########################################################\n",
    "\n",
    "            if success:\n",
    "                balance = buying_quantity\n",
    "                if buying_coin in holding_coins.keys():\n",
    "                    balance += holding_coins[buying_coin]['balance']\n",
    "\n",
    "                # Set the new acquired coin:\n",
    "                holding_coins[buying_coin] = {\n",
    "                    'balance': balance,\n",
    "                    'balance_eur': 1, \n",
    "                    'price': limit_price,\n",
    "                    'counting_epochs': 0,\n",
    "                    'symbol': symbol, \n",
    "                    'date': time.strftime('%H:%M:%S')\n",
    "                }\n",
    "\n",
    "                del holding_coins[coin]\n",
    "\n",
    "                if coin in dont_update_holding_coins:\n",
    "                    dont_update_holding_coins.remove(coin)\n",
    "                    del dont_update_holding_coins_buffer[coin]\n",
    "                    \n",
    "            print()\n",
    "\n",
    "    if median_loss < trade_when_below_loss:\n",
    "        for coin in holding_coins.keys():\n",
    "            holding_coins[coin]['counting_epochs'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down(value, decimals):\n",
    "    factor = 10 ** decimals\n",
    "    f = frac.Fraction(value)\n",
    "    return float(frac.Fraction(math.floor(f * factor),  factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2TD04LYP0V2"
   },
   "source": [
    "### trainModels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data_for_NN(training_list, y_train = None):\n",
    "    if y_train != None:\n",
    "\n",
    "        len_data = len(y_train)\n",
    "\n",
    "        training_list['coin'] = np.array(training_list['coin'], dtype = 'object')\n",
    "        training_list['coin'] = np.reshape(training_list['coin'], (len_data, 1))\n",
    "\n",
    "        training_list['symbol'] = np.array(training_list['symbol'], dtype = 'object')\n",
    "        training_list['symbol'] = np.reshape(training_list['symbol'], (len_data, 1))\n",
    "\n",
    "        training_list['time_numbers_input'] = np.array(training_list['time_numbers_input'], dtype = 'float32')\n",
    "        training_list['time_numbers_input'] = np.reshape(training_list['time_numbers_input'], (len_data, interval_columns, 8))\n",
    "\n",
    "        y_train = np.array(y_train, dtype = 'float32')\n",
    "        y_train = np.reshape(y_train, (len_data, 1))\n",
    "\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((training_list, y_train))\n",
    "        train_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size = nn_batch_size, count = nn_batch_size - 1))\n",
    "        train_ds = train_ds.batch(nn_batch_size, drop_remainder = True)\n",
    "        \n",
    "        return train_ds\n",
    "    \n",
    "    else:\n",
    "\n",
    "        len_data = len(training_list['coin'])\n",
    "\n",
    "        training_list['coin'] = np.array(training_list['coin'], dtype = 'object')\n",
    "        training_list['coin'] = np.reshape(training_list['coin'], (len_data, 1))\n",
    "\n",
    "        training_list['symbol'] = np.array(training_list['symbol'], dtype = 'object')\n",
    "        training_list['symbol'] = np.reshape(training_list['symbol'], (len_data, 1))\n",
    "\n",
    "        training_list['time_numbers_input'] = np.array(training_list['time_numbers_input'], dtype = 'float32')\n",
    "        training_list['time_numbers_input'] = np.reshape(training_list['time_numbers_input'], (len_data, interval_columns, 8))\n",
    "\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices(training_list)\n",
    "        train_ds = train_ds.repeat(nn_batch_size)\n",
    "        train_ds = train_ds.batch(nn_batch_size, drop_remainder = True)\n",
    "\n",
    "        return train_ds\n",
    "\n",
    "\n",
    "def do_warmup(training_list, y_train):\n",
    "\n",
    "    if use_models[\"NN\"] == 1:\n",
    "        time_now = time.time()\n",
    "        print(0)\n",
    "        model_name, model = create_model_nn('NNAction')\n",
    "        print(1, time.time() - time_now)\n",
    "        time_now = time.time()\n",
    "        training_ds = clean_data_for_NN(training_list, y_train)\n",
    "        print(2, time.time() - time_now)\n",
    "        time_now = time.time()\n",
    "        model.fit(training_ds,\n",
    "                epochs = nn_epochs,\n",
    "                verbose = 1)\n",
    "        print(model_name, 'Did warmup fit:', time.time() - time_now)\n",
    "\n",
    "    if use_models[\"CatBoost\"] == 1:\n",
    "        time_now = time.time()\n",
    "        print(0)\n",
    "        _, model = create_model_catboost('CatBoostAction')\n",
    "        print(1)\n",
    "        df = pd.DataFrame(training_list)\n",
    "        print(2)\n",
    "        model.fit(df, \n",
    "                y_train, \n",
    "                cat_features = categorial_features_indices, \n",
    "                verbose = True)\n",
    "        print(model_name, 'Did warmup:', time.time() - time_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3o7BpD-ZP1ce"
   },
   "outputs": [],
   "source": [
    "def trainModels(epoch, training_list, y_train):\n",
    "    global print_trained_string, saved_df_buffer, saved_y_buffer, time_train, nn_epochs\n",
    "\n",
    "    time_now = time.time()\n",
    "\n",
    "    if do_gather_dataset or use_models[\"CatBoost\"] == 1:\n",
    "        df = pd.DataFrame(training_list)\n",
    "        df = df.astype(dtype = features_dtypes)\n",
    "\n",
    "        if do_gather_dataset:\n",
    "            model_df_buffer_lock.acquire()\n",
    "            saved_df_buffer = pd.concat([saved_df_buffer, df])\n",
    "            saved_y_buffer += y_train\n",
    "            model_df_buffer_lock.release()\n",
    "\n",
    "    model_training_lock.acquire()\n",
    "    time_now = time.time()\n",
    "\n",
    "    if time_train < seconds_inbetween - 1 and time_big < seconds_inbetween - 1:\n",
    "        nn_epochs += 1\n",
    "    elif (time_train > seconds_inbetween - 0.5 or time_big > seconds_inbetween - 0.5) and nn_epochs > 1:\n",
    "        nn_epochs -= 1\n",
    "\n",
    "    if do_training and nn_epochs > 0:\n",
    "\n",
    "        if use_models[\"NN\"] == 1:\n",
    "            training_ds = clean_data_for_NN(training_list, y_train)\n",
    "            for model_name, model in models.items():\n",
    "                if \"NN\" in model_name:\n",
    "                    model.fit(training_ds,\n",
    "                            epochs = nn_epochs,\n",
    "                            verbose = do_training_verbose)\n",
    "        if use_models[\"CatBoost\"] == 1:\n",
    "            for model_name, model in models.items():\n",
    "                if \"CatBoost\" in model_name:\n",
    "                    model.fit(df, \n",
    "                            y_train, \n",
    "                            cat_features = categorial_features_indices, \n",
    "                            verbose = do_training_verbose)\n",
    "\n",
    "        if epoch % save_models_every_epochs == 0:\n",
    "            model_saving_lock.acquire()\n",
    "            save() # Save models\n",
    "            model_saving_lock.release()\n",
    "            print('Models saved.')\n",
    "\n",
    "    time_train = time.time() - time_now\n",
    "\n",
    "    model_training_lock.release()\n",
    "\n",
    "    print_trained_string = '[Trained ' + str(len(y_train)) + ' [' + str(round(time_train, 2)) + ' s]  ' + str(nn_epochs) + ' epochs ]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnK91M6QN-0Z"
   },
   "source": [
    "### save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kvDVMCMZBof"
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    global saved_df_buffer, saved_y_buffer\n",
    "    time_now = time.time()\n",
    "\n",
    "    if do_training:\n",
    "        for model_name, model in models.items():\n",
    "            if \"NN\" in model_name and use_models[\"NN\"] == 1:\n",
    "                try:\n",
    "                    model.save(root_dir + '/nn/' + model_name)\n",
    "                except Exception as e:\n",
    "                    print('SAVE FAILED:', model_name)\n",
    "                    print(e)\n",
    "            if \"CatBoost\" in model_name and use_models[\"CatBoost\"] == 1:\n",
    "                joblib.dump(model, root_dir + '/catboost/' + model_name)\n",
    "\n",
    "    if do_gather_dataset:\n",
    "        if model_df_buffer_lock.locked():\n",
    "            model_df_buffer_lock.acquire() #\n",
    "            saved_df_buffer = pd.DataFrame()\n",
    "            saved_y_buffer = []\n",
    "            model_df_buffer_lock.release() #\n",
    "            print('Aborted save df.', round(time.time() - time_now, 2), 's')\n",
    "        else:\n",
    "            time_string = str(round(time.time()))\n",
    "            model_df_buffer_lock.acquire() #\n",
    "            df_import = saved_df_buffer\n",
    "            saved_df_buffer = pd.DataFrame()\n",
    "            y_import = saved_y_buffer\n",
    "            saved_y_buffer = []\n",
    "            model_df_buffer_lock.release() #\n",
    "            df_import.to_csv(root_dir + '/' + datasets_dir + '/' + time_string + '.csv', index = False)\n",
    "            joblib.dump(y_import, root_dir + '/' + datasets_dir + '/' + time_string + '.csv.y')\n",
    "            print('Saved df to', datasets_dir, '. ', round(time.time() - time_now, 2), 's', '', len(df_import.index), len(y_import))\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cy1D3bhURrj7"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/nn/NNAction\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/nn/NNAction\\assets\n"
     ]
    }
   ],
   "source": [
    "# save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFIUOLfp79nD",
    "outputId": "a5dcc5f5-10a6-4135-f415-f962b432341d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------  Epoch:  2260   [18:58:53]\n",
      "\n",
      "[ 16.04 € ]   _ Balances:\n",
      "EUR 9.1528  9.15 €    |  Price: 0   | Epoch: 1969       [13:19:58]\n",
      "SOL 0.566  6.89 €    |  Price: 0   | Epoch: 1969       [13:19:58]\n",
      "\n",
      "_TRADING:\n",
      "EUR EURBUSD -8.743%    (> -352.8%)\n",
      "SOL SOLGBP -2.447%    (> -352.8%)\n",
      "\n",
      "--> Attempt Trading 9.152765000000002 EUR to 9.7065072 BUSD for 1.0604        [18:58:56]\n",
      "--> Attempt Trading 0.566 SOL to 5.9882799 GBP for 10.58        [18:58:56]\n",
      "binance.get_ticker() FAILED 1/2.\n",
      "_PAST:\n",
      "EUR _targets: EURUSDT  WINEUR          _pred:    WINEUR -0.05    EURBUSD -0.07    EURUSDT -0.09    BTCEUR -0.13    XRPEUR -0.22    XLMEUR -0.25    \n",
      "SOL _targets: SOLEUR  SOLBUSD  SOLUSDT  SOLBNB  SOLBTC  SOLETH          _pred:    SOLEUR 0.4    SOLBUSD 0.27    SOLETH 0.27    SOLBTC 0.23    SOLUSDT 0.22    SOLBNB 0.12    \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [82], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m schedule \u001b[39m=\u001b[39m sched\u001b[39m.\u001b[39mscheduler(time\u001b[39m.\u001b[39mtime, time\u001b[39m.\u001b[39msleep)\n\u001b[0;32m      3\u001b[0m \u001b[39mwhile\u001b[39;00m(\u001b[39m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     runner()\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNext episode\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn [65], line 31\u001b[0m, in \u001b[0;36mrunner\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     30\u001b[0m schedule\u001b[39m.\u001b[39menter((seconds_inbetween_pibeline \u001b[39m*\u001b[39m total_part_epochs) \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m init_time) \u001b[39m-\u001b[39m seconds_inbetween_pibeline, \u001b[39m1\u001b[39m, runner)\n\u001b[1;32m---> 31\u001b[0m schedule\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\sched.py:151\u001b[0m, in \u001b[0;36mscheduler.run\u001b[1;34m(self, blocking)\u001b[0m\n\u001b[0;32m    149\u001b[0m     delayfunc(time \u001b[39m-\u001b[39m now)\n\u001b[0;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     action(\u001b[39m*\u001b[39margument, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    152\u001b[0m     delayfunc(\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn [65], line 31\u001b[0m, in \u001b[0;36mrunner\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     30\u001b[0m schedule\u001b[39m.\u001b[39menter((seconds_inbetween_pibeline \u001b[39m*\u001b[39m total_part_epochs) \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m init_time) \u001b[39m-\u001b[39m seconds_inbetween_pibeline, \u001b[39m1\u001b[39m, runner)\n\u001b[1;32m---> 31\u001b[0m schedule\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\sched.py:151\u001b[0m, in \u001b[0;36mscheduler.run\u001b[1;34m(self, blocking)\u001b[0m\n\u001b[0;32m    149\u001b[0m     delayfunc(time \u001b[39m-\u001b[39m now)\n\u001b[0;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     action(\u001b[39m*\u001b[39margument, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    152\u001b[0m     delayfunc(\u001b[39m0\u001b[39m)\n",
      "    \u001b[1;31m[... skipping similar frames: runner at line 31 (343 times), scheduler.run at line 151 (342 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\sched.py:151\u001b[0m, in \u001b[0;36mscheduler.run\u001b[1;34m(self, blocking)\u001b[0m\n\u001b[0;32m    149\u001b[0m     delayfunc(time \u001b[39m-\u001b[39m now)\n\u001b[0;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     action(\u001b[39m*\u001b[39margument, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    152\u001b[0m     delayfunc(\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn [65], line 31\u001b[0m, in \u001b[0;36mrunner\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     30\u001b[0m schedule\u001b[39m.\u001b[39menter((seconds_inbetween_pibeline \u001b[39m*\u001b[39m total_part_epochs) \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m init_time) \u001b[39m-\u001b[39m seconds_inbetween_pibeline, \u001b[39m1\u001b[39m, runner)\n\u001b[1;32m---> 31\u001b[0m schedule\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\sched.py:149\u001b[0m, in \u001b[0;36mscheduler.run\u001b[1;34m(self, blocking)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m blocking:\n\u001b[0;32m    148\u001b[0m         \u001b[39mreturn\u001b[39;00m time \u001b[39m-\u001b[39m now\n\u001b[1;32m--> 149\u001b[0m     delayfunc(time \u001b[39m-\u001b[39;49m now)\n\u001b[0;32m    150\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    151\u001b[0m     action(\u001b[39m*\u001b[39margument, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------  346 [ 21.64 s == t: 0.8 + 1.91 + 0.01 + pT:4.88 + pA:1.8 | p: 1.32s/12e ]  ||  [Trained 2960 [5.04 s]  4 epochs ] |  Loss: 0.062 (P: 0.065 )    |  RAM: 7261 mb\n",
      "\n",
      "\n",
      "--------  Epoch:  2261   [18:59:14]\n",
      "\n",
      "[ 16.04 € ]   _ Balances:\n",
      "EUR 9.1528  9.15 €    |  Price: 0   | Epoch: 1970       [13:19:58]\n",
      "SOL 0.566  6.89 €    |  Price: 0   | Epoch: 1970       [13:19:58]\n",
      "\n",
      "_TRADING:\n",
      "EUR ETHEUR -6.94%    (> -353.0%)\n",
      "SOL SOLGBP 4.016%    (> -353.0%)\n",
      "\n",
      "--> Attempt Trading 9.152765000000002 EUR to 0.0081268 ETH for 1126.24        [18:59:17]\n",
      "--> Attempt Trading 0.566 SOL to 5.9882799 GBP for 10.58        [18:59:17]\n",
      "_PAST:\n",
      "EUR _targets: LTCEUR          _pred:    LTCEUR -0.11    ETHEUR -0.12    BNBEUR -0.12    BTCEUR -0.15    XRPEUR -0.31    SOLEUR -0.54    \n",
      "SOL _targets: SOLUSDT  SOLTRY  SOLBNB  SOLBTC  SOLBUSD  SOLEUR          _pred:    SOLBUSD 0.45    SOLUSDT 0.43    SOLEUR 0.39    SOLTRY 0.36    SOLBTC 0.32    SOLBNB -0.01    \n",
      "\n",
      "----------------  346 [ 24.81 s == t: 12.6 + 2.39 + 0.01 + pT:1.67 + pA:7.34 | p: 0.71s/12e ]  ||  [Trained 2960 [5.04 s]  4 epochs ] |  Loss: 0.063 (P: 0.065 )    |  RAM: 7232 mb\n",
      "\n",
      "\n",
      "Error in callback <function _draw_all_if_interactive at 0x0000025B746EA9D0> (for post_execute):--------  Epoch:  2262   [18:59:26]\n",
      "\n",
      "\n",
      "[ 16.04 € ]   _ Balances:\n",
      "EUR 9.1528  9.15 €    |  Price: 0   | Epoch: 1971       [13:19:58]\n",
      "SOL 0.566  6.89 €    |  Price: 0   | Epoch: 1971       [13:19:58]\n",
      "\n",
      "_TRADING:\n",
      "EUR EURBUSD -5.908%    (> -353.2%)\n",
      "SOL SOLUSDT 13.066%    (> -353.2%)\n",
      "\n",
      "--> Attempt Trading 9.152765000000002 EUR to 9.7065072 BUSD for 1.0604        [18:59:30]\n",
      "--> Attempt Trading 0.566 SOL to 7.3013999 USDT for 12.9        [18:59:30]\n",
      "_PAST:\n",
      "EUR _targets: NONE          _pred:    EURBUSD -0.07    TRXEUR -0.13    BNBEUR -0.2    ETHEUR -0.26    BTCEUR -0.28    XRPEUR -0.43    \n",
      "SOL _targets: SOLBTC  SOLBNB  SOLUSDT  SOLBUSD  SOLTRY  SOLETH          _pred:    SOLTRY 0.37    SOLETH 0.33    SOLUSDT 0.33    SOLBNB 0.33    SOLBUSD 0.3    SOLBTC 0.2    \n",
      "\n",
      "----------------  346 [ 23.7 s == t: 16.48 + 0.19 + 0.01 + pT:2.82 + pA:0.98 | p: 2.96s/12e ]  ||  [Trained 2960 [5.04 s]  4 epochs ] |  Loss: 0.062 (P: 0.065 )    |  RAM: 7286 mb\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\pyplot.py:119\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_draw_all_if_interactive\u001b[39m():\n\u001b[0;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m matplotlib\u001b[39m.\u001b[39mis_interactive():\n\u001b[1;32m--> 119\u001b[0m         draw_all()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\_pylab_helpers.py:132\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[1;34m(cls, force)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mfor\u001b[39;00m manager \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m    131\u001b[0m     \u001b[39mif\u001b[39;00m force \u001b[39mor\u001b[39;00m manager\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mstale:\n\u001b[1;32m--> 132\u001b[0m         manager\u001b[39m.\u001b[39;49mcanvas\u001b[39m.\u001b[39;49mdraw_idle()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2052\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_idle_drawing:\n\u001b[0;32m   2053\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idle_draw_cntx():\n\u001b[1;32m-> 2054\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdraw(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:405\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[0;32m    403\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[0;32m    404\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 405\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[0;32m    406\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    407\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\artist.py:74\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 74\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[0;32m     76\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\figure.py:3071\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3068\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3070\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3071\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3072\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3074\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[0;32m   3075\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py:3107\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3104\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m   3105\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[1;32m-> 3107\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3108\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3110\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   3111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\text.py:1982\u001b[0m, in \u001b[0;36mAnnotation.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1980\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1981\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_renderer \u001b[39m=\u001b[39m renderer\n\u001b[1;32m-> 1982\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_visible() \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_xy(renderer):\n\u001b[0;32m   1983\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1984\u001b[0m \u001b[39m# Update text positions before `Text.draw` would, so that the\u001b[39;00m\n\u001b[0;32m   1985\u001b[0m \u001b[39m# FancyArrowPatch is correctly positioned.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\text.py:1579\u001b[0m, in \u001b[0;36m_AnnotationBase._check_xy\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1576\u001b[0m \u001b[39mif\u001b[39;00m b \u001b[39mor\u001b[39;00m (b \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mxycoords \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   1577\u001b[0m     \u001b[39m# check if self.xy is inside the axes.\u001b[39;00m\n\u001b[0;32m   1578\u001b[0m     xy_pixel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_position_xy(renderer)\n\u001b[1;32m-> 1579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes\u001b[39m.\u001b[39;49mcontains_point(xy_pixel)\n\u001b[0;32m   1580\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\axes\\_base.py:4338\u001b[0m, in \u001b[0;36m_AxesBase.contains_point\u001b[1;34m(self, point)\u001b[0m\n\u001b[0;32m   4333\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcontains_point\u001b[39m(\u001b[39mself\u001b[39m, point):\n\u001b[0;32m   4334\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4335\u001b[0m \u001b[39m    Return whether *point* (pair of pixel coordinates) is inside the Axes\u001b[39;00m\n\u001b[0;32m   4336\u001b[0m \u001b[39m    patch.\u001b[39;00m\n\u001b[0;32m   4337\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4338\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpatch\u001b[39m.\u001b[39;49mcontains_point(point, radius\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\patches.py:202\u001b[0m, in \u001b[0;36mPatch.contains_point\u001b[1;34m(self, point, radius)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[39mReturn whether the given point is inside the patch.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m \n\u001b[0;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m radius \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_radius(radius)\n\u001b[1;32m--> 202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_path()\u001b[39m.\u001b[39;49mcontains_point(point,\n\u001b[0;32m    203\u001b[0m                                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_transform(),\n\u001b[0;32m    204\u001b[0m                                       radius)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\path.py:547\u001b[0m, in \u001b[0;36mPath.contains_point\u001b[1;34m(self, point, transform, radius)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39mtransform_path(\u001b[39mself\u001b[39m)\n\u001b[0;32m    546\u001b[0m     transform \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 547\u001b[0m \u001b[39mreturn\u001b[39;00m _path\u001b[39m.\u001b[39;49mpoint_in_path(point[\u001b[39m0\u001b[39;49m], point[\u001b[39m1\u001b[39;49m], radius, \u001b[39mself\u001b[39;49m, transform)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\matplotlib\\transforms.py:1773\u001b[0m, in \u001b[0;36mAffineBase.__array__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1771\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverted \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1773\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1774\u001b[0m     \u001b[39m# optimises the access of the transform matrix vs. the superclass\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_matrix()\n\u001b[0;32m   1777\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init()\n",
    "schedule = sched.scheduler(time.time, time.sleep)\n",
    "while(1):\n",
    "    runner()\n",
    "    print('Next episode')\n",
    "\n",
    "\n",
    "# Last folder size: 29.1mb\n",
    "\n",
    "# TODO:\n",
    "# Add volatility indicator per coin/symbol \n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "f1rbiuNnTOAt",
    "jOlkyfhOWYPz",
    "xGyza51MbQ8i",
    "F8t4j-VCVPv_",
    "TZMtPNjERlzE",
    "sjsTJIZxAlzA",
    "rwAVJm55CSR5",
    "f1uHH3AlgtLF",
    "Zhk559ZXlIPx",
    "6HtKD9Wrmxi0",
    "9WPpdhuugYQd",
    "dFk0gn6wjwRx",
    "wKOMrV86wxf6",
    "lEkAlPZfk7cZ",
    "eiBXDbMQlU49",
    "C2TD04LYP0V2",
    "OnK91M6QN-0Z"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m97"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff03dcfaa4ea4c7dbcc7a6acd2b5152b484988a1b13020911f06ea29377d1915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
