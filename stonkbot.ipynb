{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Men1oM4eRfAn"
   },
   "source": [
    "## Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGdtNx2iqNc-"
   },
   "source": [
    "#### Settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J75iPCI_qQkL"
   },
   "outputs": [],
   "source": [
    "\n",
    "start_over = False                                  # True will overwrite saved models with new models / False to Lock settings here.\n",
    "\n",
    "amount_of_symbols_per_coin_pred = 6                 # Symbols to predict per coin.\n",
    "aggregate_loss_history_epochs = 100                 # Calculate aggregated loss based on last X epochs\n",
    "\n",
    "minimum_prediction_prob_trade = 0.4                # Minimum 50% prediciton probability before taking trade action. \n",
    "decrease_prob_trade_per_epoch_below_30_epochs = 0.005\n",
    "decrease_prob_trade_per_epoch_above_30_epochs = 0.002\n",
    "\n",
    "trade_when_below_loss = 0.1\n",
    "binary_target_minimum_increase_min = 0.001               # Minimum 0.1 % increase.\n",
    "upscale_to_maximum_data_point_input = 0.03                # Upscale all model input data to be in real range: -3% to 3%.\n",
    "upscale_to_maximum_data_point_output = 0.01               # Upscale all model output data to be in real range: -1% to 1%.\n",
    "\n",
    "seconds_inbetween = 9                               # Seconds between handling training data.\n",
    "seconds_inbetween_pibeline = 3                      # Seconds between cycling the pibeline.\n",
    "\n",
    "pred_epoch = 20                                     # =  3    min    | Predict in how many epochs.\n",
    "interval_columns = 250                              # = 37.5  min    | Amount of epochs in history per sample.\n",
    "save_models_every_epochs = 300\n",
    "\n",
    "\n",
    "is_google_colab = False\n",
    "do_install_dependencies = False\n",
    "datasets_dir = 'datasets'\n",
    "\n",
    "\n",
    "\n",
    "real_wallet_dont_use_euro = 40\n",
    "\n",
    "do_real_money_trade = False   # prod: True\n",
    "do_training = True           # prod: True\n",
    "do_gather_dataset = False    # prod: False\n",
    "do_plots = True\n",
    "do_training_verbose = False\n",
    "\n",
    "\n",
    "use_models = {\n",
    "    'NN': True,\n",
    "    'CatBoost': False,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "nn_learning_rate = 0.0000003\n",
    "nn_batch_size = 200\n",
    "\n",
    "\n",
    "# 0.077\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1rbiuNnTOAt"
   },
   "source": [
    "### load_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqr5zV0_TOyj"
   },
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    global models, model_name_for_trading\n",
    "\n",
    "    if not exists(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    if not exists(root_dir + '/' + datasets_dir):\n",
    "        os.mkdir(root_dir + '/' + datasets_dir)\n",
    "\n",
    "    if use_models[\"CatBoost\"] == 1:\n",
    "        model_name_for_trading = 'CatBoostAction'\n",
    "        if not exists(root_dir + '/catboost'):\n",
    "            os.mkdir(root_dir + '/catboost')\n",
    "\n",
    "        for filename in os.listdir(root_dir + '/catboost/'):\n",
    "            if 'ipynb_checkpoints' in filename:\n",
    "                continue\n",
    "            if filename not in models.keys():\n",
    "                models[filename] = joblib.load(root_dir + '/catboost/' + filename)\n",
    "                model_name_for_trading = filename\n",
    "\n",
    "    if use_models[\"NN\"] == 1:\n",
    "        model_name_for_trading = 'NNAction'\n",
    "        if not exists(root_dir + '/nn'):\n",
    "            os.mkdir(root_dir + '/nn')\n",
    "            \n",
    "        for filename in os.listdir(root_dir + '/nn/'):\n",
    "            if 'ipynb_checkpoints' in filename:\n",
    "                continue\n",
    "            if filename not in models.keys():\n",
    "                models[filename] = tf.keras.models.load_model(root_dir + '/nn/' + filename)\n",
    "                model_name_for_trading = filename\n",
    "\n",
    "\n",
    "    models = sorted(models.items(), key=lambda x: x[0], reverse=False)\n",
    "    models = {k: v for k, v in models}\n",
    "\n",
    "    for model_name, _ in models.items():\n",
    "        print('The holy ' + model_name + ' model has loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOlkyfhOWYPz"
   },
   "source": [
    "### create_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WkttSkCNWZ2z"
   },
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    global did_fit, do_predictions, losses_agregated, losses_agregated_positives, model_name_for_trading\n",
    "\n",
    "    if len(models.keys()) == 0 or start_over:\n",
    "        if use_models[\"NN\"] == 1:\n",
    "            model_name, model = create_model_nn('NNAction')\n",
    "            models[model_name] = model\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "            \n",
    "            # model.summary()\n",
    "            keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "            model_name_for_trading = model_name\n",
    "            print(model_name + ' model created!')\n",
    "\n",
    "        if use_models[\"CatBoost\"] == 1:\n",
    "            model_name, model = create_model_catboost('CatBoostAction')\n",
    "            models[model_name] = model\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "            model_name_for_trading = model_name\n",
    "            print(model_name + ' model created!')\n",
    "\n",
    "        did_fit = False\n",
    "        do_predictions = False\n",
    "    else:\n",
    "        for model_name in models.keys():\n",
    "            losses_agregated[model_name] = []\n",
    "            losses_agregated_positives[model_name] = []\n",
    "\n",
    "\n",
    "def create_model_nn(name):\n",
    "    coin_input = keras.Input(batch_shape=(nn_batch_size, 1,), name = 'coin', dtype='string')\n",
    "    symbol_input = keras.Input(batch_shape=(nn_batch_size, 1,), name = 'symbol', dtype='string')\n",
    "    time_numbers_input = keras.Input(batch_shape=(nn_batch_size, interval_columns, 8), name = 'time_numbers_input')\n",
    "    inputs = [\n",
    "        coin_input,\n",
    "        symbol_input,\n",
    "        time_numbers_input\n",
    "    ]\n",
    "\n",
    "    normalizer = layers.StringLookup(vocabulary=list(avaiable_coins.keys()), output_mode='one_hot')\n",
    "    coin = normalizer(coin_input)\n",
    "    \n",
    "    normalizer = layers.StringLookup(vocabulary=avaiable_symbols_list, output_mode='one_hot')\n",
    "    symbol = normalizer(symbol_input)\n",
    "\n",
    "\n",
    "    lstm = layers.LSTM(100, stateful = True, return_sequences = True)(time_numbers_input)\n",
    "    lstm = layers.Dropout(0.3)(lstm)\n",
    "    lstm = layers.LSTM(100, stateful = True, return_sequences = False)(lstm)\n",
    "    lstm = layers.Dropout(0.3)(lstm)\n",
    "    lstm = keras.Model(time_numbers_input, lstm)\n",
    "    \n",
    "    time_numbers_input_flattened = layers.Flatten()(time_numbers_input)\n",
    "    dense = layers.concatenate([time_numbers_input_flattened, coin, symbol])\n",
    "    dense = layers.Dense(100, kernel_constraint = max_norm(4))(dense)\n",
    "    dense = layers.Dropout(0.3)(dense)\n",
    "    dense = keras.Model(inputs, dense)\n",
    "    \n",
    "    main = layers.concatenate([lstm.output, dense.output])\n",
    "    main = layers.Dense(100, kernel_constraint = max_norm(3))(main)\n",
    "    main = layers.Dropout(0.3)(main)\n",
    "    main = layers.Dense(100, kernel_constraint = max_norm(3))(main)\n",
    "    main = layers.Dropout(0.3)(main)\n",
    "    main = layers.Dense(100, kernel_constraint = max_norm(2))(main)\n",
    "\n",
    "    output = layers.Dense(1, activation = 'tanh')(main)\n",
    "\n",
    "\n",
    "    model = keras.Model(inputs, output, name=name)\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(\n",
    "            learning_rate = nn_learning_rate\n",
    "        ),\n",
    "        loss = tf.keras.losses.SquaredHinge(),\n",
    "    )\n",
    "    \n",
    "    return name, model\n",
    "\n",
    "def create_model_catboost(name):\n",
    "\n",
    "    catboost_iterations = 7\n",
    "    catboost_depth = 10\n",
    "    catboost_learning_rate = 0.10\n",
    "    catboost_one_hot_max_size = 0\n",
    "    catboost_ctr_target_border_count = 50\n",
    "    catboost_model_size_reg = 0\n",
    "    catboost_max_ctr_complexity = 0\n",
    "    catboost_l2_leaf_reg = None\n",
    "    catboost_min_data_in_leaf = None\n",
    "    catboost_random_strength = None\n",
    "    catboost_bootstrap_type = 'Bernoulli'\n",
    "    catboost_subsample = 0.5\n",
    "    catboost_bagging_temperature = None\n",
    "\n",
    "    param = {\n",
    "        \"iterations\": catboost_iterations,\n",
    "        \"depth\": catboost_depth,\n",
    "        'learning_rate': catboost_learning_rate,\n",
    "        \"one_hot_max_size\": catboost_one_hot_max_size,\n",
    "        \"ctr_target_border_count\": catboost_ctr_target_border_count,\n",
    "        \"model_size_reg\": catboost_model_size_reg,\n",
    "        \"max_ctr_complexity\": catboost_max_ctr_complexity,\n",
    "        'l2_leaf_reg': catboost_l2_leaf_reg,\n",
    "        'min_data_in_leaf': catboost_min_data_in_leaf,\n",
    "        'random_strength': catboost_random_strength,\n",
    "        \"bootstrap_type\": catboost_bootstrap_type,\n",
    "\n",
    "        \"objective\": \"MultiClass\",\n",
    "        \"allow_const_label\": True,\n",
    "        \"task_type\": \"GPU\", \n",
    "        \"has_time\": True, \n",
    "        \"class_names\": possible_labels,\n",
    "        \"random_state\": 420,\n",
    "        \"allow_writing_files\": False,\n",
    "        \"boosting_type\": \"Plain\",\n",
    "    }\n",
    "    if catboost_bootstrap_type == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = catboost_bagging_temperature\n",
    "    elif catboost_bootstrap_type == \"Bernoulli\":\n",
    "        param[\"subsample\"] = catboost_subsample\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "\n",
    "    return name, model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGyza51MbQ8i",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### populate_coins_to_pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMaypnE0AUsi"
   },
   "outputs": [],
   "source": [
    "def validateActiveTickerSymbol(ticker):\n",
    "    if float(ticker['lastPrice']) < 0.0000001 or float(ticker['bidPrice']) < 0.0000001 or float(ticker['askPrice']) < 0.0000001:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def populate_coins_to_pairs():\n",
    "    global avaiable_coins, avaiable_symbols_list\n",
    "    avaiable_coins = {}\n",
    "    avaiable_symbols_list = []\n",
    "\n",
    "    balances = binance.get_account()['balances']\n",
    "    tickers = binance.get_ticker() # All symbol info\n",
    "\n",
    "\n",
    "    for balance in balances:\n",
    "        coin = balance['asset']\n",
    "        avaiable_coins[coin] = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if not validateActiveTickerSymbol(ticker):\n",
    "            continue\n",
    "        symbol = ticker['symbol']\n",
    "\n",
    "        found = False\n",
    "        for balance in balances:\n",
    "            coin = balance['asset']\n",
    "            if isCoinPairMatching(coin, symbol):\n",
    "              avaiable_coins[coin].append(symbol)\n",
    "              found = True\n",
    "        if found:\n",
    "            avaiable_symbols_list.append(symbol)\n",
    "\n",
    "def isCoinPairMatching(coin, symbol):\n",
    "    if coin not in symbol:\n",
    "        return False\n",
    "    \n",
    "    symbols = [\"BTCUP\", \"BTCDOWN\", \"ADAUP\", \"ADADOWN\", \"ETHUP\", \"ETHDOWN\", \"DOTUP\", \"DOTDOWN\", \"TRXUP\", \"TRXDOWN\", \"LINKUP\", \"LINKDOWN\", \\\n",
    "                \"BNBUP\", \"BNBDOWN\", \"CRH\"]\n",
    "    if any(x in symbol for x in symbols):\n",
    "        return False\n",
    "\n",
    "    if coin == 'AMB':\n",
    "        similars = [\"CREAMBUSD\", \"BEAM\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False \n",
    "    elif coin == 'AUD':\n",
    "        similars = [\"AUDIO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TRU':\n",
    "        similars = [\"ASTRUSDT\", \"USDTRUB\", \"DOT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TUSD':\n",
    "        similars = [\"TUSDT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GAL':\n",
    "        similars = [\"GALA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'BTC':\n",
    "        similars = [\"BTCST\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'OG':\n",
    "        similars = [\"DOGE\", \"OGN\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'COS':\n",
    "        similars = [\"COCOS\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'RUB':\n",
    "        similars = [\"TRUBTC\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'SHIB':\n",
    "        similars = [\"SUSHIBTC\", \"SUSHIBUSD\", \"SUSHIBNB\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'FET':\n",
    "        similars = [\"ELFETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'YFI':\n",
    "        similars = [\"YFII\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TRB':\n",
    "        similars = [\"ASTRBTC\", \"ASTRBUSD\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'BAR':\n",
    "        similars = [\"HBAR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'SC':\n",
    "        similars = [\"SCRT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'REP':\n",
    "        similars = [\"DREP\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GO':\n",
    "        similars = [\"AERGO\", \"ALGO\", \"DEGO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AST':\n",
    "        similars = [\"ASTR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AST':\n",
    "        similars = [\"CRVETH\", \"SSVETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ONE':\n",
    "        similars = [\"AIONETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GLM':\n",
    "        similars = [\"GLMR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'DAR':\n",
    "        similars = [\"ADARUB\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'VET':\n",
    "        similars = [\"CRVETH\", \"SSVETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OXT':\n",
    "        similars = [\"MBOXTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'ACA':\n",
    "        similars = [\"ALPACA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ONT':\n",
    "        similars = [\"FRONT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TCT':\n",
    "        similars = [\"BTCTUSD\", \"BTTCTRY\", \"BTCTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'AMP':\n",
    "        similars = [\"RAMP\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'WBTC':\n",
    "        similars = [\"FLOWBTC\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'LPT':\n",
    "        similars = [\"SLPTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'PHA':\n",
    "        similars = [\"ALPHA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AVA':\n",
    "        similars = [\"KAVA\", \"AVAX\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'MOB':\n",
    "        similars = [\"TOMO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'ORN':\n",
    "        similars = [\"TORN\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OM':\n",
    "        similars = [\"OMG\", \"ATOM\", \"COMP\", \"LOOM\", \"TOMO\", \"PROM\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'AR':\n",
    "        similars = [\"ARDR\", \"ARK\", \"ARPA\", \"BAR\", \"FARM\", \"HARD\", \"HBAR\", \"NEAR\", \"RARE\", \"DAR\", \"SPARTA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ATA':\n",
    "        similars = [\"DATA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ANT':\n",
    "        similars = [\"SANTOS\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'WIN':\n",
    "        similars = [\"WING\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'BUSD':\n",
    "        similars = [\"BNBUSDC\", \"TRBUSDT\", \"MOBUSDT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OP':\n",
    "        similars = [\"PEOPLE\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'FOR':\n",
    "        similars = [\"FORTH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'CKB':\n",
    "        similars = [\"DOCK\", \"QUICK\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin in ['BETH', 'BDOT', 'T']:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8t4j-VCVPv_",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### initBinanceInfo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hwLwVhYLVRg9"
   },
   "outputs": [],
   "source": [
    "def initBinanceInfo():\n",
    "    global binance_symbols\n",
    "\n",
    "    get_exchange_info = binance.get_exchange_info()\n",
    "    for symbol in get_exchange_info['symbols']:\n",
    "        if symbol['symbol'] in avaiable_symbols_list:\n",
    "            stepSize = 0\n",
    "            stepSizeInteger = 0\n",
    "            tickSize = 0\n",
    "            minNotional = 0\n",
    "            for filter in symbol['filters']:\n",
    "                if filter['filterType'] == 'LOT_SIZE':\n",
    "                    stepSize = float(filter['stepSize'])\n",
    "                    if filter['stepSize'] == '0.10000000':\n",
    "                        stepSizeInteger = 1\n",
    "                    elif filter['stepSize'] == '0.01000000':\n",
    "                        stepSizeInteger = 2\n",
    "                    elif filter['stepSize'] == '0.00100000':\n",
    "                        stepSizeInteger = 3\n",
    "                    elif filter['stepSize'] == '0.00010000':\n",
    "                        stepSizeInteger = 4\n",
    "                    elif filter['stepSize'] == '0.00001000':\n",
    "                        stepSizeInteger = 5\n",
    "                    elif filter['stepSize'] == '0.00000100':\n",
    "                        stepSizeInteger = 6\n",
    "                    elif filter['stepSize'] == '0.00000010':\n",
    "                        stepSizeInteger = 7\n",
    "                    elif filter['stepSize'] == '0.00000001':\n",
    "                        stepSizeInteger = 8\n",
    "                elif filter['filterType'] == 'PRICE_FILTER':\n",
    "                    if filter['tickSize'] == '0.10000000':\n",
    "                        tickSize = 1\n",
    "                    elif filter['tickSize'] == '0.01000000':\n",
    "                        tickSize = 2\n",
    "                    elif filter['tickSize'] == '0.00100000':\n",
    "                        tickSize = 3\n",
    "                    elif filter['tickSize'] == '0.00010000':\n",
    "                        tickSize = 4\n",
    "                    elif filter['tickSize'] == '0.00001000':\n",
    "                        tickSize = 5\n",
    "                    elif filter['tickSize'] == '0.00000100':\n",
    "                        tickSize = 6\n",
    "                    elif filter['tickSize'] == '0.00000010':\n",
    "                        tickSize = 7\n",
    "                    elif filter['tickSize'] == '0.00000001':\n",
    "                        tickSize = 8\n",
    "                elif filter['filterType'] == 'MIN_NOTIONAL':\n",
    "                    minNotional = float(filter['minNotional'])\n",
    "\n",
    "            binance_symbols[symbol['symbol']] = {\n",
    "                'stepSize': stepSize,\n",
    "                'stepSizeInteger': stepSizeInteger,\n",
    "                'tickSize': tickSize,\n",
    "                'minNotional': minNotional,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZMtPNjERlzE"
   },
   "source": [
    "### init_meta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J-bgr9_RQOz",
    "outputId": "3bbd267c-d865-4946-e2b2-59e3eeb38f20"
   },
   "outputs": [],
   "source": [
    "root_dir = 'models' \n",
    "categorial_features = ['symbol', 'coin']    # 'direction_', \n",
    "\n",
    "if is_google_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    root_dir = 'drive/MyDrive/tradebot'\n",
    "\n",
    "if is_google_colab or do_install_dependencies:\n",
    "    !pip install catboost\n",
    "    !pip install python-binance\n",
    "    !pip install tensorflow\n",
    "\n",
    "import os, psutil\n",
    "from os.path import exists\n",
    "\n",
    "from catboost import *\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from binance import Client\n",
    "from binance.enums import *\n",
    "\n",
    "import sched, time\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from threading import Thread, Lock\n",
    "import numpy as np\n",
    "\n",
    "import fractions as frac\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "models = {}\n",
    "categorial_features_indices = None\n",
    "holding_coins = None\n",
    "holding_coins_DEFAULT = {\n",
    "    'balance': 0,\n",
    "    'balance_eur': 1,\n",
    "    'price': 0,\n",
    "    'counting_epochs': 0,\n",
    "    'symbol': '',\n",
    "    'date': time.strftime(\"%H:%M:%S\")\n",
    "}\n",
    "features_list = None\n",
    "features_dtypes = None\n",
    "avaiable_coins = None\n",
    "avaiable_symbols_list = None\n",
    "\n",
    "possible_labels = ['NONE']\n",
    "for i in range(0, amount_of_symbols_per_coin_pred):\n",
    "    possible_labels.append(str(i))\n",
    "\n",
    "binance_api_key = 'AoVFfn3JvetSRHpffstx9tg0Zlmzc6WHeAdVjVUnLfbzOTslBanPUMFa7bP4CqtU'\n",
    "binance_api_secret = 'zNGuMcE2UcycFQeVhTi5o9psM6GjZHvg7gEcTu1f8pazQg42EAMgvma5G583wv4G'\n",
    "binance = Client(binance_api_key, binance_api_secret)\n",
    "\n",
    "##### :\n",
    "epoch, part_epoch, total_part_epochs = 1, 1, 0\n",
    "memory_data = []\n",
    "memory_symbols = {}\n",
    "predictions_saved = []\n",
    "deleted_symbol_data = 0\n",
    "print_trained_string = '---'\n",
    "loss_string = '-'\n",
    "model_training_lock = None\n",
    "model_df_buffer_lock = None\n",
    "handleTickers_lock = None\n",
    "model_saving_lock = None\n",
    "binance_symbols = {} #\n",
    "dont_update_holding_coins = []\n",
    "dont_update_holding_coins_buffer = {}\n",
    "cancel_orders = False\n",
    "temp_tickers = {}\n",
    "do_predictions = True\n",
    "saved_df_buffer = pd.DataFrame()\n",
    "saved_y_buffer = []\n",
    "init_time = None\n",
    "did_fit = True\n",
    "losses_agregated = {}\n",
    "losses_agregated_positives = {}\n",
    "eur_balance_agregated = []\n",
    "trades_history = {}\n",
    "median_loss = 1\n",
    "median_loss_positives = 1\n",
    "time_train = seconds_inbetween - 2\n",
    "time_big = seconds_inbetween - 2\n",
    "model_name_for_trading = ''\n",
    "nn_epochs = 1  # Dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NN:\n",
    "\n",
    "categorical_encoder = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    ")\n",
    "preprocessor = make_column_transformer(\n",
    "    (categorical_encoder, make_column_selector(dtype_include=object)),\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XiN8nxrY1HI",
    "outputId": "d04b8f43-43d0-40dd-cfb1-614f5cc0813e"
   },
   "outputs": [],
   "source": [
    "populate_coins_to_pairs()\n",
    "initBinanceInfo()\n",
    "# create_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AzHvj-pYFMJ"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjsTJIZxAlzA"
   },
   "source": [
    "### Init:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuFLPr_78efB"
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    global holding_coins, do_predictions, model_training_lock, model_df_buffer_lock, \\\n",
    "    epoch, part_epoch, total_part_epochs, memory_data, memory_symbols, predictions_saved, \\\n",
    "    deleted_symbol_data, print_trained_string, loss_string, saved_y_buffer, \\\n",
    "    dont_update_holding_coins, dont_update_holding_coins_buffer, \\\n",
    "    cancel_orders, temp_tickers, saved_df_buffer, \\\n",
    "    handleTickers_lock, model_saving_lock, init_time\n",
    "\n",
    "    initBinanceInfo()\n",
    "\n",
    "    epoch, part_epoch, total_part_epochs = 1, 1, 0\n",
    "    memory_data = []\n",
    "    memory_symbols = {}\n",
    "    predictions_saved = []\n",
    "    deleted_symbol_data = 0\n",
    "    print_trained_string = '---'\n",
    "    loss_string = '-'\n",
    "    model_training_lock = None\n",
    "    model_df_buffer_lock = None\n",
    "    handleTickers_lock = None\n",
    "    dont_update_holding_coins = []\n",
    "    dont_update_holding_coins_buffer = {}\n",
    "    cancel_orders = False\n",
    "    temp_tickers = {}\n",
    "    do_predictions = True\n",
    "    saved_df_buffer = pd.DataFrame()\n",
    "    saved_y_buffer = []\n",
    "    init_time = time.time()\n",
    "    holding_coins = {}\n",
    "\n",
    "    model_training_lock = Lock()\n",
    "    model_df_buffer_lock = Lock()\n",
    "    handleTickers_lock = Lock()\n",
    "    model_saving_lock = Lock()\n",
    "\n",
    "    print(\"\"\"\\\n",
    "                        ._ o o\n",
    "                        \\_`-)|_\n",
    "                      ,\"\"       \\ \n",
    "                    ,\"  ## |   = ಠ. \n",
    "                  ,\" ##   ,-\\__    `.\n",
    "                ,\"       /     `--._;)\n",
    "              ,\"     ## /\n",
    "            ,\"   ##    /\n",
    "███████╗████████╗ ██████╗ ███╗   ██╗██╗  ██╗██████╗  ██████╗ ████████╗\n",
    "██╔════╝╚══██╔══╝██╔═══██╗████╗  ██║██║ ██╔╝██╔══██╗██╔═══██╗╚══██╔══╝\n",
    "███████╗   ██║   ██║   ██║██╔██╗ ██║█████╔╝ ██████╔╝██║   ██║   ██║   \n",
    "╚════██║   ██║   ██║   ██║██║╚██╗██║██╔═██╗ ██╔══██╗██║   ██║   ██║   \n",
    "███████║   ██║   ╚██████╔╝██║ ╚████║██║  ██╗██████╔╝╚██████╔╝   ██║   \n",
    "╚══════╝   ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚═╝  ╚═╝╚═════╝  ╚═════╝    ╚═╝   v0.4\n",
    "                                                                      \n",
    "                    \"\"\")\n",
    "    print()\n",
    "    load_models()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwAVJm55CSR5"
   },
   "source": [
    "### Runner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uZ0wly0CZA9"
   },
   "outputs": [],
   "source": [
    "def runner():\n",
    "    global schedule, epoch, part_epoch, total_part_epochs, init_time\n",
    "    time_now = time.time()\n",
    "    \n",
    "    getTickers(part_epoch)\n",
    "\n",
    "    if part_epoch == (seconds_inbetween / seconds_inbetween_pibeline) - 1:\n",
    "        thread = Thread(target = updateBinanceBalances)\n",
    "        thread.start()\n",
    "\n",
    "    if seconds_inbetween / seconds_inbetween_pibeline <= part_epoch:\n",
    "        processTickers()\n",
    "        thread = Thread(target = handleTickers, args = (time_now, epoch, memory_symbols,))\n",
    "        thread.start()\n",
    "        epoch += 1\n",
    "        part_epoch = 0\n",
    "    part_epoch += 1\n",
    "    total_part_epochs += 1\n",
    "    # 459: 6 sec break..\n",
    "    if total_part_epochs == 460:\n",
    "        sleepy = (seconds_inbetween_pibeline * total_part_epochs) - (time.time() - init_time) - seconds_inbetween_pibeline + 2.5\n",
    "        if sleepy < 0:\n",
    "          sleepy = 0\n",
    "        print('sleepy', sleepy)\n",
    "        time.sleep(sleepy)\n",
    "        init_time = time.time()\n",
    "        total_part_epochs = 0\n",
    "        return\n",
    "\n",
    "    schedule.enter((seconds_inbetween_pibeline * total_part_epochs) - (time.time() - init_time) - seconds_inbetween_pibeline, 1, runner)\n",
    "    schedule.run()\n",
    "\n",
    "def getTickers(part_epoch):\n",
    "  global temp_tickers\n",
    "\n",
    "  try:\n",
    "      tickers = binance.get_ticker() # All symbol info\n",
    "  except:\n",
    "      print('binance.get_ticker() FAILED 1/2.')\n",
    "      try:\n",
    "          tickers = binance.get_ticker() # All symbol info\n",
    "      except:\n",
    "          print('binance.get_ticker() FAILED 2/2.')\n",
    "          return\n",
    "  \n",
    "  if part_epoch == 1:\n",
    "      for symbol in tickers:\n",
    "          if symbol['symbol'] not in avaiable_symbols_list:\n",
    "              continue\n",
    "          temp_tickers[symbol['symbol']] = {\n",
    "              'bidPrice_low': float(symbol['bidPrice']),\n",
    "              'bidPrice_high': float(symbol['bidPrice']),\n",
    "              'askPrice_low': float(symbol['askPrice']),\n",
    "              'askPrice_high': float(symbol['askPrice']),\n",
    "              'volume': float(symbol['volume']),\n",
    "              'quoteVolume': float(symbol['quoteVolume']),\n",
    "              'tradeCount': int(symbol['count']),\n",
    "              'lastPrice': float(symbol['lastPrice']),\n",
    "          }\n",
    "        \n",
    "  else:\n",
    "      for symbol in tickers:\n",
    "          if symbol['symbol'] not in avaiable_symbols_list:\n",
    "              continue\n",
    "        \n",
    "          new_bidPrice = float(symbol['bidPrice'])\n",
    "          new_askPrice = float(symbol['askPrice'])\n",
    "          \n",
    "          temp_tickers[symbol['symbol']] = {\n",
    "              'bidPrice_low': new_bidPrice if temp_tickers[symbol['symbol']]['bidPrice_low'] > new_bidPrice else temp_tickers[symbol['symbol']]['bidPrice_low'],\n",
    "              'bidPrice_high': new_bidPrice if temp_tickers[symbol['symbol']]['bidPrice_high'] < new_bidPrice else temp_tickers[symbol['symbol']]['bidPrice_high'],\n",
    "              'askPrice_low': new_askPrice if temp_tickers[symbol['symbol']]['askPrice_low'] > new_askPrice else temp_tickers[symbol['symbol']]['askPrice_low'],\n",
    "              'askPrice_high': new_askPrice if temp_tickers[symbol['symbol']]['askPrice_high'] < new_askPrice else temp_tickers[symbol['symbol']]['askPrice_high'],\n",
    "              'volume': float(symbol['volume']),\n",
    "              'quoteVolume': float(symbol['quoteVolume']),\n",
    "              'tradeCount': int(symbol['count']),\n",
    "              'lastPrice': float(symbol['lastPrice']),\n",
    "          }\n",
    "\n",
    "def processTickers():\n",
    "    global memory_symbols\n",
    "    for symbol, values in temp_tickers.items():\n",
    "        if symbol not in memory_symbols:\n",
    "            memory_symbols[symbol] = {\n",
    "                'bidPrice_low': [],\n",
    "                'bidPrice_high': [],\n",
    "                'askPrice_low': [],\n",
    "                'askPrice_high': [],\n",
    "                'volume': [],\n",
    "                'quoteVolume': [],\n",
    "                'tradeCount': [],\n",
    "                'lastPrice': [],\n",
    "            }\n",
    "        memory_symbols[symbol]['bidPrice_low'].append(values['bidPrice_low'])\n",
    "        memory_symbols[symbol]['bidPrice_high'].append(values['bidPrice_high'])\n",
    "        memory_symbols[symbol]['askPrice_low'].append(values['askPrice_low'])\n",
    "        memory_symbols[symbol]['askPrice_high'].append(values['askPrice_high'])\n",
    "        memory_symbols[symbol]['volume'].append(values['volume'])\n",
    "        memory_symbols[symbol]['quoteVolume'].append(values['quoteVolume'])\n",
    "        memory_symbols[symbol]['tradeCount'].append(values['tradeCount'])\n",
    "        memory_symbols[symbol]['lastPrice'].append(values['lastPrice'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1uHH3AlgtLF"
   },
   "source": [
    "### MAIN Thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JA60IEuagyml"
   },
   "outputs": [],
   "source": [
    "def handleTickers(time_now_big, epoch, memory_symbols):\n",
    "    global memory_data, deleted_symbol_data, print_trained_string, do_predictions, \\\n",
    "    predictions_saved, handleTickers_Lock, categorial_features_indices, features_dtypes, features_list, \\\n",
    "    time_big\n",
    "\n",
    "    memory_data_symbol = None\n",
    "    predictions_byModel = (\n",
    "        {},\n",
    "        '0',\n",
    "    )\n",
    "    \n",
    "    handleTickers_lock.acquire() #\n",
    "    if do_plots and epoch % 4 == 0:\n",
    "        clear_output(wait=True)\n",
    "    print('--------  Epoch: ', epoch, '  [' + str(time.strftime(\"%H:%M:%S\")) + ']')\n",
    "    print()\n",
    "\n",
    "    # Proccess coin data\n",
    "    proccessTickers_time = ''\n",
    "    if epoch > 1:\n",
    "        # Get list of symbols to check:\n",
    "        use_symbols = []\n",
    "        for coin in holding_coins.keys():\n",
    "            use_symbols += avaiable_coins[coin]\n",
    "            \n",
    "        time_big_itcp = time.time() - time_now_big\n",
    "        time_now = time.time()\n",
    "        memory_data_symbol = proccessTickers(epoch, memory_symbols, True, use_symbols)\n",
    "        proccessTickers_time = str(round(time_big_itcp, 2)) + ' + ' + str(round(time.time() - time_now, 2))\n",
    "\n",
    "    # Balances and euro:\n",
    "    print_eur_string = convert_wallet_to_euro(holding_coins, memory_symbols, epoch)\n",
    "    print('[ ' + print_eur_string + ' ]   _ Balances:')\n",
    "    for coin, inner in holding_coins.items():\n",
    "        print(coin, str(round(inner['balance'], 4)), '', str(round(inner['balance_eur'], 2)) + ' €', '   |  Price: ' + str(inner['price']) + ' ' + inner['symbol'] + '  | Epoch: ' + str(inner['counting_epochs']) + '       [' + inner['date'] + ']')\n",
    "    print()\n",
    "\n",
    "    if epoch > pred_epoch:\n",
    "        # Process Action Data\n",
    "        time_now = time.time()\n",
    "        saved, coins = processActionData(memory_data_symbol, True)\n",
    "        proccessTickers_time += ' + ' + str(round(time.time() - time_now, 2))\n",
    "\n",
    "        ## Init Set features_dtypes & categorial_features_indices ##\n",
    "        if epoch == pred_epoch + 1:\n",
    "            features_list = list(saved[0].keys())\n",
    "            features_dtypes = {}\n",
    "            categorial_features_indices = []\n",
    "            i = 0\n",
    "            for feature in features_list:\n",
    "                if any(x in feature for x in categorial_features):\n",
    "                    categorial_features_indices.append(i)\n",
    "                i += 1\n",
    "                if 'symbol' in feature or 'coin' in feature:    #  or 'direction_' in feature\n",
    "                    features_dtypes[feature] = 'string'\n",
    "                else:\n",
    "                    features_dtypes[feature] = 'float32'\n",
    "        ####\n",
    "\n",
    "        if do_predictions and len(holding_coins.keys()) > 0:\n",
    "            # Do Predictions:\n",
    "            predictions_byModel = proccessPredictions(saved, coins)\n",
    "    \n",
    "            # Trade coins:\n",
    "            if do_predictions and epoch > interval_columns + pred_epoch + 20:\n",
    "                processTrading(predictions_byModel[0], epoch, memory_symbols)\n",
    "            #\n",
    "\n",
    "    # Now build data for the rest of the coins and symbols:\n",
    "    if epoch > 1:\n",
    "        time_now_proccessTickers = time.time()\n",
    "        memory_data_symbol = proccessTickers(epoch, memory_symbols, False, None)\n",
    "        proccessTickers_time += ' + pT:' + str(round(time.time() - time_now_proccessTickers, 2))\n",
    "\n",
    "        # Start updating symbol priority list into avaiable_coins:\n",
    "        thread = Thread(target = updateSymbolPriorityList, args = (memory_data_symbol,))\n",
    "        thread.start()\n",
    "\n",
    "    if epoch > pred_epoch:\n",
    "        time_now_processActionData = time.time()\n",
    "        memory_data.append(processActionData(memory_data_symbol, False)[0])\n",
    "        proccessTickers_time += ' + pA:' + str(round(time.time() - time_now_processActionData, 2))\n",
    "    #\n",
    "    \n",
    "    if epoch % pred_epoch == 0 and epoch > pred_epoch + interval_columns:\n",
    "        do_predictions = True\n",
    "        \n",
    "    if epoch > pred_epoch:\n",
    "        predictions_saved.append(predictions_byModel[0])\n",
    "\n",
    "        if epoch == pred_epoch + 1:\n",
    "            print('Attempting to create models now...')\n",
    "            thread = Thread(target = create_models)\n",
    "            thread.start()\n",
    "        else:\n",
    "            # Do Validation on Past predictions:\n",
    "            training_list, y_train, validated_list_targets = validatePredictions(epoch, memory_symbols)\n",
    "            if do_predictions and epoch > interval_columns:\n",
    "                validatePastPredictions(validated_list_targets)\n",
    "            \n",
    "            if epoch == pred_epoch + interval_columns - 5:\n",
    "                # Do warmup:\n",
    "                print('Attempting to do warmup now...')\n",
    "                thread = Thread(target = do_warmup, args = (training_list, y_train,))\n",
    "                thread.start()\n",
    "\n",
    "            elif epoch > pred_epoch + interval_columns:\n",
    "                # Do training:\n",
    "                thread = Thread(target = trainModels, args = (epoch, training_list, y_train,))\n",
    "                thread.start()\n",
    "\n",
    "                if do_plots and nn_epochs > 1 and epoch % 4 == 0 and len(holding_coins.keys()) > 0:\n",
    "                    processPlotting(coins)\n",
    "    \n",
    "\n",
    "    # Cleanup:\n",
    "    if epoch > interval_columns:\n",
    "        for _, value in memory_symbols.items():\n",
    "            del value['bidPrice_high'][0]\n",
    "            del value['bidPrice_low'][0]\n",
    "            del value['askPrice_high'][0]\n",
    "            del value['askPrice_low'][0]\n",
    "            del value['volume'][0]\n",
    "            del value['quoteVolume'][0]\n",
    "            del value['tradeCount'][0]\n",
    "            del value['lastPrice'][0]\n",
    "        deleted_symbol_data += 1\n",
    "    if len(memory_data) == pred_epoch:\n",
    "        del memory_data[0]\n",
    "        del predictions_saved[0]\n",
    "\n",
    "    for text in trades_history.keys():\n",
    "        if trades_history[text]['x'] == 0:\n",
    "            del trades_history[text]\n",
    "            break\n",
    "    for text in trades_history.keys():\n",
    "        trades_history[text]['x'] -= 1\n",
    "    \n",
    "\n",
    "    if len(eur_balance_agregated) >= aggregate_loss_history_epochs:\n",
    "        del eur_balance_agregated[0]\n",
    "        \n",
    "    ##\n",
    "    time_big = round(time.time()-time_now_big, 2)\n",
    "    print('---------------- ', total_part_epochs, '[', time_big, 's ==', 't: ' + proccessTickers_time, '| p:', predictions_byModel[1], ']', \\\n",
    "          ' || ', print_trained_string, '|  Loss:', loss_string, ' |  RAM:', round(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2), 'mb')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    handleTickers_lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processPlotting():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPlotting(coins):\n",
    "    plt.figure(1)\n",
    "    plt.subplots_adjust(hspace=0.3)\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 5)\n",
    "    \n",
    "\n",
    "    ### Loss plot:\n",
    "    plt.subplot(211)\n",
    "    ax = plt.gca()\n",
    "    found = False\n",
    "    \n",
    "    for model_name, losses_agregat in losses_agregated.items():\n",
    "        plt.plot(losses_agregat, label=model_name + ' Loss', marker='.', linestyle='-', color='b')\n",
    "    for model_name, losses_agregat in losses_agregated_positives.items():\n",
    "        if len(losses_agregat) > 0:\n",
    "            found = True\n",
    "            plt.plot(losses_agregat, label=model_name + ' Positives', marker='.', linestyle='--', color='orange')\n",
    "    if found == False:\n",
    "        return\n",
    "\n",
    "    for trade in trades_history.values():\n",
    "        if trade['x'] <= aggregate_loss_history_epochs - pred_epoch:\n",
    "            ax.annotate(trade['text'], (trade['x'] + pred_epoch, 0.9), fontsize = 7)\n",
    "\n",
    "    plt.axhline(y = 0.1, color = 'gray', linestyle = 'dotted')\n",
    "    plt.title(\"Losses last \" + str(aggregate_loss_history_epochs) + \" epochs. Now: \" + ', '.join(coins))\n",
    "    plt.ylabel('Loss', fontsize=8)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim(0, 0.3)\n",
    "    \n",
    "\n",
    "    ### EUR profit plot:\n",
    "    plt.subplot(212)\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for trade in trades_history.values():\n",
    "        ax.annotate(trade['text'], (trade['x'], trade['y']), fontsize = 7)\n",
    "\n",
    "    if eur_balance_agregated[0] <= eur_balance_agregated[-1]:\n",
    "        plt.plot(eur_balance_agregated, marker='.', linestyle='-', color='green')\n",
    "    else:\n",
    "        plt.plot(eur_balance_agregated, marker='.', linestyle='-', color='red')\n",
    "\n",
    "    plt.title(\"EUR balance last \" + str(aggregate_loss_history_epochs) + \" epochs\")\n",
    "    plt.xlabel('Epoch', fontsize=8)\n",
    "    plt.ylabel('EUR €', fontsize=8)\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhk559ZXlIPx"
   },
   "source": [
    "### proccessTickers():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN5wC6Eni6s8"
   },
   "outputs": [],
   "source": [
    "def proccessTickers(epoch, memory_symbols, only_use_holding_symbols, use_symbols):\n",
    "    global highest, lowest\n",
    "\n",
    "    memory_data_symbol = {}\n",
    "\n",
    "    for symbol, inner in memory_symbols.items():\n",
    "        if only_use_holding_symbols and symbol not in use_symbols:\n",
    "            continue\n",
    "\n",
    "        dat = []\n",
    "\n",
    "        temp_bidPrice_low = inner['bidPrice_low'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_bidPrice_high = inner['bidPrice_high'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_askPrice_low = inner['askPrice_low'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_askPrice_high = inner['askPrice_high'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_volume = inner['volume'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_volume == 0:\n",
    "            temp_volume = 0.0000001\n",
    "        temp_quoteVolume = inner['quoteVolume'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_quoteVolume == 0:\n",
    "            temp_quoteVolume = 0.0000001\n",
    "        temp_tradeCount = inner['tradeCount'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_tradeCount == 0:\n",
    "            temp_tradeCount = 0.0000001\n",
    "        temp_lastPrice = inner['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_lastPrice == 0:\n",
    "            temp_lastPrice = 0.0000001\n",
    "\n",
    "\n",
    "        for i in range(1, interval_columns + 1):\n",
    "            if (epoch > i):\n",
    "                index = epoch - i - 1 - deleted_symbol_data\n",
    "\n",
    "                arr = []\n",
    "                \n",
    "                bidPrice_low = inner['bidPrice_low'][index] # Reverse + Pick i element.\n",
    "                if bidPrice_low == 0:\n",
    "                    arr.append(0)\n",
    "                else:\n",
    "                    bidPrice_low_change = (temp_bidPrice_low - bidPrice_low) / bidPrice_low\n",
    "                    if bidPrice_low_change > upscale_to_maximum_data_point_input:\n",
    "                        bidPrice_low_change = 1\n",
    "                    elif bidPrice_low_change < -upscale_to_maximum_data_point_input:\n",
    "                        bidPrice_low_change = -1\n",
    "                    else:\n",
    "                        bidPrice_low_change /= upscale_to_maximum_data_point_input\n",
    "                    arr.append(bidPrice_low_change)\n",
    "                    \n",
    "                bidPrice_high = inner['bidPrice_high'][index] # Reverse + Pick i element.\n",
    "                if bidPrice_high == 0:\n",
    "                    arr.append(0)\n",
    "                else:\n",
    "                    bidPrice_high_change = (temp_bidPrice_high - bidPrice_high) / bidPrice_high\n",
    "                    if bidPrice_high_change > upscale_to_maximum_data_point_input:\n",
    "                        bidPrice_high_change = 1\n",
    "                    elif bidPrice_high_change < -upscale_to_maximum_data_point_input:\n",
    "                        bidPrice_high_change = -1\n",
    "                    else:\n",
    "                        bidPrice_high_change /= upscale_to_maximum_data_point_input\n",
    "                    bidPrice_high_change /= upscale_to_maximum_data_point_input\n",
    "                    arr.append(bidPrice_high_change)\n",
    "\n",
    "                askPrice_low = inner['askPrice_low'][index] # Reverse + Pick i element.\n",
    "                if askPrice_low == 0:\n",
    "                    arr.append(0)\n",
    "                else:\n",
    "                    askPrice_low_change = (temp_askPrice_low - askPrice_low) / askPrice_low\n",
    "                    if askPrice_low_change > upscale_to_maximum_data_point_input:\n",
    "                        askPrice_low_change = 1\n",
    "                    elif askPrice_low_change < -upscale_to_maximum_data_point_input:\n",
    "                        askPrice_low_change = -1\n",
    "                    else:\n",
    "                        askPrice_low_change /= upscale_to_maximum_data_point_input\n",
    "                    arr.append(askPrice_low_change)\n",
    "\n",
    "                askPrice_high = inner['askPrice_high'][index] # Reverse + Pick i element.\n",
    "                if askPrice_high == 0:\n",
    "                    arr.append(0)\n",
    "                else:\n",
    "                    askPrice_high_change = (temp_askPrice_high - askPrice_high) / askPrice_high\n",
    "                    if askPrice_high_change > upscale_to_maximum_data_point_input:\n",
    "                        askPrice_high_change = 1\n",
    "                    elif askPrice_high_change < -upscale_to_maximum_data_point_input:\n",
    "                        askPrice_high_change = -1\n",
    "                    else:\n",
    "                        askPrice_high_change /= upscale_to_maximum_data_point_input\n",
    "                    arr.append(askPrice_high_change)\n",
    "\n",
    "                volume = inner['volume'][index] # Reverse + Pick i element.\n",
    "                if volume == 0:\n",
    "                    volume = 0.0000001\n",
    "                volume_change = (temp_volume - volume) / volume\n",
    "                if volume_change > upscale_to_maximum_data_point_input:\n",
    "                    volume_change = 1\n",
    "                elif volume_change < -upscale_to_maximum_data_point_input:\n",
    "                    volume_change = -1\n",
    "                else:\n",
    "                    volume_change /= upscale_to_maximum_data_point_input\n",
    "                arr.append(volume_change)\n",
    "\n",
    "                quoteVolume = inner['quoteVolume'][index] # Reverse + Pick i element.\n",
    "                if quoteVolume == 0:\n",
    "                    quoteVolume = 0.0000001\n",
    "                quoteVolume_change = (temp_quoteVolume - quoteVolume) / quoteVolume\n",
    "                if quoteVolume_change > upscale_to_maximum_data_point_input:\n",
    "                    quoteVolume_change = 1\n",
    "                elif quoteVolume_change < -upscale_to_maximum_data_point_input:\n",
    "                    quoteVolume_change = -1\n",
    "                else:\n",
    "                    quoteVolume_change /= upscale_to_maximum_data_point_input\n",
    "                arr.append(quoteVolume_change)\n",
    "\n",
    "                tradeCount = inner['tradeCount'][index] # Reverse + Pick i element.\n",
    "                if tradeCount == 0:\n",
    "                    tradeCount = 0.0000001\n",
    "                tradeCount_change = (temp_tradeCount - tradeCount) / tradeCount\n",
    "                if tradeCount_change > upscale_to_maximum_data_point_input:\n",
    "                    tradeCount_change = 1\n",
    "                elif tradeCount_change < -upscale_to_maximum_data_point_input:\n",
    "                    tradeCount_change = -1\n",
    "                else:\n",
    "                    tradeCount_change /= upscale_to_maximum_data_point_input\n",
    "                arr.append(tradeCount_change)\n",
    "\n",
    "                lastPrice = inner['lastPrice'][index] # Reverse + Pick i element.\n",
    "                if lastPrice == 0:\n",
    "                    lastPrice = 0.0000001\n",
    "                lastPrice_change = (temp_lastPrice - lastPrice) / lastPrice\n",
    "                if lastPrice_change > upscale_to_maximum_data_point_input:\n",
    "                    lastPrice_change = 1\n",
    "                elif lastPrice_change < -upscale_to_maximum_data_point_input:\n",
    "                    lastPrice_change = -1\n",
    "                else:\n",
    "                    lastPrice_change /= upscale_to_maximum_data_point_input\n",
    "                arr.append(lastPrice_change)\n",
    "\n",
    "\n",
    "                dat.insert(0, arr)\n",
    "\n",
    "\n",
    "                temp_bidPrice_low = bidPrice_low\n",
    "                temp_bidPrice_high = bidPrice_high\n",
    "                temp_askPrice_low = askPrice_low\n",
    "                temp_askPrice_high = askPrice_high\n",
    "                temp_volume = volume\n",
    "                temp_quoteVolume = quoteVolume\n",
    "                temp_tradeCount = tradeCount\n",
    "                temp_lastPrice = lastPrice\n",
    "\n",
    "            else:\n",
    "                dat.insert(0, [0, 0, 0, 0, 0, 0, 0, 0])\n",
    "            \n",
    "\n",
    "        memory_data_symbol[symbol] = dat\n",
    "\n",
    "    return memory_data_symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HtKD9Wrmxi0"
   },
   "source": [
    "### processActionData():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flVCYZidm5aB"
   },
   "outputs": [],
   "source": [
    "def processActionData(memory_data_symbol, only_use_holding_symbols):\n",
    "    global holding_coins, memory_data, categorial_features_indices, features_list, saved_df_buffer\n",
    "\n",
    "    saved, coins = [], []\n",
    "\n",
    "    if only_use_holding_symbols:\n",
    "        for coin in list(holding_coins.keys()):\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                saved.append(getActionSampleRow(symbol, coin, memory_data_symbol))\n",
    "\n",
    "            coins.append(coin)\n",
    "    else:\n",
    "        for coin in avaiable_coins.keys():\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                saved.append(getActionSampleRow(symbol, coin, memory_data_symbol))\n",
    "\n",
    "            coins.append(coin)\n",
    "\n",
    "    return saved, coins\n",
    "\n",
    "\n",
    "def getActionSampleRow(symbol, coin, memory_data_symbol):\n",
    "    data = {\n",
    "        'coin': coin,\n",
    "        'symbol': symbol,\n",
    "        'time_numbers_input': []\n",
    "    }\n",
    "\n",
    "    if symbol.startswith(coin):\n",
    "        for arr in memory_data_symbol[symbol]:\n",
    "            arr_input = [x * -1 for x in arr]\n",
    "            data['time_numbers_input'].append(arr_input)\n",
    "    else:\n",
    "        for arr in memory_data_symbol[symbol]:\n",
    "            data['time_numbers_input'].append(arr)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WPpdhuugYQd"
   },
   "source": [
    "### updateBinanceBalances + updateSymbolPriorityList:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXnUSgd2gUxg"
   },
   "outputs": [],
   "source": [
    "def updateBinanceBalances():\n",
    "    global holding_coins, dont_update_holding_coins, cancel_orders\n",
    "\n",
    "    if cancel_orders:\n",
    "        cancel_orders = False\n",
    "        orders = binance.get_open_orders()\n",
    "        for order in orders:\n",
    "            print('cancel_order:', binance.cancel_order(\n",
    "                symbol = order['symbol'],\n",
    "                orderId = order['orderId']))\n",
    "\n",
    "    balances = binance.get_account()['balances']\n",
    "\n",
    "    # ### DEBUG:\n",
    "    # balances.append(\n",
    "    #     {\n",
    "    #         \"asset\": \"DOGE\",\n",
    "    #         \"free\": \"1000\",\n",
    "    # })\n",
    "    # balances.append(\n",
    "    #     {\n",
    "    #         \"asset\": \"EUR\",\n",
    "    #         \"free\": \"440\",\n",
    "    # })\n",
    "\n",
    "    found_assets = []\n",
    "    for balance in balances:\n",
    "        balance_number = float(balance['free'])\n",
    "        if balance_number > 0.0001:\n",
    "            if balance['asset'] not in holding_coins.keys():\n",
    "                holding_coins[balance['asset']] = holding_coins_DEFAULT.copy()\n",
    "            if balance['asset'] == 'EUR':\n",
    "                balance_number -= real_wallet_dont_use_euro\n",
    "                if balance_number < 1:\n",
    "                    continue\n",
    "            if balance['asset'] == 'BNB':\n",
    "                balance_number -= 0.01  # 2.76eur 15.09.22\n",
    "            if balance_number < 0.0001:\n",
    "                continue\n",
    "            if balance['asset'] not in dont_update_holding_coins:\n",
    "                holding_coins[balance['asset']]['balance'] = balance_number\n",
    "            found_assets.append(balance['asset'])\n",
    "    \n",
    "    for coin in list(holding_coins.keys()):\n",
    "        if coin not in found_assets or holding_coins[coin]['balance_eur'] < 1:\n",
    "            if coin in dont_update_holding_coins:\n",
    "                dont_update_holding_coins.remove(coin)\n",
    "                del dont_update_holding_coins_buffer[coin]\n",
    "            del holding_coins[coin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deEBL0RsYvti"
   },
   "outputs": [],
   "source": [
    "def updateSymbolPriorityList(memory_data_symbol):\n",
    "    global avaiable_coins\n",
    "\n",
    "    symbol_changes = {}\n",
    "    for symbol, details in memory_data_symbol.items():\n",
    "        symbol_changes[symbol] = getPositiveChange(details[0][7]) # lastPrice\n",
    "    symbol_changes = list(dict(sorted(symbol_changes.items(), key=lambda item: item[1], reverse = True)).keys())\n",
    "\n",
    "    new_avaiable_coins = {}\n",
    "    for coin, symbols in avaiable_coins.items():\n",
    "        new_avaiable_coins[coin] = []\n",
    "        for symbol in symbol_changes:\n",
    "            if symbol in symbols:\n",
    "                new_avaiable_coins[coin].append(symbol)\n",
    "\n",
    "    avaiable_coins = new_avaiable_coins\n",
    "\n",
    "\n",
    "def getPositiveChange(number):\n",
    "    if number < 0:\n",
    "        return number * -1\n",
    "    else:\n",
    "        return number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFk0gn6wjwRx"
   },
   "source": [
    "### proccessPredictions():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9W3xKw0j30q"
   },
   "outputs": [],
   "source": [
    "def runModelPredictions(model_name, model, symbols, ds, list_data, coins):\n",
    "    \n",
    "    model_saving_lock.acquire()\n",
    "  \n",
    "    try:\n",
    "        if model_name == 'NNAction':\n",
    "            results = model.predict(ds, verbose = 0)\n",
    "        elif model_name == 'CatBoostAction':\n",
    "            results = model.predict_proba(list_data)\n",
    "    except Exception as e:\n",
    "        print('Model.Predict() Failed.')\n",
    "        print(e)\n",
    "        model_saving_lock.release()\n",
    "        return {}\n",
    "\n",
    "    model_saving_lock.release()\n",
    "\n",
    "    predictions_byModel = {}\n",
    "\n",
    "    i = 0\n",
    "    for coin in coins:\n",
    "        predictions_byModel[coin] = {}\n",
    "        \n",
    "        array = []\n",
    "        found = 0\n",
    "\n",
    "        for a in range(0, amount_of_symbols_per_coin_pred):\n",
    "            if len(symbols) < i + 1:\n",
    "                break\n",
    "            if not symbols[i].startswith(coin) and not symbols[i].endswith(coin):\n",
    "                break\n",
    "            \n",
    "            array.append(results[i][0])\n",
    "            i += 1\n",
    "            found += 1\n",
    "\n",
    "        for b in range(found, amount_of_symbols_per_coin_pred):\n",
    "            array.append(0)\n",
    "\n",
    "        sorted_indices_array = np.argsort(array)[::-1][:amount_of_symbols_per_coin_pred] # highest first\n",
    "\n",
    "        for a in range(0, found):\n",
    "            predictions_byModel[coin][a] = {\n",
    "                'symbol': symbols[i - found + sorted_indices_array[a]],\n",
    "                'value': array[sorted_indices_array[a]],\n",
    "            }\n",
    "        \n",
    "        for b in range(found, amount_of_symbols_per_coin_pred):\n",
    "            predictions_byModel[coin][b] = {\n",
    "                'symbol': '0',\n",
    "                'value': 0,\n",
    "            }\n",
    "    \n",
    "    return predictions_byModel\n",
    "\n",
    "def proccessPredictions(saved, coins):\n",
    "    time_now = time.time()\n",
    "    \n",
    "    list_data = {\n",
    "        'coin': [],\n",
    "        'symbol': [],\n",
    "        'time_numbers_input': [],\n",
    "    }\n",
    "    predictions_byModel = {}\n",
    "\n",
    "    coin_count = {}\n",
    "    symbols = []\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for sample in saved:\n",
    "        if sample['coin'] not in coin_count.keys():\n",
    "            coin_count[sample['coin']] = 1\n",
    "        elif coin_count[sample['coin']] >= amount_of_symbols_per_coin_pred:\n",
    "            continue\n",
    "        else:\n",
    "            coin_count[sample['coin']] += 1\n",
    "\n",
    "        # duplicate 42\n",
    "\n",
    "        list_data['coin'].append(sample['coin'])\n",
    "        list_data['symbol'].append(sample['symbol'])\n",
    "        list_data['time_numbers_input'].append(sample['time_numbers_input'])\n",
    "\n",
    "        # list_data.append(list(sample.values()))\n",
    "        total_predictions += 1\n",
    "\n",
    "        symbols.append(sample['symbol'])\n",
    "\n",
    "    ds = clean_data_for_NN(list_data)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        predictions_byModel[model_name] = runModelPredictions(model_name, model, symbols, ds, list_data, coins)\n",
    "\n",
    "    pred_time = str(round(time.time() - time_now, 2)) + 's/' + str(total_predictions) + 'e'\n",
    "\n",
    "    return predictions_byModel, pred_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKOMrV86wxf6"
   },
   "source": [
    "### validatePredictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mKv-Feew7vS"
   },
   "outputs": [],
   "source": [
    "def validatePredictions(current_epoch, memory_symbols):\n",
    "    global memory_data, predictions_saved\n",
    "    \n",
    "    list_data = {\n",
    "        'coin': [],\n",
    "        'symbol': [],\n",
    "        'time_numbers_input': [],\n",
    "    }\n",
    "    y_train = []\n",
    "    validated_list_targets = {}\n",
    "        \n",
    "    for sample in memory_data[0]:\n",
    "        coin = sample['coin']\n",
    "        symbol = sample['symbol']\n",
    "        time_numbers_input = sample['time_numbers_input']\n",
    "\n",
    "        if coin not in validated_list_targets.keys():\n",
    "            validated_list_targets[coin] = []\n",
    "        \n",
    "\n",
    "        old_lastPrice = memory_symbols[symbol]['lastPrice'][current_epoch - 1 - deleted_symbol_data - pred_epoch]\n",
    "        new_lastPrice = memory_symbols[symbol]['lastPrice'][current_epoch - 1 - deleted_symbol_data]\n",
    "        if old_lastPrice == 0:\n",
    "            old_lastPrice = new_lastPrice\n",
    "        reg_target = (new_lastPrice - old_lastPrice) / old_lastPrice\n",
    "\n",
    "\n",
    "        if symbol.startswith(coin):\n",
    "            reg_target *= -1\n",
    "\n",
    "        if reg_target > binary_target_minimum_increase_min:\n",
    "            validated_list_targets[coin].append(symbol)\n",
    "\n",
    "        if reg_target > upscale_to_maximum_data_point_output:\n",
    "            reg_target = 1\n",
    "        elif reg_target < -upscale_to_maximum_data_point_output:\n",
    "            reg_target = -1\n",
    "        else:\n",
    "            reg_target /= upscale_to_maximum_data_point_output\n",
    "\n",
    "\n",
    "        # duplicate 43: for fitting\n",
    "\n",
    "        list_data['coin'].append(coin)\n",
    "        list_data['symbol'].append(symbol)\n",
    "        list_data['time_numbers_input'].append(time_numbers_input)\n",
    "\n",
    "        y_train.append(reg_target)\n",
    "\n",
    "    return list_data, y_train, validated_list_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX4Yb1Cqm7km"
   },
   "outputs": [],
   "source": [
    "def validatePastPredictions(validated_list_targets):\n",
    "    global loss_string, median_loss, median_loss_positives\n",
    "\n",
    "    loss_string = ''\n",
    "\n",
    "    for model_name, inner in predictions_saved[0].items():\n",
    "        # Calculate Loss:\n",
    "        losses, count = 0, 0\n",
    "        losses_positives, count_positives = 0, 0\n",
    "\n",
    "        print('_PAST:')\n",
    "        for coin, detail in inner.items():\n",
    "            symbols = ['NONE']\n",
    "            for i in range(0, amount_of_symbols_per_coin_pred):\n",
    "                if detail[i]['symbol'] == '0':\n",
    "                    break\n",
    "                symbols.append(detail[i]['symbol'])\n",
    "            targets = validated_list_targets[coin]\n",
    "            targets = list(filter(lambda x: x in symbols, targets))\n",
    "            if len(targets) == 0:\n",
    "                targets = ['NONE']\n",
    "\n",
    "            pred_streng = ''\n",
    "            for i in range(0, amount_of_symbols_per_coin_pred):\n",
    "                if detail[i]['symbol'] == '0':\n",
    "                    break\n",
    "                pred_streng += detail[i]['symbol'] + ' ' + str(round(detail[i]['value'], 2)) + '    '\n",
    "\n",
    "            print(coin, '_targets:', '  '.join(targets), '  ', '  ', '  ', '_pred:   ', pred_streng)\n",
    "            \n",
    "            found_positive = False\n",
    "            loss, loss_positive = 0, 1\n",
    "\n",
    "            if 'NONE' in targets:\n",
    "                # Loss:\n",
    "                loss = detail[0]['value']\n",
    "\n",
    "                # Positives:\n",
    "                if loss > 0:\n",
    "                    found_positive = True\n",
    "            else:\n",
    "                if detail[0]['symbol'] in targets:\n",
    "                    loss = 0.1 - detail[0]['value']\n",
    "                else:\n",
    "                    loss = 0.1 + detail[0]['value']\n",
    "                found_positive = True\n",
    "\n",
    "            if loss > 0.3:\n",
    "                loss = 0.3\n",
    "            elif loss < 0:\n",
    "                loss = 0\n",
    "                \n",
    "            if found_positive:\n",
    "                count_positives += 1\n",
    "                losses_positives += loss\n",
    "            count += 1\n",
    "            losses += loss\n",
    "        print()\n",
    "\n",
    "        if count == 0:\n",
    "            return\n",
    "        \n",
    "        losses /= count\n",
    "\n",
    "        losses_agregated[model_name].append(losses)\n",
    "\n",
    "        length_losses_agregated = len(losses_agregated[model_name])\n",
    "        length_losses_agregated_positives = len(losses_agregated_positives[model_name])\n",
    "\n",
    "        if count_positives > 0:\n",
    "            losses_positives /= count_positives\n",
    "        elif length_losses_agregated_positives > 0:\n",
    "            losses_positives = losses_agregated_positives[model_name][length_losses_agregated_positives - 1]\n",
    "        else:\n",
    "            losses_positives = losses\n",
    "        losses_agregated_positives[model_name].append(losses_positives)\n",
    "        length_losses_agregated_positives += 1\n",
    "\n",
    "        if length_losses_agregated > aggregate_loss_history_epochs:\n",
    "            length_losses_agregated -= 1\n",
    "            del losses_agregated[model_name][0]\n",
    "\n",
    "        if length_losses_agregated_positives > aggregate_loss_history_epochs:\n",
    "            length_losses_agregated_positives -= 1\n",
    "            del losses_agregated_positives[model_name][0]\n",
    "        \n",
    "        median_loss = round(sum(losses_agregated[model_name]) / length_losses_agregated, 3)\n",
    "        median_loss_positives = round(sum(losses_agregated_positives[model_name]) / length_losses_agregated_positives, 3)\n",
    "\n",
    "        loss_string += str(median_loss) + ' (P: ' + str(median_loss_positives) + ' )  '\n",
    "        #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEkAlPZfk7cZ"
   },
   "source": [
    "### convert_wallet_to_euro():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGuJiuABk8Uh"
   },
   "outputs": [],
   "source": [
    "def convert_wallet_to_euro(holding_coins, memory_symbols, epoch):\n",
    "    global dont_update_holding_coins, dont_update_holding_coins_buffer, eur_balance_agregated\n",
    "\n",
    "    euro = 0\n",
    "\n",
    "    for coin in list(holding_coins.keys()):\n",
    "        found = False\n",
    "        if coin == 'EUR':\n",
    "            euro += holding_coins[coin]['balance']\n",
    "            holding_coins[coin]['balance_eur'] = holding_coins[coin]['balance']\n",
    "            found = True\n",
    "            continue\n",
    "        \n",
    "        for symbol, inner in memory_symbols.items():\n",
    "            if symbol in avaiable_coins[coin] and 'EUR' in symbol:\n",
    "                balance = 0\n",
    "                if symbol.endswith(coin):\n",
    "                    price = (inner['askPrice_high'][epoch - 1 - deleted_symbol_data] + inner['askPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                    balance = holding_coins[coin]['balance'] / price\n",
    "                else:\n",
    "                    price = (inner['bidPrice_high'][epoch - 1 - deleted_symbol_data] + inner['bidPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                    balance = holding_coins[coin]['balance'] * price\n",
    "                    \n",
    "                euro += balance\n",
    "                holding_coins[coin]['balance_eur'] = balance\n",
    "                found = True\n",
    "                break\n",
    "        else:\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                similars = [\"BTC\", \"ETH\", \"BNB\", \"USDT\", \"BUSD\"]\n",
    "                if any(x in symbol for x in similars):\n",
    "                    new_currency = 0\n",
    "                    if symbol.endswith(coin):\n",
    "                        price = (memory_symbols[symbol]['askPrice_high'][epoch - 1 - deleted_symbol_data] + memory_symbols[symbol]['askPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                        new_currency = holding_coins[coin]['balance'] / price\n",
    "                    else:\n",
    "                        price = (memory_symbols[symbol]['bidPrice_high'][epoch - 1 - deleted_symbol_data] + memory_symbols[symbol]['bidPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                        new_currency = holding_coins[coin]['balance'] * price\n",
    "                    new_coin = symbol.replace(coin, '')\n",
    "                    \n",
    "                    # print(symbol, coin, new_coin) \n",
    "                    for symbol2 in memory_symbols.keys():\n",
    "                        if new_coin in avaiable_coins.keys():\n",
    "                            if symbol2 in avaiable_coins[new_coin] and 'EUR' in symbol2:\n",
    "                                balance = 0\n",
    "                                if symbol2.endswith(coin):\n",
    "                                    price = (memory_symbols[symbol2]['askPrice_high'][epoch - 1 - deleted_symbol_data] + memory_symbols[symbol2]['askPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                                    balance = new_currency / price\n",
    "                                else:\n",
    "                                    price = (memory_symbols[symbol2]['bidPrice_high'][epoch - 1 - deleted_symbol_data] + memory_symbols[symbol2]['bidPrice_low'][epoch - 1 - deleted_symbol_data]) / 2\n",
    "                                    balance = new_currency * price\n",
    "                                    \n",
    "                                euro += balance\n",
    "                                holding_coins[coin]['balance_eur'] = balance\n",
    "                                found = True\n",
    "                                break\n",
    "                    else:\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "        if found == False:            \n",
    "          print('ALEED!!: convert_wallet_to_euro() | Couldnt resolve coin for trading euro:', coin)\n",
    "\n",
    "    # Cleanup low balances:\n",
    "    for coin in list(holding_coins.keys()):\n",
    "        if holding_coins[coin]['balance_eur'] < 5:\n",
    "            euro -= holding_coins[coin]['balance_eur']\n",
    "            del holding_coins[coin]\n",
    "\n",
    "    # For EUR profit plot:\n",
    "    eur_balance_agregated.append(euro)\n",
    "\n",
    "    return str(round(euro, 2)) + ' €'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiBXDbMQlU49"
   },
   "source": [
    "### processTrading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtAGU3cjlZLG"
   },
   "outputs": [],
   "source": [
    "def processTrading(predictions_byModel, current_epoch, memory_symbols):\n",
    "    global holding_coins, dont_update_holding_coins, dont_update_holding_coins_buffer, cancel_orders\n",
    "\n",
    "    coin_list = list(holding_coins.keys())\n",
    "    coins_minimum_limit = {}\n",
    "\n",
    "    for coin in coin_list:\n",
    "        if holding_coins[coin]['counting_epochs'] < 30:\n",
    "            coins_minimum_limit[coin] = minimum_prediction_prob_trade - (decrease_prob_trade_per_epoch_below_30_epochs * holding_coins[coin]['counting_epochs'])\n",
    "        else:\n",
    "            counting_epochs = holding_coins[coin]['counting_epochs'] - 30\n",
    "            if counting_epochs > 120:\n",
    "                coins_minimum_limit[coin] = 0\n",
    "            else:\n",
    "                coins_minimum_limit[coin] = minimum_prediction_prob_trade - (decrease_prob_trade_per_epoch_below_30_epochs * 30) - (decrease_prob_trade_per_epoch_above_30_epochs * counting_epochs)\n",
    "\n",
    "    print('_TRADING:')\n",
    "    for inner in predictions_byModel.values():\n",
    "        for coin, details in inner.items():\n",
    "            if coin in holding_coins.keys():\n",
    "                print(coin, details[0]['symbol'], str(round(details[0]['value'] * 100, 3)) + '%', '  ', '(>', str(round(100 * coins_minimum_limit[coin], 2)) + '%)')\n",
    "    print()\n",
    "\n",
    "    for coin in coin_list:\n",
    "        if coin not in predictions_byModel[model_name_for_trading].keys():\n",
    "            continue\n",
    "        if median_loss > trade_when_below_loss:\n",
    "            continue\n",
    "        if predictions_byModel[model_name_for_trading][coin][0]['value'] < coins_minimum_limit[coin]:\n",
    "            continue\n",
    "\n",
    "        symbol = predictions_byModel[model_name_for_trading][coin][0]['symbol']\n",
    "        buying_coin = symbol.replace(coin, '')\n",
    "\n",
    "        buying_quantity = None\n",
    "        price = None\n",
    "\n",
    "        if symbol.startswith(coin):\n",
    "            bidPrice_low = memory_symbols[symbol]['bidPrice_low'][current_epoch - 1 - deleted_symbol_data]\n",
    "            price = bidPrice_low\n",
    "            buying_quantity = holding_coins[coin]['balance'] * price\n",
    "        else:\n",
    "            askPrice_high = memory_symbols[symbol]['askPrice_high'][current_epoch - 1 - deleted_symbol_data]\n",
    "            price = askPrice_high\n",
    "            buying_quantity = holding_coins[coin]['balance'] / price\n",
    "\n",
    "        price = round_down(price, int(binance_symbols[symbol]['tickSize']))\n",
    "        buying_quantity = round_down(buying_quantity, 7)\n",
    "\n",
    "\n",
    "        trade = '--> Attempt Trading ' + str(holding_coins[coin]['balance']) + ' ' + coin + ' to ' + str(buying_quantity) + ' ' + buying_coin + \\\n",
    "                ' for ' + str(price) + '        [' + time.strftime(\"%H:%M:%S\") + ']'\n",
    "        print(trade)\n",
    "\n",
    "        trades_history[coin + '->' + buying_coin] = {\n",
    "            'text': coin + '->' + buying_coin,\n",
    "            'x': len(eur_balance_agregated) - 1,\n",
    "            'y': eur_balance_agregated[-1],\n",
    "        }\n",
    "\n",
    "\n",
    "        if do_real_money_trade:\n",
    "            #########################################################\n",
    "            #########################################################\n",
    "            #########################################################\n",
    "              \n",
    "            side = SIDE_BUY\n",
    "            order_quantity = buying_quantity\n",
    "            order_notional = holding_coins[coin]['balance']\n",
    "            if symbol.endswith(buying_coin):\n",
    "                side = SIDE_SELL\n",
    "                order_quantity = holding_coins[coin]['balance']\n",
    "                order_notional = buying_quantity\n",
    "\n",
    "            order_quantity = round_down(order_quantity, int(binance_symbols[symbol]['stepSizeInteger']))\n",
    "\n",
    "            if binance_symbols[symbol]['minNotional'] >= order_notional:\n",
    "                print('minNotional err', coin, binance_symbols[symbol]['minNotional'], order_quantity)\n",
    "                del holding_coins[coin]\n",
    "                if coin in dont_update_holding_coins:\n",
    "                    dont_update_holding_coins.remove(coin)\n",
    "                    del dont_update_holding_coins_buffer[coin]\n",
    "                print(coin + ' deleted from trading wallet.')\n",
    "                continue\n",
    "\n",
    "            limit_price = format(price, '.' + str(binance_symbols[symbol]['tickSize']) + 'f')\n",
    "            order_quantity = format(order_quantity, '.' + str(binance_symbols[symbol]['stepSizeInteger']) + 'f')\n",
    "\n",
    "            print(symbol, side, order_quantity, limit_price)\n",
    "        \n",
    "            success = False\n",
    "            try:\n",
    "                cancel_orders = True\n",
    "                order = binance.create_order(\n",
    "                    symbol=symbol,\n",
    "                    side=side,\n",
    "                    type=ORDER_TYPE_LIMIT,\n",
    "                    timeInForce=TIME_IN_FORCE_GTC,\n",
    "                    quantity=order_quantity,\n",
    "                    price=limit_price)\n",
    "                print(order)\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print('create_order err:', e.message)\n",
    "                if 'insufficient balance' in e.message or 'MIN_NOTIONAL' in e.message:\n",
    "                    if coin not in dont_update_holding_coins:\n",
    "                        if coin not in dont_update_holding_coins_buffer.keys():\n",
    "                            dont_update_holding_coins_buffer[coin] = 1\n",
    "                        else:\n",
    "                            dont_update_holding_coins_buffer[coin] += 1\n",
    "                            if dont_update_holding_coins_buffer[coin] > 2:\n",
    "                                dont_update_holding_coins.append(coin)\n",
    "                    else:\n",
    "                        holding_coins[coin]['balance'] -= binance_symbols[symbol]['stepSize']\n",
    "            ###\n",
    "            ########################################################\n",
    "\n",
    "            if success:\n",
    "                balance = buying_quantity\n",
    "                if buying_coin in holding_coins.keys():\n",
    "                    balance += holding_coins[buying_coin]['balance']\n",
    "\n",
    "                # Set the new acquired coin:\n",
    "                holding_coins[buying_coin] = {\n",
    "                    'balance': balance,\n",
    "                    'balance_eur': 1, \n",
    "                    'price': limit_price,\n",
    "                    'counting_epochs': 0,\n",
    "                    'symbol': symbol, \n",
    "                    'date': time.strftime('%H:%M:%S')\n",
    "                }\n",
    "\n",
    "                del holding_coins[coin]\n",
    "\n",
    "                if coin in dont_update_holding_coins:\n",
    "                    dont_update_holding_coins.remove(coin)\n",
    "                    del dont_update_holding_coins_buffer[coin]\n",
    "                    \n",
    "            print()\n",
    "\n",
    "    if median_loss < trade_when_below_loss:\n",
    "        for coin in holding_coins.keys():\n",
    "            holding_coins[coin]['counting_epochs'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down(value, decimals):\n",
    "    factor = 10 ** decimals\n",
    "    f = frac.Fraction(value)\n",
    "    return float(frac.Fraction(math.floor(f * factor),  factor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2TD04LYP0V2"
   },
   "source": [
    "### trainModels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_data_for_NN(training_list, y_train = None):\n",
    "    if y_train != None:\n",
    "\n",
    "        len_data = len(y_train)\n",
    "\n",
    "        training_list['coin'] = np.array(training_list['coin'], dtype = 'object')\n",
    "        training_list['coin'] = np.reshape(training_list['coin'], (len_data, 1))\n",
    "\n",
    "        training_list['symbol'] = np.array(training_list['symbol'], dtype = 'object')\n",
    "        training_list['symbol'] = np.reshape(training_list['symbol'], (len_data, 1))\n",
    "\n",
    "        training_list['time_numbers_input'] = np.array(training_list['time_numbers_input'], dtype = 'float32')\n",
    "        training_list['time_numbers_input'] = np.reshape(training_list['time_numbers_input'], (len_data, interval_columns, 8))\n",
    "\n",
    "        y_train = np.array(y_train, dtype = 'float32')\n",
    "        y_train = np.reshape(y_train, (len_data, 1))\n",
    "\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices((training_list, y_train))\n",
    "        train_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size = nn_batch_size, count = nn_batch_size - 1))\n",
    "        train_ds = train_ds.batch(nn_batch_size, drop_remainder = True)\n",
    "        \n",
    "        return train_ds\n",
    "    \n",
    "    else:\n",
    "\n",
    "        len_data = len(training_list['coin'])\n",
    "\n",
    "        training_list['coin'] = np.array(training_list['coin'], dtype = 'object')\n",
    "        training_list['coin'] = np.reshape(training_list['coin'], (len_data, 1))\n",
    "\n",
    "        training_list['symbol'] = np.array(training_list['symbol'], dtype = 'object')\n",
    "        training_list['symbol'] = np.reshape(training_list['symbol'], (len_data, 1))\n",
    "\n",
    "        training_list['time_numbers_input'] = np.array(training_list['time_numbers_input'], dtype = 'float32')\n",
    "        training_list['time_numbers_input'] = np.reshape(training_list['time_numbers_input'], (len_data, interval_columns, 8))\n",
    "\n",
    "        train_ds = tf.data.Dataset.from_tensor_slices(training_list)\n",
    "        train_ds = train_ds.repeat(nn_batch_size)\n",
    "        train_ds = train_ds.batch(nn_batch_size, drop_remainder = True)\n",
    "\n",
    "        return train_ds\n",
    "\n",
    "\n",
    "def do_warmup(training_list, y_train):\n",
    "\n",
    "    if use_models[\"NN\"] == 1:\n",
    "        time_now = time.time()\n",
    "        print(0)\n",
    "        model_name, model = create_model_nn('NNAction')\n",
    "        print(1, time.time() - time_now)\n",
    "        time_now = time.time()\n",
    "        training_ds = clean_data_for_NN(training_list, y_train)\n",
    "        print(2, time.time() - time_now)\n",
    "        time_now = time.time()\n",
    "        model.fit(training_ds,\n",
    "                epochs = nn_epochs,\n",
    "                verbose = 1)\n",
    "        print(model_name, 'Did warmup fit:', time.time() - time_now)\n",
    "\n",
    "    if use_models[\"CatBoost\"] == 1:\n",
    "        time_now = time.time()\n",
    "        print(0)\n",
    "        _, model = create_model_catboost('CatBoostAction')\n",
    "        print(1)\n",
    "        df = pd.DataFrame(training_list)\n",
    "        print(2)\n",
    "        model.fit(df, \n",
    "                y_train, \n",
    "                cat_features = categorial_features_indices, \n",
    "                verbose = True)\n",
    "        print(model_name, 'Did warmup:', time.time() - time_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3o7BpD-ZP1ce"
   },
   "outputs": [],
   "source": [
    "def trainModels(epoch, training_list, y_train):\n",
    "    global print_trained_string, saved_df_buffer, saved_y_buffer, time_train, nn_epochs\n",
    "\n",
    "    time_now = time.time()\n",
    "\n",
    "    if do_gather_dataset or use_models[\"CatBoost\"] == 1:\n",
    "        df = pd.DataFrame(training_list)\n",
    "        df = df.astype(dtype = features_dtypes)\n",
    "\n",
    "        if do_gather_dataset:\n",
    "            model_df_buffer_lock.acquire()\n",
    "            saved_df_buffer = pd.concat([saved_df_buffer, df])\n",
    "            saved_y_buffer += y_train\n",
    "            model_df_buffer_lock.release()\n",
    "\n",
    "    model_training_lock.acquire()\n",
    "    time_now = time.time()\n",
    "\n",
    "    if time_train < seconds_inbetween - 1 and time_big < seconds_inbetween - 1:\n",
    "        nn_epochs += 1\n",
    "    elif (time_train > seconds_inbetween - 0.5 or time_big > seconds_inbetween - 0.5) and nn_epochs > 1:\n",
    "        nn_epochs -= 1\n",
    "\n",
    "    if do_training and nn_epochs > 0:\n",
    "\n",
    "        if use_models[\"NN\"] == 1:\n",
    "            training_ds = clean_data_for_NN(training_list, y_train)\n",
    "            for model_name, model in models.items():\n",
    "                if \"NN\" in model_name:\n",
    "                    model.fit(training_ds,\n",
    "                            epochs = nn_epochs,\n",
    "                            verbose = do_training_verbose)\n",
    "        if use_models[\"CatBoost\"] == 1:\n",
    "            for model_name, model in models.items():\n",
    "                if \"CatBoost\" in model_name:\n",
    "                    model.fit(df, \n",
    "                            y_train, \n",
    "                            cat_features = categorial_features_indices, \n",
    "                            verbose = do_training_verbose)\n",
    "\n",
    "        if epoch % save_models_every_epochs == 0:\n",
    "            model_saving_lock.acquire()\n",
    "            save() # Save models\n",
    "            model_saving_lock.release()\n",
    "            print('Models saved.')\n",
    "\n",
    "    time_train = time.time() - time_now\n",
    "\n",
    "    model_training_lock.release()\n",
    "\n",
    "    print_trained_string = '[Trained ' + str(len(y_train)) + ' [' + str(round(time_train, 2)) + ' s]  ' + str(nn_epochs) + ' epochs ]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnK91M6QN-0Z"
   },
   "source": [
    "### save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kvDVMCMZBof"
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    global saved_df_buffer, saved_y_buffer\n",
    "    time_now = time.time()\n",
    "\n",
    "    if do_training:\n",
    "        for model_name, model in models.items():\n",
    "            if \"NN\" in model_name and use_models[\"NN\"] == 1:\n",
    "                try:\n",
    "                    model.save(root_dir + '/nn/' + model_name)\n",
    "                except Exception as e:\n",
    "                    print('SAVE FAILED:', model_name)\n",
    "                    print(e)\n",
    "            if \"CatBoost\" in model_name and use_models[\"CatBoost\"] == 1:\n",
    "                joblib.dump(model, root_dir + '/catboost/' + model_name)\n",
    "\n",
    "    if do_gather_dataset:\n",
    "        if model_df_buffer_lock.locked():\n",
    "            model_df_buffer_lock.acquire() #\n",
    "            saved_df_buffer = pd.DataFrame()\n",
    "            saved_y_buffer = []\n",
    "            model_df_buffer_lock.release() #\n",
    "            print('Aborted save df.', round(time.time() - time_now, 2), 's')\n",
    "        else:\n",
    "            time_string = str(round(time.time()))\n",
    "            model_df_buffer_lock.acquire() #\n",
    "            df_import = saved_df_buffer\n",
    "            saved_df_buffer = pd.DataFrame()\n",
    "            y_import = saved_y_buffer\n",
    "            saved_y_buffer = []\n",
    "            model_df_buffer_lock.release() #\n",
    "            df_import.to_csv(root_dir + '/' + datasets_dir + '/' + time_string + '.csv', index = False)\n",
    "            joblib.dump(y_import, root_dir + '/' + datasets_dir + '/' + time_string + '.csv.y')\n",
    "            print('Saved df to', datasets_dir, '. ', round(time.time() - time_now, 2), 's', '', len(df_import.index), len(y_import))\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cy1D3bhURrj7"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFIUOLfp79nD",
    "outputId": "a5dcc5f5-10a6-4135-f415-f962b432341d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "init()\n",
    "schedule = sched.scheduler(time.time, time.sleep)\n",
    "while(1):\n",
    "    runner()\n",
    "    print('Next episode')\n",
    "\n",
    "\n",
    "# Last folder size: 8.35mb\n",
    "\n",
    "# TODO:\n",
    "# Add volatility indicator per coin/symbol \n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "f1rbiuNnTOAt",
    "jOlkyfhOWYPz",
    "xGyza51MbQ8i",
    "F8t4j-VCVPv_",
    "TZMtPNjERlzE",
    "sjsTJIZxAlzA",
    "rwAVJm55CSR5",
    "f1uHH3AlgtLF",
    "Zhk559ZXlIPx",
    "6HtKD9Wrmxi0",
    "9WPpdhuugYQd",
    "dFk0gn6wjwRx",
    "wKOMrV86wxf6",
    "lEkAlPZfk7cZ",
    "eiBXDbMQlU49",
    "C2TD04LYP0V2",
    "OnK91M6QN-0Z"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m97"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff03dcfaa4ea4c7dbcc7a6acd2b5152b484988a1b13020911f06ea29377d1915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
