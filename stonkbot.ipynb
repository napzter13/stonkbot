{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Men1oM4eRfAn"
   },
   "source": [
    "## Meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGdtNx2iqNc-"
   },
   "source": [
    "#### Settings:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J75iPCI_qQkL"
   },
   "outputs": [],
   "source": [
    "start_over = False                           # True will overwrite saved models with new models / False to Lock settings here.\n",
    "amount_of_symbols_per_action_sample = 3      # Symbols to propose per coin.\n",
    "aggregate_loss_history_epochs = 30           # Calculate aggregated loss based on last X epochs\n",
    "minimum_prediction_prob_trade_NextIsNone = 0.33      # Minimum 33% prediciton probability before taking action if Next option is None (out of 4 options)\n",
    "minimum_prediction_prob_trade_NextIsNotNone = 0.29   # Minimum 29% prediciton probability before taking action if Next option is another symbol (out of 4 options)\n",
    "binary_target_minimum_increase_min = 0.0005  #                 Minimum 0.05 % increase.\n",
    "binary_target_minimum_increase_max = 0.002   # Starting with more than 0.2  % increase.\n",
    "seconds_inbetween = 9                        # Seconds between handling training data.\n",
    "seconds_inbetween_pibeline = 3               # Seconds between cycling the pibeline.\n",
    "\n",
    "pred_epoch = 30                              # =  4.5  min    | Predict in how many epochs.\n",
    "interval_columns = 150                       # = 22.5  min    | Amount of epochs in history per sample.\n",
    "\n",
    "catboost_iterations = 7\n",
    "catboost_depth = 10\n",
    "catboost_learning_rate = 0.10\n",
    "catboost_one_hot_max_size = 0\n",
    "catboost_ctr_target_border_count = 50\n",
    "catboost_model_size_reg = 0\n",
    "catboost_max_ctr_complexity = 0\n",
    "catboost_l2_leaf_reg = None\n",
    "catboost_min_data_in_leaf = None\n",
    "catboost_random_strength = None\n",
    "catboost_bootstrap_type = 'Bernoulli'\n",
    "catboost_subsample = 0.5\n",
    "catboost_bagging_temperature = None\n",
    "\n",
    "is_google_colab, is_google_cloud = False, True\n",
    "datasets_dir = 'datasets12'\n",
    "\n",
    "real_wallet_dont_use_euro = 20\n",
    "do_real_money_trade = True                       # prod: True\n",
    "do_training = True                               # prod: True\n",
    "do_gather_dataset = False                        # prod: False\n",
    "model_name_for_trading = 'CatBoostAction'\n",
    "debug_symbol = 'SUNUSDT'\n",
    "use_models = \"NN\" # Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1rbiuNnTOAt"
   },
   "source": [
    "### load_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gqr5zV0_TOyj"
   },
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    global models\n",
    "\n",
    "    if not exists(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    if not exists(root_dir + '/' + datasets_dir):\n",
    "        os.mkdir(root_dir + '/' + datasets_dir)\n",
    "    if not exists(root_dir + '/catboost'):\n",
    "        os.mkdir(root_dir + '/catboost')\n",
    "    if not exists(root_dir + '/nn'):\n",
    "        os.mkdir(root_dir + '/nn')\n",
    "    \n",
    "    models_catboost, models_nn = {}, {}\n",
    "\n",
    "    for filename in os.listdir(root_dir + '/catboost/'):\n",
    "        if 'ipynb_checkpoints' in filename:\n",
    "            continue\n",
    "        models_catboost[filename] = joblib.load(root_dir + '/catboost/' + filename)\n",
    "\n",
    "    for filename in os.listdir(root_dir + '/nn/'):\n",
    "        if 'ipynb_checkpoints' in filename:\n",
    "            continue\n",
    "        models_nn[filename] = tf.keras.models.load_model(root_dir + '/nn/' + filename)\n",
    "\n",
    "    if use_models == \"NN\":\n",
    "        models = models_nn\n",
    "    else:\n",
    "        models = models_catboost\n",
    "\n",
    "    models = sorted(models.items(), key=lambda x: x[0], reverse=False)\n",
    "    models = {k: v for k, v in models}\n",
    "\n",
    "    for model_name, _ in models.items():\n",
    "        print(model_name + ' loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOlkyfhOWYPz"
   },
   "source": [
    "### create_models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WkttSkCNWZ2z"
   },
   "outputs": [],
   "source": [
    "def create_models():\n",
    "    if len(models.keys()) == 0 or start_over:\n",
    "        if use_models == \"NN\":\n",
    "            data = create_model_nn('NNAction')\n",
    "        else:\n",
    "            data = create_model_catboost('CatBoostAction')\n",
    "        models[data[0]] = data[1]\n",
    "        print(data[0] + ' model created!')\n",
    "\n",
    "def create_model_nn(name):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=2))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss=' categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return name, model\n",
    "\n",
    "def create_model_catboost(name):\n",
    "    param = {\n",
    "        \"iterations\": catboost_iterations,\n",
    "        \"depth\": catboost_depth,\n",
    "        'learning_rate': catboost_learning_rate,\n",
    "        \"one_hot_max_size\": catboost_one_hot_max_size,\n",
    "        \"ctr_target_border_count\": catboost_ctr_target_border_count,\n",
    "        \"model_size_reg\": catboost_model_size_reg,\n",
    "        \"max_ctr_complexity\": catboost_max_ctr_complexity,\n",
    "        'l2_leaf_reg': catboost_l2_leaf_reg,\n",
    "        'min_data_in_leaf': catboost_min_data_in_leaf,\n",
    "        'random_strength': catboost_random_strength,\n",
    "        \"bootstrap_type\": catboost_bootstrap_type,\n",
    "\n",
    "        \"objective\": \"MultiClass\",\n",
    "        \"allow_const_label\": True,\n",
    "        \"task_type\": \"GPU\", \n",
    "        \"has_time\": True, \n",
    "        \"class_names\": possible_labels,\n",
    "        \"random_state\": 420,\n",
    "        \"allow_writing_files\": False,\n",
    "        \"boosting_type\": \"Plain\",\n",
    "    }\n",
    "    if catboost_bootstrap_type == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = catboost_bagging_temperature\n",
    "    elif catboost_bootstrap_type == \"Bernoulli\":\n",
    "        param[\"subsample\"] = catboost_subsample\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "\n",
    "    return name, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGyza51MbQ8i",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### populate_coins_to_pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cMaypnE0AUsi"
   },
   "outputs": [],
   "source": [
    "def validateActiveTickerSymbol(ticker):\n",
    "    if float(ticker['lastPrice']) < 0.0000001 or float(ticker['bidPrice']) < 0.0000001 or float(ticker['askPrice']) < 0.0000001:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def populate_coins_to_pairs():\n",
    "    global avaiable_coins, avaiable_symbols_list\n",
    "    avaiable_coins = {}\n",
    "    avaiable_symbols_list = []\n",
    "\n",
    "    balances = binance.get_account()['balances']\n",
    "    tickers = binance.get_ticker() # All symbol info\n",
    "\n",
    "\n",
    "    for balance in balances:\n",
    "        coin = balance['asset']\n",
    "        avaiable_coins[coin] = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        if not validateActiveTickerSymbol(ticker):\n",
    "            continue\n",
    "        symbol = ticker['symbol']\n",
    "\n",
    "        found = False\n",
    "        for balance in balances:\n",
    "            coin = balance['asset']\n",
    "            if isCoinPairMatching(coin, symbol):\n",
    "              avaiable_coins[coin].append(symbol)\n",
    "              found = True\n",
    "        if found:\n",
    "            avaiable_symbols_list.append(symbol)\n",
    "\n",
    "def isCoinPairMatching(coin, symbol):\n",
    "    if coin not in symbol:\n",
    "        return False\n",
    "    \n",
    "    symbols = [\"BTCUP\", \"BTCDOWN\", \"ADAUP\", \"ADADOWN\", \"ETHUP\", \"ETHDOWN\", \"DOTUP\", \"DOTDOWN\", \"TRXUP\", \"TRXDOWN\", \"LINKUP\", \"LINKDOWN\", \\\n",
    "                \"BNBUP\", \"BNBDOWN\", \"CRH\"]\n",
    "    if any(x in symbol for x in symbols):\n",
    "        return False\n",
    "\n",
    "    if coin == 'AMB':\n",
    "        similars = [\"CREAMBUSD\", \"BEAM\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False \n",
    "    elif coin == 'AUD':\n",
    "        similars = [\"AUDIO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TRU':\n",
    "        similars = [\"ASTRUSDT\", \"USDTRUB\", \"DOT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TUSD':\n",
    "        similars = [\"TUSDT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GAL':\n",
    "        similars = [\"GALA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'BTC':\n",
    "        similars = [\"BTCST\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'OG':\n",
    "        similars = [\"DOGE\", \"OGN\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'COS':\n",
    "        similars = [\"COCOS\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'RUB':\n",
    "        similars = [\"TRUBTC\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'SHIB':\n",
    "        similars = [\"SUSHIBTC\", \"SUSHIBUSD\", \"SUSHIBNB\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'FET':\n",
    "        similars = [\"ELFETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'YFI':\n",
    "        similars = [\"YFII\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TRB':\n",
    "        similars = [\"ASTRBTC\", \"ASTRBUSD\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'BAR':\n",
    "        similars = [\"HBAR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'SC':\n",
    "        similars = [\"SCRT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'REP':\n",
    "        similars = [\"DREP\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GO':\n",
    "        similars = [\"AERGO\", \"ALGO\", \"DEGO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AST':\n",
    "        similars = [\"ASTR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AST':\n",
    "        similars = [\"CRVETH\", \"SSVETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ONE':\n",
    "        similars = [\"AIONETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'GLM':\n",
    "        similars = [\"GLMR\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'DAR':\n",
    "        similars = [\"ADARUB\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'VET':\n",
    "        similars = [\"CRVETH\", \"SSVETH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OXT':\n",
    "        similars = [\"MBOXTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'ACA':\n",
    "        similars = [\"ALPACA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ONT':\n",
    "        similars = [\"FRONT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'TCT':\n",
    "        similars = [\"BTCTUSD\", \"BTTCTRY\", \"BTCTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'AMP':\n",
    "        similars = [\"RAMP\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'WBTC':\n",
    "        similars = [\"FLOWBTC\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'LPT':\n",
    "        similars = [\"SLPTRY\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'PHA':\n",
    "        similars = [\"ALPHA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'AVA':\n",
    "        similars = [\"KAVA\", \"AVAX\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'MOB':\n",
    "        similars = [\"TOMO\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'ORN':\n",
    "        similars = [\"TORN\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OM':\n",
    "        similars = [\"OMG\", \"ATOM\", \"COMP\", \"LOOM\", \"TOMO\", \"PROM\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'AR':\n",
    "        similars = [\"ARDR\", \"ARK\", \"ARPA\", \"BAR\", \"FARM\", \"HARD\", \"HBAR\", \"NEAR\", \"RARE\", \"DAR\", \"SPARTA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ATA':\n",
    "        similars = [\"DATA\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'ANT':\n",
    "        similars = [\"SANTOS\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'WIN':\n",
    "        similars = [\"WING\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'BUSD':\n",
    "        similars = [\"BNBUSDC\", \"TRBUSDT\", \"MOBUSDT\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin == 'OP':\n",
    "        similars = [\"PEOPLE\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'FOR':\n",
    "        similars = [\"FORTH\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "            return False\n",
    "    elif coin == 'CKB':\n",
    "        similars = [\"DOCK\", \"QUICK\"]\n",
    "        if any(x in symbol for x in similars):\n",
    "           return False\n",
    "    elif coin in ['BETH', 'BDOT', 'T']:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8t4j-VCVPv_",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### initBinanceInfo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hwLwVhYLVRg9"
   },
   "outputs": [],
   "source": [
    "def initBinanceInfo():\n",
    "    global binance_symbols\n",
    "\n",
    "    get_exchange_info = binance.get_exchange_info()\n",
    "    for symbol in get_exchange_info['symbols']:\n",
    "        if symbol['symbol'] in avaiable_symbols_list:\n",
    "            stepSize = 0\n",
    "            stepSizeInteger = 0\n",
    "            tickSize = 0\n",
    "            minNotional = 0\n",
    "            for filter in symbol['filters']:\n",
    "                if filter['filterType'] == 'LOT_SIZE':\n",
    "                    stepSize = float(filter['stepSize'])\n",
    "                    if filter['stepSize'] == '0.10000000':\n",
    "                        stepSizeInteger = 1\n",
    "                    elif filter['stepSize'] == '0.01000000':\n",
    "                        stepSizeInteger = 2\n",
    "                    elif filter['stepSize'] == '0.00100000':\n",
    "                        stepSizeInteger = 3\n",
    "                    elif filter['stepSize'] == '0.00010000':\n",
    "                        stepSizeInteger = 4\n",
    "                    elif filter['stepSize'] == '0.00001000':\n",
    "                        stepSizeInteger = 5\n",
    "                    elif filter['stepSize'] == '0.00000100':\n",
    "                        stepSizeInteger = 6\n",
    "                    elif filter['stepSize'] == '0.00000010':\n",
    "                        stepSizeInteger = 7\n",
    "                    elif filter['stepSize'] == '0.00000001':\n",
    "                        stepSizeInteger = 8\n",
    "                elif filter['filterType'] == 'PRICE_FILTER':\n",
    "                    if filter['tickSize'] == '0.10000000':\n",
    "                        tickSize = 1\n",
    "                    elif filter['tickSize'] == '0.01000000':\n",
    "                        tickSize = 2\n",
    "                    elif filter['tickSize'] == '0.00100000':\n",
    "                        tickSize = 3\n",
    "                    elif filter['tickSize'] == '0.00010000':\n",
    "                        tickSize = 4\n",
    "                    elif filter['tickSize'] == '0.00001000':\n",
    "                        tickSize = 5\n",
    "                    elif filter['tickSize'] == '0.00000100':\n",
    "                        tickSize = 6\n",
    "                    elif filter['tickSize'] == '0.00000010':\n",
    "                        tickSize = 7\n",
    "                    elif filter['tickSize'] == '0.00000001':\n",
    "                        tickSize = 8\n",
    "                elif filter['filterType'] == 'MIN_NOTIONAL':\n",
    "                    minNotional = float(filter['minNotional'])\n",
    "\n",
    "            binance_symbols[symbol['symbol']] = {\n",
    "                'stepSize': stepSize,\n",
    "                'stepSizeInteger': stepSizeInteger,\n",
    "                'tickSize': tickSize,\n",
    "                'minNotional': minNotional,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZMtPNjERlzE"
   },
   "source": [
    "### init_meta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5J-bgr9_RQOz",
    "outputId": "3bbd267c-d865-4946-e2b2-59e3eeb38f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: catboost in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from catboost) (1.5.0)\n",
      "Requirement already satisfied: six in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from catboost) (1.22.3)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from catboost) (3.6.0)\n",
      "Requirement already satisfied: graphviz in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from catboost) (5.10.0)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from catboost) (1.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from pandas>=0.24.0->catboost) (2022.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from matplotlib->catboost) (4.37.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from matplotlib->catboost) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib->catboost) (3.0.8)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from matplotlib->catboost) (9.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from plotly->catboost) (8.1.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: python-binance in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (1.0.16)\n",
      "Requirement already satisfied: dateparser in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from python-binance) (1.1.1)\n",
      "Requirement already satisfied: aiohttp in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from python-binance) (3.8.3)\n",
      "Requirement already satisfied: six in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from python-binance) (1.16.0)\n",
      "Requirement already satisfied: ujson in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from python-binance) (5.5.0)\n",
      "Requirement already satisfied: websockets in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from python-binance) (10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from python-binance) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->python-binance) (2.0.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from aiohttp->python-binance) (1.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from aiohttp->python-binance) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from aiohttp->python-binance) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from aiohttp->python-binance) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from aiohttp->python-binance) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from aiohttp->python-binance) (22.1.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from dateparser->python-binance) (2.8.2)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from dateparser->python-binance) (2022.2.1)\n",
      "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from dateparser->python-binance) (2022.3.2)\n",
      "Requirement already satisfied: tzlocal in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from dateparser->python-binance) (4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from requests->python-binance) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from requests->python-binance) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from requests->python-binance) (2021.10.8)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tzlocal->dateparser->python-binance) (0.1.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tzlocal->dateparser->python-binance) (2022.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (65.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from packaging->tensorflow) (3.0.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nap\\appdata\\roaming\\python\\python39\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\envs\\py39gpu\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "root_dir = 'models' \n",
    "categorial_features = ['direction_', 'symbol', 'coin']\n",
    "\n",
    "if is_google_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    root_dir = 'drive/MyDrive/tradebot'\n",
    "\n",
    "if is_google_colab or is_google_cloud:\n",
    "    !pip install catboost\n",
    "    !pip install python-binance\n",
    "    !pip install tensorflow\n",
    "\n",
    "import os, psutil\n",
    "from os.path import exists\n",
    "\n",
    "from catboost import *\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from binance import Client\n",
    "from binance.enums import *\n",
    "\n",
    "import sched, time\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "from threading import Thread, Lock\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "models = {}\n",
    "categorial_features_indices = None\n",
    "holding_coins = None\n",
    "features_list = None\n",
    "features_dtypes = None\n",
    "avaiable_coins = None\n",
    "avaiable_symbols_list = None\n",
    "\n",
    "possible_labels = ['NONE']\n",
    "for i in range(0, amount_of_symbols_per_action_sample):\n",
    "    possible_labels.append(str(i))\n",
    "\n",
    "binance_api_key = 'AoVFfn3JvetSRHpffstx9tg0Zlmzc6WHeAdVjVUnLfbzOTslBanPUMFa7bP4CqtU'\n",
    "binance_api_secret = 'zNGuMcE2UcycFQeVhTi5o9psM6GjZHvg7gEcTu1f8pazQg42EAMgvma5G583wv4G'\n",
    "binance = Client(binance_api_key, binance_api_secret)\n",
    "\n",
    "##### :\n",
    "epoch, part_epoch, total_part_epochs = 1, 1, 0\n",
    "memory_data = []\n",
    "memory_symbols = {}\n",
    "predictions_saved = []\n",
    "deleted_symbol_data = 0\n",
    "print_trained_string = '---'\n",
    "loss_string = '-'\n",
    "model_training_lock = None\n",
    "model_df_buffer_lock = None\n",
    "handleTickers_lock = None\n",
    "binance_symbols = {} #\n",
    "dont_update_holding_coins = []\n",
    "dont_update_holding_coins_buffer = {}\n",
    "cancel_orders = False\n",
    "temp_tickers = {}\n",
    "do_predictions = True\n",
    "saved_df_buffer = pd.DataFrame()\n",
    "saved_y_buffer = []\n",
    "init_time = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7XiN8nxrY1HI",
    "outputId": "d04b8f43-43d0-40dd-cfb1-614f5cc0813e"
   },
   "outputs": [
    {
     "ename": "BinanceAPIException",
     "evalue": "APIError(code=-1021): Timestamp for this request is outside of the recvWindow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBinanceAPIException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m populate_coins_to_pairs()\n\u001b[0;32m      2\u001b[0m initBinanceInfo()\n\u001b[0;32m      3\u001b[0m load_models()\n",
      "Cell \u001b[1;32mIn [14], line 11\u001b[0m, in \u001b[0;36mpopulate_coins_to_pairs\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m avaiable_coins \u001b[39m=\u001b[39m {}\n\u001b[0;32m      9\u001b[0m avaiable_symbols_list \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 11\u001b[0m balances \u001b[39m=\u001b[39m binance\u001b[39m.\u001b[39;49mget_account()[\u001b[39m'\u001b[39m\u001b[39mbalances\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     12\u001b[0m tickers \u001b[39m=\u001b[39m binance\u001b[39m.\u001b[39mget_ticker() \u001b[39m# All symbol info\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m balance \u001b[39min\u001b[39;00m balances:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\binance\\client.py:1968\u001b[0m, in \u001b[0;36mClient.get_account\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m   1931\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_account\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m   1932\u001b[0m     \u001b[39m\"\"\"Get current account information.\u001b[39;00m\n\u001b[0;32m   1933\u001b[0m \n\u001b[0;32m   1934\u001b[0m \u001b[39m    https://binance-docs.github.io/apidocs/spot/en/#account-information-user_data\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \n\u001b[0;32m   1967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1968\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(\u001b[39m'\u001b[39;49m\u001b[39maccount\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m, data\u001b[39m=\u001b[39;49mparams)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\binance\\client.py:371\u001b[0m, in \u001b[0;36mClient._get\u001b[1;34m(self, path, signed, version, **kwargs)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, path, signed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, version\u001b[39m=\u001b[39mBaseClient\u001b[39m.\u001b[39mPUBLIC_API_VERSION, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 371\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request_api(\u001b[39m'\u001b[39m\u001b[39mget\u001b[39m\u001b[39m'\u001b[39m, path, signed, version, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\binance\\client.py:334\u001b[0m, in \u001b[0;36mClient._request_api\u001b[1;34m(self, method, path, signed, version, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_request_api\u001b[39m(\n\u001b[0;32m    331\u001b[0m     \u001b[39mself\u001b[39m, method, path: \u001b[39mstr\u001b[39m, signed: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, version\u001b[39m=\u001b[39mBaseClient\u001b[39m.\u001b[39mPUBLIC_API_VERSION, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    332\u001b[0m ):\n\u001b[0;32m    333\u001b[0m     uri \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_api_uri(path, signed, version)\n\u001b[1;32m--> 334\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(method, uri, signed, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\binance\\client.py:315\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, method, uri, signed, force_params, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_request_kwargs(method, signed, force_params, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession, method)(uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 315\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_response(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresponse)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\py39gpu\\lib\\site-packages\\binance\\client.py:324\u001b[0m, in \u001b[0;36mClient._handle_response\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39m\"\"\"Internal helper for handling API responses from the Binance server.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39mRaises the appropriate exceptions when necessary; otherwise, returns the\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[39mresponse.\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 324\u001b[0m     \u001b[39mraise\u001b[39;00m BinanceAPIException(response, response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n\u001b[0;32m    325\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "\u001b[1;31mBinanceAPIException\u001b[0m: APIError(code=-1021): Timestamp for this request is outside of the recvWindow."
     ]
    }
   ],
   "source": [
    "populate_coins_to_pairs()\n",
    "initBinanceInfo()\n",
    "load_models()\n",
    "create_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AzHvj-pYFMJ"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjsTJIZxAlzA"
   },
   "source": [
    "### Init:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuFLPr_78efB"
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    global holding_coins, do_predictions, model_training_lock, model_df_buffer_lock, \\\n",
    "    epoch, part_epoch, total_part_epochs, memory_data, memory_symbols, predictions_saved, \\\n",
    "    deleted_symbol_data, print_trained_string, loss_string, saved_y_buffer, \\\n",
    "    dont_update_holding_coins, dont_update_holding_coins_buffer, \\\n",
    "    cancel_orders, temp_tickers, saved_df_buffer, \\\n",
    "    handleTickers_lock, init_time\n",
    "\n",
    "    initBinanceInfo()\n",
    "\n",
    "    epoch, part_epoch, total_part_epochs = 1, 1, 0\n",
    "    memory_data = []\n",
    "    memory_symbols = {}\n",
    "    predictions_saved = []\n",
    "    deleted_symbol_data = 0\n",
    "    print_trained_string = '---'\n",
    "    loss_string = '-'\n",
    "    model_training_lock = None\n",
    "    model_df_buffer_lock = None\n",
    "    handleTickers_lock = None\n",
    "    dont_update_holding_coins = []\n",
    "    dont_update_holding_coins_buffer = {}\n",
    "    cancel_orders = False\n",
    "    temp_tickers = {}\n",
    "    do_predictions = True\n",
    "    saved_df_buffer = pd.DataFrame()\n",
    "    saved_y_buffer = []\n",
    "    init_time = time.time()\n",
    "\n",
    "    holding_coins = {\n",
    "        'DEFAULT': {\n",
    "            'balance': 0,\n",
    "            'balance_eur': 1,\n",
    "            'price': 0,\n",
    "            'counting_epochs': 0,\n",
    "            'symbol': '',\n",
    "            'date': time.strftime(\"%H:%M:%S\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        if not model.is_fitted():\n",
    "            do_predictions = False\n",
    "\n",
    "    model_training_lock = Lock()\n",
    "    model_df_buffer_lock = Lock()\n",
    "    handleTickers_lock = Lock()\n",
    "\n",
    "    print(\"\"\"\\\n",
    "                        ._ o o\n",
    "                        \\_`-)|_\n",
    "                      ,\"\"       \\ \n",
    "                    ,\"  ## |   = ಠ. \n",
    "                  ,\" ##   ,-\\__    `.\n",
    "                ,\"       /     `--._;)\n",
    "              ,\"     ## /\n",
    "            ,\"   ##    /\n",
    "███████╗████████╗ ██████╗ ███╗   ██╗██╗  ██╗██████╗  ██████╗ ████████╗\n",
    "██╔════╝╚══██╔══╝██╔═══██╗████╗  ██║██║ ██╔╝██╔══██╗██╔═══██╗╚══██╔══╝\n",
    "███████╗   ██║   ██║   ██║██╔██╗ ██║█████╔╝ ██████╔╝██║   ██║   ██║   \n",
    "╚════██║   ██║   ██║   ██║██║╚██╗██║██╔═██╗ ██╔══██╗██║   ██║   ██║   \n",
    "███████║   ██║   ╚██████╔╝██║ ╚████║██║  ██╗██████╔╝╚██████╔╝   ██║   \n",
    "╚══════╝   ╚═╝    ╚═════╝ ╚═╝  ╚═══╝╚═╝  ╚═╝╚═════╝  ╚═════╝    ╚═╝   v0.2\n",
    "                                                                      \n",
    "                    \"\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwAVJm55CSR5"
   },
   "source": [
    "### Runner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uZ0wly0CZA9"
   },
   "outputs": [],
   "source": [
    "def runner():\n",
    "    global schedule, epoch, part_epoch, total_part_epochs, init_time\n",
    "    time_now = time.time()\n",
    "    \n",
    "    getTickers(part_epoch)\n",
    "\n",
    "    if part_epoch == (seconds_inbetween / seconds_inbetween_pibeline) - 1:\n",
    "        thread = Thread(target = updateBinanceBalances)\n",
    "        thread.start()\n",
    "\n",
    "    if seconds_inbetween / seconds_inbetween_pibeline <= part_epoch:\n",
    "        processTickers()\n",
    "        thread = Thread(target = handleTickers, args = (time_now, epoch, memory_symbols,))\n",
    "        thread.start()\n",
    "        epoch += 1\n",
    "        part_epoch = 0\n",
    "    part_epoch += 1\n",
    "    total_part_epochs += 1\n",
    "    # 459: 6 sec break..\n",
    "    if total_part_epochs == 460:\n",
    "        sleepy = (seconds_inbetween_pibeline * total_part_epochs) - (time.time() - init_time) - seconds_inbetween_pibeline + 2.5\n",
    "        if sleepy < 0:\n",
    "          sleepy = 0\n",
    "        print('sleepy', sleepy)\n",
    "        time.sleep(sleepy)\n",
    "        init_time = time.time()\n",
    "        total_part_epochs = 0\n",
    "        return\n",
    "\n",
    "    schedule.enter((seconds_inbetween_pibeline * total_part_epochs) - (time.time() - init_time) - seconds_inbetween_pibeline, 1, runner)\n",
    "    schedule.run()\n",
    "\n",
    "def getTickers(part_epoch):\n",
    "  global temp_tickers\n",
    "\n",
    "  try:\n",
    "      tickers = binance.get_ticker() # All symbol info\n",
    "  except:\n",
    "      print('binance.get_ticker() FAILED 1/2.')\n",
    "      try:\n",
    "          tickers = binance.get_ticker() # All symbol info\n",
    "      except:\n",
    "          print('binance.get_ticker() FAILED 2/2.')\n",
    "          return\n",
    "  \n",
    "  if part_epoch == 1:\n",
    "      for symbol in tickers:\n",
    "          if symbol['symbol'] not in avaiable_symbols_list:\n",
    "              continue\n",
    "          temp_tickers[symbol['symbol']] = {\n",
    "              'symbol': symbol['symbol'],\n",
    "              'bidPrice_low': float(symbol['bidPrice']),\n",
    "              'bidPrice_high': float(symbol['bidPrice']),\n",
    "              'askPrice_low': float(symbol['askPrice']),\n",
    "              'askPrice_high': float(symbol['askPrice']),\n",
    "              'volume': float(symbol['volume']),\n",
    "              'quoteVolume': float(symbol['quoteVolume']),\n",
    "              'tradeCount': int(symbol['count']),\n",
    "              'lastPrice': float(symbol['lastPrice']),\n",
    "          }\n",
    "        \n",
    "  else:\n",
    "      for symbol in tickers:\n",
    "          if symbol['symbol'] not in avaiable_symbols_list:\n",
    "              continue\n",
    "        \n",
    "          new_bidPrice = float(symbol['bidPrice'])\n",
    "          new_askPrice = float(symbol['askPrice'])\n",
    "          \n",
    "          temp_tickers[symbol['symbol']] = {\n",
    "              'symbol': symbol['symbol'],\n",
    "              'bidPrice_low': new_bidPrice if temp_tickers[symbol['symbol']]['bidPrice_low'] > new_bidPrice else temp_tickers[symbol['symbol']]['bidPrice_low'],\n",
    "              'bidPrice_high': new_bidPrice if temp_tickers[symbol['symbol']]['bidPrice_high'] < new_bidPrice else temp_tickers[symbol['symbol']]['bidPrice_high'],\n",
    "              'askPrice_low': new_askPrice if temp_tickers[symbol['symbol']]['askPrice_low'] > new_askPrice else temp_tickers[symbol['symbol']]['askPrice_low'],\n",
    "              'askPrice_high': new_askPrice if temp_tickers[symbol['symbol']]['askPrice_high'] < new_askPrice else temp_tickers[symbol['symbol']]['askPrice_high'],\n",
    "              'volume': float(symbol['volume']),\n",
    "              'quoteVolume': float(symbol['quoteVolume']),\n",
    "              'tradeCount': int(symbol['count']),\n",
    "              'lastPrice': float(symbol['lastPrice']),\n",
    "          }\n",
    "        \n",
    "          # if new_bidPrice == 0 or new_askPrice == 0:\n",
    "          #     print(symbol)\n",
    "          #     del temp_tickers[symbol['symbol']]\n",
    "          #     del memory_symbols[symbol['symbol']]\n",
    "          #     avaiable_symbols_list.remove(symbol['symbol'])\n",
    "          #     print(symbol['symbol'], 'removed.', symbol['bidPrice'], symbol['askPrice'])\n",
    "\n",
    "def processTickers():\n",
    "    global memory_symbols\n",
    "    for coin in temp_tickers.values():\n",
    "        if coin['symbol'] not in memory_symbols:\n",
    "            memory_symbols[coin['symbol']] = {\n",
    "                'bidPrice_low': [],\n",
    "                'bidPrice_high': [],\n",
    "                'askPrice_low': [],\n",
    "                'askPrice_high': [],\n",
    "                'volume': [],\n",
    "                'quoteVolume': [],\n",
    "                'tradeCount': [],\n",
    "                'lastPrice': [],\n",
    "            }\n",
    "        memory_symbols[coin['symbol']]['bidPrice_low'].append(coin['bidPrice_low'])\n",
    "        memory_symbols[coin['symbol']]['bidPrice_high'].append(coin['bidPrice_high'])\n",
    "        memory_symbols[coin['symbol']]['askPrice_low'].append(coin['askPrice_low'])\n",
    "        memory_symbols[coin['symbol']]['askPrice_high'].append(coin['askPrice_high'])\n",
    "        memory_symbols[coin['symbol']]['volume'].append(coin['volume'])\n",
    "        memory_symbols[coin['symbol']]['quoteVolume'].append(coin['quoteVolume'])\n",
    "        memory_symbols[coin['symbol']]['tradeCount'].append(coin['tradeCount'])\n",
    "        memory_symbols[coin['symbol']]['lastPrice'].append(coin['lastPrice'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1uHH3AlgtLF"
   },
   "source": [
    "### MAIN Thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JA60IEuagyml"
   },
   "outputs": [],
   "source": [
    "def handleTickers(time_now_big, epoch, memory_symbols):\n",
    "    global memory_data, deleted_symbol_data, print_trained_string, do_predictions, do_predictions, \\\n",
    "    predictions_saved, handleTickers_Lock, categorial_features_indices, features_dtypes, features_list\n",
    "\n",
    "    # Get list of symbols to check:\n",
    "    use_symbols = []\n",
    "    for coin in holding_coins.keys():\n",
    "        use_symbols += avaiable_coins[coin]\n",
    "\n",
    "    memory_data_symbol = None\n",
    "    predictions_byModel = [\n",
    "        {},\n",
    "        '0',\n",
    "    ]\n",
    "    \n",
    "    handleTickers_lock.acquire() #\n",
    "    print('--------  Epoch: ', epoch, '  [' + str(time.strftime(\"%H:%M:%S\")) + ']')\n",
    "    print()\n",
    "\n",
    "    # Proccess coin data\n",
    "    proccessTickers_time = ''\n",
    "    if epoch > 1:\n",
    "        time_big_itcp = time.time() - time_now_big\n",
    "        time_now = time.time()\n",
    "        memory_data_symbol = proccessTickers(epoch, memory_symbols, True, use_symbols)\n",
    "        proccessTickers_time = str(round(time_big_itcp, 2)) + ' + ' + str(round(time.time() - time_now, 2))\n",
    "\n",
    "    if epoch > pred_epoch:\n",
    "        # Process Action Data\n",
    "        time_now = time.time()\n",
    "        saved = processActionData(epoch, memory_data_symbol, True)\n",
    "        proccessTickers_time += ' + ' + str(round(time.time() - time_now, 2))\n",
    "\n",
    "        ## Init Set features_dtypes & categorial_features_indices ##\n",
    "        if epoch == pred_epoch + 1:\n",
    "            features_list = list(saved[list(holding_coins.keys())[0]].keys())\n",
    "            features_dtypes = {}\n",
    "            categorial_features_indices = []\n",
    "            i = 0\n",
    "            for feature in features_list:\n",
    "                if any(x in feature for x in categorial_features):\n",
    "                    categorial_features_indices.append(i)\n",
    "                i += 1\n",
    "                if 'coin' in feature or 'symbol' in feature or 'direction_' in feature:\n",
    "                    features_dtypes[feature] = 'object'\n",
    "                else:\n",
    "                    features_dtypes[feature] = 'float32'\n",
    "        ####\n",
    "\n",
    "        if do_predictions:\n",
    "            # Do Predictions:\n",
    "            predictions_byModel = proccessPredictions(epoch, saved)\n",
    "\n",
    "\n",
    "    # Balances and euro:\n",
    "    print_eur_string = convert_wallet_to_euro(holding_coins, memory_symbols, epoch)\n",
    "    print('[ ' + print_eur_string + ' ]   _ Balances:')\n",
    "    for coin, inner in holding_coins.items():\n",
    "        print(coin, str(round(inner['balance'], 4)), '', str(round(inner['balance_eur'], 2)) + ' €', '   |  Price: ' + str(inner['price']) + ' ' + inner['symbol'] + '  | Epoch: ' + str(inner['counting_epochs']) + '       [' + inner['date'] + ']')\n",
    "    print()\n",
    "    \n",
    "    # Trade coins:\n",
    "    if do_predictions and epoch > interval_columns + pred_epoch + 50:\n",
    "        processTrading(predictions_byModel[0], epoch, memory_symbols)\n",
    "    #\n",
    "\n",
    "    # Now build data for the rest of the coins and symbols:\n",
    "    if epoch > 1:\n",
    "        memory_data_symbol = proccessTickers(epoch, memory_symbols, False, None)\n",
    "\n",
    "        # Start updating symbol priority list into avaiable_coins:\n",
    "        thread = Thread(target = updateSymbolPriorityList, args = (memory_data_symbol,))\n",
    "        thread.start()\n",
    "\n",
    "    if epoch > pred_epoch:\n",
    "        memory_data.append(processActionData(epoch, memory_data_symbol, False))\n",
    "    #\n",
    "    \n",
    "    if epoch % 20 == 0 and epoch > pred_epoch:\n",
    "        for model in models.values():\n",
    "            if model.is_fitted():\n",
    "                do_predictions = True\n",
    "            else:\n",
    "                do_predictions = False\n",
    "\n",
    "    \n",
    "    if epoch > pred_epoch:\n",
    "        predictions_saved.append(predictions_byModel[0])\n",
    "\n",
    "        # Do Validation on Past predictions:\n",
    "        training_list, y_train, validated_list_targets = validatePredictions(epoch, memory_symbols)\n",
    "        if do_predictions:\n",
    "            validatePastPredictions(validated_list_targets)\n",
    "            \n",
    "        if epoch == pred_epoch + interval_columns - 20:\n",
    "            # Do warmup:\n",
    "            print('Will try to do warmup now...')\n",
    "            thread = Thread(target = do_warmup, args = (training_list, y_train,))\n",
    "            thread.start()\n",
    "\n",
    "        elif epoch > pred_epoch + interval_columns:\n",
    "            # Do training:\n",
    "            thread = Thread(target = trainModels, args = (epoch, training_list, y_train,))\n",
    "            thread.start()\n",
    "\n",
    "\n",
    "    # Cleanup:\n",
    "    if epoch > interval_columns:\n",
    "        for k, value in memory_symbols.items():\n",
    "            del value['bidPrice_high'][0]\n",
    "            del value['bidPrice_low'][0]\n",
    "            del value['askPrice_high'][0]\n",
    "            del value['askPrice_low'][0]\n",
    "            del value['volume'][0]\n",
    "            del value['quoteVolume'][0]\n",
    "            del value['tradeCount'][0]\n",
    "            del value['lastPrice'][0]\n",
    "        deleted_symbol_data += 1\n",
    "    if len(memory_data) == pred_epoch:\n",
    "        del memory_data[0]\n",
    "        del predictions_saved[0]\n",
    "    ##\n",
    "    print('---------------- ', total_part_epochs, '[', round(time.time()-time_now_big, 2), 's ==', 't: ' + proccessTickers_time, '| p:', predictions_byModel[1], ']', \\\n",
    "          ' || ', print_trained_string, '|  Loss:', loss_string, ' |  RAM:', round(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2), 'mb')\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    handleTickers_lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhk559ZXlIPx"
   },
   "source": [
    "### proccessTickers():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XN5wC6Eni6s8"
   },
   "outputs": [],
   "source": [
    "def proccessTickers(epoch, memory_symbols, only_use_holding_symbols, use_symbols):\n",
    "    memory_data_symbol = {}\n",
    "\n",
    "    for symbol, inner in memory_symbols.items():\n",
    "        if only_use_holding_symbols and symbol not in use_symbols:\n",
    "            continue\n",
    "\n",
    "        dat = {\n",
    "              'symbol': symbol,                               # categorical\n",
    "              # 'weekday': str(currentime.weekday() + 1),     # categorical\n",
    "              # 'hour': str(currentime.hour + 1),             # categorical\n",
    "        }\n",
    "\n",
    "        temp_bidPrice_low = inner['bidPrice_low'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_bidPrice_high = inner['bidPrice_high'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_askPrice_low = inner['askPrice_low'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_askPrice_high = inner['askPrice_high'][epoch - 1 - deleted_symbol_data]\n",
    "        temp_volume = inner['volume'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_volume == 0:\n",
    "            temp_volume = 0.0000001\n",
    "        temp_quoteVolume = inner['quoteVolume'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_quoteVolume == 0:\n",
    "            temp_quoteVolume = 0.0000001\n",
    "        temp_tradeCount = inner['tradeCount'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_tradeCount == 0:\n",
    "            temp_tradeCount = 0.0000001\n",
    "        temp_lastPrice = inner['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "        if temp_lastPrice == 0:\n",
    "            temp_lastPrice = 0.0000001\n",
    "\n",
    "        seconds_ago = seconds_inbetween\n",
    "\n",
    "        for i in range(1, interval_columns + 1):\n",
    "            seconds_ago_string = str(seconds_ago)\n",
    "            if (epoch > i):\n",
    "                index = epoch - i - 1 - deleted_symbol_data\n",
    "                \n",
    "                bidPrice_low = inner['bidPrice_low'][index] # Reverse + Pick i element.\n",
    "                if bidPrice_low == 0:\n",
    "                    dat['bidPrice_low_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                else:\n",
    "                    dat['bidPrice_low_' + seconds_ago_string + '_secAgo'] = (temp_bidPrice_low - bidPrice_low) / bidPrice_low\n",
    "\n",
    "                bidPrice_high = inner['bidPrice_high'][index] # Reverse + Pick i element.\n",
    "                if bidPrice_high == 0:\n",
    "                    dat['bidPrice_high_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                else:\n",
    "                    dat['bidPrice_high_' + seconds_ago_string + '_secAgo'] = (temp_bidPrice_high - bidPrice_high) / bidPrice_high\n",
    "\n",
    "                askPrice_low = inner['askPrice_low'][index] # Reverse + Pick i element.\n",
    "                if askPrice_low == 0:\n",
    "                    dat['askPrice_low_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                else:\n",
    "                    dat['askPrice_low_' + seconds_ago_string + '_secAgo'] = (temp_askPrice_low - askPrice_low) / askPrice_low\n",
    "\n",
    "                askPrice_high = inner['askPrice_high'][index] # Reverse + Pick i element.\n",
    "                if askPrice_high == 0:\n",
    "                    dat['askPrice_high_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                else:\n",
    "                    dat['askPrice_high_' + seconds_ago_string + '_secAgo'] = (temp_askPrice_high - askPrice_high) / askPrice_high\n",
    "\n",
    "                volume = inner['volume'][index] # Reverse + Pick i element.\n",
    "                if volume == 0:\n",
    "                    volume = 0.0000001\n",
    "                dat['volume_' + seconds_ago_string + '_secAgo'] = (temp_volume - volume) / volume\n",
    "\n",
    "                quoteVolume = inner['quoteVolume'][index] # Reverse + Pick i element.\n",
    "                if quoteVolume == 0:\n",
    "                    quoteVolume = 0.0000001\n",
    "                dat['quoteVolume_' + seconds_ago_string + '_secAgo'] = (temp_quoteVolume - quoteVolume) / quoteVolume\n",
    "\n",
    "                tradeCount = inner['tradeCount'][index] # Reverse + Pick i element.\n",
    "                if tradeCount == 0:\n",
    "                    tradeCount = 0.0000001\n",
    "                dat['tradeCount_' + seconds_ago_string + '_secAgo'] = (temp_tradeCount - tradeCount) / tradeCount\n",
    "\n",
    "                lastPrice = inner['lastPrice'][index] # Reverse + Pick i element.\n",
    "                if lastPrice == 0:\n",
    "                    lastPrice = 0.0000001\n",
    "                dat['lastPrice_' + seconds_ago_string + '_secAgo'] = (temp_lastPrice - lastPrice) / lastPrice\n",
    "            else:\n",
    "                dat['bidPrice_low_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['bidPrice_high_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['askPrice_low_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['askPrice_high_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['volume_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['quoteVolume_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['tradeCount_' + seconds_ago_string + '_secAgo'] = 0\n",
    "                dat['lastPrice_' + seconds_ago_string + '_secAgo'] = 0\n",
    "\n",
    "            direction = 'BIGGEST_DOWN'\n",
    "            lastPrice = dat['lastPrice_' + seconds_ago_string + '_secAgo']\n",
    "            if lastPrice > 3:\n",
    "              direction = 'BIGGEST_UP'\n",
    "            elif lastPrice > 2:\n",
    "              direction = 'BIGGER_UP'\n",
    "            elif lastPrice > 1:\n",
    "              direction = 'BIG_UP'\n",
    "            elif lastPrice > 0.5:\n",
    "              direction = 'HALF_UP'\n",
    "            elif lastPrice > binary_target_minimum_increase_min * 2:\n",
    "              direction = 'UP_UP'\n",
    "            elif lastPrice > binary_target_minimum_increase_min:\n",
    "              direction = 'UP'\n",
    "            elif lastPrice > 0:\n",
    "              direction = 'NEUTRAL'\n",
    "            elif lastPrice == 0:\n",
    "              direction = 'NULL'\n",
    "            elif lastPrice > -binary_target_minimum_increase_min:\n",
    "              direction = 'DOWN'\n",
    "            elif lastPrice > -binary_target_minimum_increase_min * 2:\n",
    "              direction = 'DOWN_DOWN'\n",
    "            elif lastPrice > -0.5:\n",
    "              direction = 'DOWNER'\n",
    "            elif lastPrice > -1:\n",
    "              direction = 'HALF_DOWN'\n",
    "            elif lastPrice > -2:\n",
    "              direction = 'BIG_DOWN'\n",
    "            elif lastPrice > -3:\n",
    "              direction = 'BIGGER_DOWN'\n",
    "            dat['direction_' + seconds_ago_string + '_secAgo'] = direction\n",
    "\n",
    "            seconds_ago += seconds_inbetween\n",
    "            \n",
    "\n",
    "        memory_data_symbol[symbol] = dat\n",
    "\n",
    "    return memory_data_symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6HtKD9Wrmxi0"
   },
   "source": [
    "### processActionData():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flVCYZidm5aB"
   },
   "outputs": [],
   "source": [
    "def processActionData(epoch, memory_data_symbol, only_use_holding_symbols):\n",
    "    global holding_coins, memory_data, categorial_features_indices, features_list, features_dtypes, saved_df_buffer\n",
    "\n",
    "    saved = {}\n",
    "    if only_use_holding_symbols:\n",
    "        for coin, inner in holding_coins.items():\n",
    "            counting_epochs = inner['counting_epochs']\n",
    "            if counting_epochs > pred_epoch:\n",
    "                counting_epochs = pred_epoch\n",
    "            saved[coin] = getActionSampleRow(coin, memory_data_symbol, counting_epochs)\n",
    "    else:\n",
    "        for coin in avaiable_coins.keys():\n",
    "            counting_epochs = random.randint(0, pred_epoch)\n",
    "            saved[coin] = getActionSampleRow(coin, memory_data_symbol, counting_epochs)\n",
    "\n",
    "    return saved\n",
    "\n",
    "\n",
    "def getActionSampleRow(coin, memory_data_symbol, counting_epochs):\n",
    "    minimum_threshold = binary_target_minimum_increase_min\n",
    "    if counting_epochs < pred_epoch:\n",
    "        minimum_threshold = binary_target_minimum_increase_max - (counting_epochs * (binary_target_minimum_increase_max / pred_epoch))\n",
    " \n",
    "    data = {\n",
    "      'coin': coin,\n",
    "      'minimum_threshold': minimum_threshold, \n",
    "    }\n",
    "\n",
    "    i = 0\n",
    "    for symbol in avaiable_coins[coin]:\n",
    "        if i > amount_of_symbols_per_action_sample - 1:\n",
    "            break\n",
    "\n",
    "        if symbol.startswith(coin):\n",
    "            for attr, value in memory_data_symbol[symbol].items():\n",
    "                if 'Price_' in attr or 'olume_' in attr or 'tradeCount_' in attr:\n",
    "                    if value != 0:\n",
    "                        data[str(i) + attr] = value * -1\n",
    "                    else:\n",
    "                        data[str(i) + attr] = value\n",
    "                elif 'direction_' in attr:\n",
    "                    data[str(i) + attr] = changeDirection(value)\n",
    "                else:\n",
    "                    data[str(i) + attr] = value\n",
    "        else:\n",
    "            for attr, value in memory_data_symbol[symbol].items():\n",
    "                data[str(i) + attr] = value\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    for a in range (i, amount_of_symbols_per_action_sample):\n",
    "        for attr in memory_data_symbol[debug_symbol].keys():\n",
    "            data[str(a) + attr] = '0'\n",
    "\n",
    "    return data\n",
    "\n",
    "def changeDirection(value):\n",
    "    if value == 'BIGGEST_DOWN':\n",
    "        return 'BIGGEST_UP'\n",
    "    if value == 'BIGGER_DOWN':\n",
    "        return 'BIGGER_UP'\n",
    "    if value == 'BIG_DOWN':\n",
    "        return 'BIG_UP'\n",
    "    if value == 'HALF_DOWN':\n",
    "        return 'HALF_UP'\n",
    "    if value == 'DOWNER':\n",
    "        return 'UP_UP'\n",
    "    if value == 'DOWN_DOWN':\n",
    "        return 'UP_UP'\n",
    "    if value == 'DOWN':\n",
    "        return 'UP'\n",
    "    if value == 'NEUTRAL':\n",
    "        return 'DOWN'\n",
    "    if value == 'UP':\n",
    "        return 'DOWN'\n",
    "    if value == 'UP_UP':\n",
    "        return 'DOWN_DOWN'\n",
    "    if value == 'HALF_UP':\n",
    "        return 'HALF_DOWN'\n",
    "    if value == 'BIG_UP':\n",
    "        return 'BIG_DOWN'\n",
    "    if value == 'BIGGER_UP':\n",
    "        return 'BIGGER_DOWN'\n",
    "    if value == 'BIGGEST_UP':\n",
    "        return 'BIGGEST_DOWN'\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WPpdhuugYQd"
   },
   "source": [
    "### updateBinanceBalances + updateSymbolPriorityList:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXnUSgd2gUxg"
   },
   "outputs": [],
   "source": [
    "def updateBinanceBalances():\n",
    "    global holding_coins, dont_update_holding_coins, cancel_orders\n",
    "\n",
    "    if cancel_orders:\n",
    "        cancel_orders = False\n",
    "        orders = binance.get_open_orders()\n",
    "        for order in orders:\n",
    "            print('cancel_order:', binance.cancel_order(\n",
    "                symbol = order['symbol'],\n",
    "                orderId = order['orderId']))\n",
    "\n",
    "    balances = binance.get_account()['balances']\n",
    "    found_assets = []\n",
    "    for balance in balances:\n",
    "        balance_number = float(balance['free'])\n",
    "        if balance_number > 0.0001:\n",
    "            if balance['asset'] not in holding_coins.keys():\n",
    "                if 'DEFAULT' in holding_coins.keys():\n",
    "                    holding_coins[balance['asset']] = holding_coins['DEFAULT'].copy()\n",
    "                else:\n",
    "                    continue\n",
    "            if balance['asset'] == 'EUR':\n",
    "                balance_number -= real_wallet_dont_use_euro\n",
    "                if balance_number < 1:\n",
    "                    continue\n",
    "            if balance['asset'] == 'BNB':\n",
    "                balance_number -= 0.01  # 2.76eur 15.09.22\n",
    "            if balance_number < 0.0001:\n",
    "                continue\n",
    "            if balance['asset'] not in dont_update_holding_coins:\n",
    "                holding_coins[balance['asset']]['balance'] = balance_number\n",
    "            found_assets.append(balance['asset'])\n",
    "    for coin in list(holding_coins.keys()):\n",
    "        if coin not in found_assets or holding_coins[coin]['balance_eur'] < 1:\n",
    "            if coin in dont_update_holding_coins:\n",
    "                dont_update_holding_coins.remove(coin)\n",
    "                del dont_update_holding_coins_buffer[coin]\n",
    "            del holding_coins[coin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "deEBL0RsYvti"
   },
   "outputs": [],
   "source": [
    "def updateSymbolPriorityList(memory_data_symbol):\n",
    "    global avaiable_coins\n",
    "\n",
    "    symbol_changes = {}\n",
    "    for symbol, details in memory_data_symbol.items():\n",
    "        symbol_changes[symbol] = 0\n",
    "        symbol_changes[symbol] += getPositiveChange(details['bidPrice_high_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        symbol_changes[symbol] += getPositiveChange(details['askPrice_high_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        symbol_changes[symbol] += getPositiveChange(details['volume_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        symbol_changes[symbol] += getPositiveChange(details['quoteVolume_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        symbol_changes[symbol] += getPositiveChange(details['tradeCount_' + str(seconds_inbetween) + '_secAgo'])\n",
    "        symbol_changes[symbol] += getPositiveChange(details['lastPrice_' + str(seconds_inbetween) + '_secAgo'])\n",
    "    symbol_changes = list(dict(sorted(symbol_changes.items(), key=lambda item: item[1], reverse = True)).keys())\n",
    "\n",
    "    new_avaiable_coins = {}\n",
    "    for coin, symbols in avaiable_coins.items():\n",
    "        new_avaiable_coins[coin] = []\n",
    "        for symbol in symbol_changes:\n",
    "            if symbol in symbols:\n",
    "                new_avaiable_coins[coin].append(symbol)\n",
    "\n",
    "    avaiable_coins = new_avaiable_coins\n",
    "\n",
    "\n",
    "def getPositiveChange(number):\n",
    "    if number < 0:\n",
    "        return number * -1\n",
    "    else:\n",
    "        return number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFk0gn6wjwRx"
   },
   "source": [
    "### proccessPredictions():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9W3xKw0j30q"
   },
   "outputs": [],
   "source": [
    "def runModelPredictions(predictions_byModel, model_name, model, df):\n",
    "  \n",
    "  results = model.predict_proba(df)\n",
    "\n",
    "  for i in range(len(results)):\n",
    "      coin = df['coin'][i]\n",
    "      predictions_byModel[model_name][coin] = {}\n",
    "\n",
    "      sorted_array = np.argsort(results[i])\n",
    "      \n",
    "      a = -1\n",
    "      found = 0\n",
    "      for result in results[i]:\n",
    "          if found > 1:\n",
    "              break\n",
    "          a += 1\n",
    "\n",
    "          position = None\n",
    "          if a == sorted_array[-1]:\n",
    "              position = 0\n",
    "          elif a == sorted_array[-2]:\n",
    "              position = 1\n",
    "          else:\n",
    "              continue\n",
    "\n",
    "          found += 1\n",
    "          label = possible_labels[a]\n",
    "          symbol = 'NONE'\n",
    "\n",
    "          if label != 'NONE':\n",
    "              symbol = df[label + 'symbol'][i]\n",
    "              # if symbol == '0':\n",
    "              #     continue\n",
    "          \n",
    "          predictions_byModel[model_name][coin][position] = {\n",
    "              'symbol': symbol,\n",
    "              'value': result,\n",
    "          }\n",
    "\n",
    "  return predictions_byModel\n",
    "\n",
    "def proccessPredictions(epoch, saved):\n",
    "    time_now = time.time()\n",
    "    list_data = []\n",
    "    predictions_byModel = {}\n",
    "    \n",
    "    for _, sample in saved.items():\n",
    "        list_data.insert(0, list(sample.values()))\n",
    "\n",
    "    df = pd.DataFrame(list_data, columns = features_list)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        predictions_byModel[model_name] = {}\n",
    "        predictions_byModel = runModelPredictions(predictions_byModel, model_name, model, df)\n",
    "\n",
    "    pred_time = str(round(time.time() - time_now, 2))\n",
    "\n",
    "    return predictions_byModel, pred_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKOMrV86wxf6"
   },
   "source": [
    "### validatePredictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mKv-Feew7vS"
   },
   "outputs": [],
   "source": [
    "def validatePredictions(current_epoch, memory_symbols):\n",
    "    global memory_data, predictions_saved\n",
    "    \n",
    "    list_list = []\n",
    "    list_data = []\n",
    "    y_train = []\n",
    "    validated_list = {}\n",
    "    validated_list_targets = {}\n",
    "\n",
    "    for symbol, inner in memory_symbols.items():\n",
    "        old_lastPrice = inner['lastPrice'][0]\n",
    "        new_lastPrice = inner['lastPrice'][current_epoch - 1 - deleted_symbol_data]\n",
    "\n",
    "        validated_list[symbol] = (new_lastPrice - old_lastPrice) / old_lastPrice\n",
    "        \n",
    "    for coin, sample in memory_data[0].items():\n",
    "        biggest_symbol = {\n",
    "            'result': 'NONE',\n",
    "            'name': 'NONE',\n",
    "            'reg_target': sample['minimum_threshold'],\n",
    "        }\n",
    "\n",
    "        for i in range(0, amount_of_symbols_per_action_sample):\n",
    "            symbol = sample[str(i) + 'symbol']\n",
    "            if symbol is not '0':\n",
    "                reg_target = validated_list[symbol]\n",
    "                if symbol.startswith(coin):\n",
    "                    reg_target *= -1\n",
    "                if reg_target > biggest_symbol['reg_target']:\n",
    "                    biggest_symbol['result'] = str(i)\n",
    "                    biggest_symbol['name'] = symbol\n",
    "                    biggest_symbol['reg_target'] = reg_target\n",
    "\n",
    "        list_data.append(sample)\n",
    "        y_train.append(biggest_symbol['result'])\n",
    "        validated_list_targets[coin] = biggest_symbol['name']\n",
    "\n",
    "    return list_data, y_train, validated_list_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX4Yb1Cqm7km"
   },
   "outputs": [],
   "source": [
    "def validatePastPredictions(validated_list_targets):\n",
    "    global loss_string\n",
    "\n",
    "    loss_string = ''\n",
    "    validated_binary_result = {}\n",
    "\n",
    "    for model_name, inner in predictions_saved[0].items():\n",
    "        validated_binary_result[model_name] = {}\n",
    "\n",
    "        for coin, detail in inner.items():\n",
    "            pred_0 = detail[0]\n",
    "            pred_1 = detail[1]\n",
    "            target = validated_list_targets[coin]\n",
    "\n",
    "            if pred_0['symbol'] != target:\n",
    "                validated_binary_result[model_name][coin] = pred_0['value']\n",
    "            elif pred_1['symbol'] != target:\n",
    "                validated_binary_result[model_name][coin] = pred_1['value']\n",
    "\n",
    "        # Calculate Loss:\n",
    "        losses = 0\n",
    "        for coin, value in validated_binary_result[model_name].items():\n",
    "            losses += value\n",
    "        \n",
    "        losses /= len(validated_binary_result[model_name].keys())\n",
    "\n",
    "        losses_agregated[model_name].append(losses)\n",
    "\n",
    "        if len(losses_agregated[model_name]) > aggregate_loss_history_epochs:\n",
    "            del losses_agregated[model_name][0]\n",
    "        \n",
    "        median = round(sum(losses_agregated[model_name]) / len(losses_agregated[model_name]), 5)\n",
    "\n",
    "        loss_string += str(median) + '  '\n",
    "        #\n",
    "\n",
    "\n",
    "losses_agregated = {}\n",
    "for model_name in models.keys():\n",
    "    losses_agregated[model_name] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEkAlPZfk7cZ"
   },
   "source": [
    "### convert_wallet_to_euro():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGuJiuABk8Uh"
   },
   "outputs": [],
   "source": [
    "def convert_wallet_to_euro(holding_coins, memory_symbols, epoch):\n",
    "    global dont_update_holding_coins, dont_update_holding_coins_buffer\n",
    "\n",
    "    euro = 0\n",
    "\n",
    "    for coin, data in holding_coins.items():\n",
    "        found = False\n",
    "        if coin == 'EUR':\n",
    "            euro += data['balance']\n",
    "            holding_coins[coin]['balance_eur'] = data['balance']\n",
    "            found = True\n",
    "            continue\n",
    "\n",
    "        if coin == 'DEFAULT':\n",
    "            continue\n",
    "        \n",
    "        for symbol, inner in memory_symbols.items():\n",
    "            if symbol in avaiable_coins[coin] and 'EUR' in symbol:\n",
    "                lastPrice = inner['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "                balance = 0\n",
    "                if symbol.endswith(coin):\n",
    "                    balance = data['balance'] / lastPrice\n",
    "                else:\n",
    "                    balance = data['balance'] * lastPrice\n",
    "                    \n",
    "                euro += balance\n",
    "                holding_coins[coin]['balance_eur'] = balance\n",
    "                found = True\n",
    "                break\n",
    "        else:\n",
    "            for symbol in avaiable_coins[coin]:\n",
    "                lastPrice = memory_symbols[symbol]['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "                similars = [\"BTC\", \"ETH\", \"BNB\", \"USDT\", \"BUSD\"]\n",
    "                if any(x in symbol for x in similars):\n",
    "                    new_currency = 0\n",
    "                    if symbol.endswith(coin):\n",
    "                        new_currency = data['balance'] / lastPrice\n",
    "                    else:\n",
    "                        new_currency = data['balance'] * lastPrice\n",
    "                    new_coin = symbol.replace(coin, '')\n",
    "                    \n",
    "                    # print(symbol, coin, new_coin) \n",
    "                    for symbol2 in memory_symbols.keys():\n",
    "                        if symbol2 in avaiable_coins[new_coin] and 'EUR' in symbol2:\n",
    "                            lastPrice = memory_symbols[symbol2]['lastPrice'][epoch - 1 - deleted_symbol_data]\n",
    "                            balance = 0\n",
    "                            if symbol2.endswith(coin):\n",
    "                                balance = new_currency / lastPrice\n",
    "                            else:\n",
    "                                balance = new_currency * lastPrice\n",
    "                                \n",
    "                            euro += balance\n",
    "                            holding_coins[coin]['balance_eur'] = balance\n",
    "                            found = True\n",
    "                            break\n",
    "                    else:\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "        if found == False:            \n",
    "          print('ALEED!!: convert_wallet_to_euro() | Couldnt resolve coin for trading euro:', coin)\n",
    "\n",
    "    return str(round(euro, 2)) + ' €'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiBXDbMQlU49"
   },
   "source": [
    "### processTrading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtAGU3cjlZLG"
   },
   "outputs": [],
   "source": [
    "def processTrading(predictions_byModel, current_epoch, memory_symbols):\n",
    "    global holding_coins, dont_update_holding_coins, dont_update_holding_coins_buffer, cancel_orders, debug_symbol\n",
    "\n",
    "    print('_TRADING:')\n",
    "    for model_name, inner in predictions_byModel.items():\n",
    "        for coin, details in inner.items():\n",
    "            if coin in holding_coins.keys():\n",
    "                print(coin, details[0]['symbol'], str(round(details[0]['value'] * 100, 2)) + '%')\n",
    "                print(coin, details[1]['symbol'], str(round(details[1]['value'] * 100, 2)) + '%')\n",
    "    print()\n",
    "\n",
    "\n",
    "    for coin in list(holding_coins.keys()):\n",
    "        symbol = predictions_byModel[model_name_for_trading][coin][0]['symbol']\n",
    "        if symbol == 'NONE':\n",
    "            if holding_coins[coin]['counting_epochs'] > 99:\n",
    "                symbol = predictions_byModel[model_name_for_trading][coin][1]['symbol']\n",
    "                print('Will trade ' + coin + ' now because counting_epochs > 99.')\n",
    "            else:\n",
    "                continue\n",
    "        elif (predictions_byModel[model_name_for_trading][coin][1]['symbol'] == \"NONE\" \\\n",
    "              and predictions_byModel[model_name_for_trading][coin][0]['value'] < minimum_prediction_prob_trade_NextIsNone) or \\\n",
    "              predictions_byModel[model_name_for_trading][coin][0]['value'] < minimum_prediction_prob_trade_NextIsNotNone:\n",
    "            continue\n",
    "        if symbol == '0':\n",
    "            print(predictions_byModel[model_name_for_trading][coin])\n",
    "            continue\n",
    "\n",
    "        buying_coin = symbol.replace(coin, '')\n",
    "\n",
    "        buying_quantity = None\n",
    "        price = None\n",
    "\n",
    "        if symbol.startswith(coin):\n",
    "            bidPrice_low = memory_symbols[symbol]['bidPrice_low'][current_epoch - 1 - deleted_symbol_data]\n",
    "            price = bidPrice_low\n",
    "            buying_quantity = holding_coins[coin]['balance'] * price\n",
    "        else:\n",
    "            askPrice_high = memory_symbols[symbol]['askPrice_high'][current_epoch - 1 - deleted_symbol_data]\n",
    "            price = askPrice_high\n",
    "            buying_quantity = holding_coins[coin]['balance'] / price\n",
    "\n",
    "        price = round(price, binance_symbols[symbol]['tickSize'])\n",
    "        buying_quantity = round(buying_quantity, 7)\n",
    "\n",
    "        trade = '--> Attempt Trading ' + str(holding_coins[coin]['balance']) + ' ' + coin + ' to ' + str(buying_quantity) + ' ' + buying_coin + \\\n",
    "                ' for ' + str(price) + '        [' + time.strftime(\"%H:%M:%S\") + ']'\n",
    "        print(trade)\n",
    "\n",
    "        #########################################################\n",
    "        #########################################################\n",
    "        #########################################################\n",
    "        \n",
    "        if do_real_money_trade:\n",
    "              \n",
    "            side = SIDE_BUY\n",
    "            order_quantity = buying_quantity\n",
    "            order_notional = holding_coins[coin]['balance']\n",
    "            if symbol.endswith(buying_coin):\n",
    "                side = SIDE_SELL\n",
    "                order_quantity = holding_coins[coin]['balance']\n",
    "                order_notional = buying_quantity\n",
    "\n",
    "            order_quantity = round(order_quantity, binance_symbols[symbol]['stepSizeInteger'])\n",
    "\n",
    "            if binance_symbols[symbol]['minNotional'] >= order_notional:\n",
    "                print('minNotional err', coin, binance_symbols[symbol]['minNotional'], order_quantity)\n",
    "                del holding_coins[coin]\n",
    "                if coin in dont_update_holding_coins:\n",
    "                    dont_update_holding_coins.remove(coin)\n",
    "                    del dont_update_holding_coins_buffer[coin]\n",
    "                print(coin + ' deleted from trading wallet.')\n",
    "                continue\n",
    "\n",
    "            limit_price = format(price, '.' + str(binance_symbols[symbol]['tickSize']) + 'f')\n",
    "            order_quantity = format(order_quantity, '.' + str(binance_symbols[symbol]['stepSizeInteger']) + 'f')\n",
    "\n",
    "            print(symbol, side, order_quantity, limit_price)\n",
    "        \n",
    "            success = False\n",
    "            try:\n",
    "                cancel_orders = True\n",
    "                order = binance.create_order(\n",
    "                    symbol=symbol,\n",
    "                    side=side,\n",
    "                    type=ORDER_TYPE_LIMIT,\n",
    "                    timeInForce=TIME_IN_FORCE_GTC,\n",
    "                    quantity=order_quantity,\n",
    "                    price=limit_price)\n",
    "                print(order)\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print('create_order err:', e.message)\n",
    "                if 'insufficient balance' in e.message or 'MIN_NOTIONAL' in e.message:\n",
    "                    if coin not in dont_update_holding_coins:\n",
    "                        if coin not in dont_update_holding_coins_buffer.keys():\n",
    "                            dont_update_holding_coins_buffer[coin] = 1\n",
    "                        else:\n",
    "                            dont_update_holding_coins_buffer[coin] += 1\n",
    "                            if dont_update_holding_coins_buffer[coin] > 2:\n",
    "                                dont_update_holding_coins.append(coin)\n",
    "                    else:\n",
    "                        holding_coins[coin]['balance'] -= binance_symbols[symbol]['stepSize']\n",
    "            print()\n",
    "            ###\n",
    "            ########################################################\n",
    "\n",
    "            if success:\n",
    "                balance = buying_quantity\n",
    "                if buying_coin in holding_coins.keys():\n",
    "                    balance += holding_coins[buying_coin]['balance']\n",
    "\n",
    "                # Set the new acquired coin:\n",
    "                holding_coins[buying_coin] = {\n",
    "                    'balance': balance,\n",
    "                    'balance_eur': 1, \n",
    "                    'price': limit_price,\n",
    "                    'counting_epochs': 0,\n",
    "                    'symbol': symbol, \n",
    "                    'date': time.strftime('%H:%M:%S')\n",
    "                }\n",
    "\n",
    "                debug_symbol = symbol\n",
    "\n",
    "                if coin in dont_update_holding_coins:\n",
    "                    dont_update_holding_coins.remove(coin)\n",
    "                    del dont_update_holding_coins_buffer[coin]\n",
    "\n",
    "    for coin in holding_coins.keys():\n",
    "        holding_coins[coin]['counting_epochs'] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2TD04LYP0V2"
   },
   "source": [
    "### trainModels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_warmup(training_list, y_train):\n",
    "    time_now = time.time()\n",
    "    model_name, model = create_model('CatBoostAction')\n",
    "    df = pd.DataFrame(training_list)\n",
    "    model.fit(df, \n",
    "                y_train, \n",
    "                cat_features = categorial_features_indices, \n",
    "                verbose = False)\n",
    "    print('Did warmup:', time.time() - time_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3o7BpD-ZP1ce"
   },
   "outputs": [],
   "source": [
    "def trainModels(epoch, training_list, y_train):\n",
    "    global print_trained_string, saved_df_buffer, saved_y_buffer\n",
    "\n",
    "    time_now = time.time()\n",
    "\n",
    "    df = pd.DataFrame(training_list)\n",
    "\n",
    "    if do_gather_dataset:\n",
    "        model_df_buffer_lock.acquire()\n",
    "        saved_df_buffer = pd.concat([saved_df_buffer, df])\n",
    "        saved_y_buffer += y_train\n",
    "        model_df_buffer_lock.release()\n",
    "\n",
    "    time_df = time.time() - time_now\n",
    "\n",
    "    model_training_lock.acquire()\n",
    "    time_now = time.time()\n",
    "\n",
    "    if do_training:\n",
    "        for model_name, model in models.items():\n",
    "            model.fit(df, \n",
    "                y_train, \n",
    "                cat_features = categorial_features_indices, \n",
    "                verbose = False)\n",
    "\n",
    "    time_train = time.time() - time_now\n",
    "\n",
    "    model_training_lock.release()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        save() # Save models\n",
    "\n",
    "    print_trained_string = '[Trained ' + str(len(y_train)) + ' [' + str(round(time_df, 2)) + ' + ' + str(round(time_train, 2)) + ' s]]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnK91M6QN-0Z"
   },
   "source": [
    "### save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kvDVMCMZBof"
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    global saved_df_buffer, saved_y_buffer\n",
    "    time_now = time.time()\n",
    "\n",
    "    if do_training:\n",
    "        if use_models == \"NN\":\n",
    "            for model_name, model in models.items():\n",
    "                model.save(root_dir + '/catboost/' + model_name)\n",
    "        else:\n",
    "            for model_name, model in models.items():\n",
    "                joblib.dump(model, root_dir + '/catboost/' + model_name)\n",
    "\n",
    "    if do_gather_dataset:\n",
    "        if model_df_buffer_lock.locked():\n",
    "            model_df_buffer_lock.acquire() #\n",
    "            saved_df_buffer = pd.DataFrame()\n",
    "            saved_y_buffer = []\n",
    "            model_df_buffer_lock.release() #\n",
    "            print('Aborted save df.', round(time.time() - time_now, 2), 's')\n",
    "        else:\n",
    "            time_string = str(round(time.time()))\n",
    "            model_df_buffer_lock.acquire() #\n",
    "            df_import = saved_df_buffer\n",
    "            saved_df_buffer = pd.DataFrame()\n",
    "            y_import = saved_y_buffer\n",
    "            saved_y_buffer = []\n",
    "            model_df_buffer_lock.release() #\n",
    "            df_import.to_csv(root_dir + '/' + datasets_dir + '/' + time_string + '.csv', index = False)\n",
    "            joblib.dump(y_import, root_dir + '/' + datasets_dir + '/' + time_string + '.csv.y')\n",
    "            print('Saved df to', datasets_dir, '. ', round(time.time() - time_now, 2), 's', '', df_import.shape[0], len(y_import))\n",
    "\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cy1D3bhURrj7"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFIUOLfp79nD",
    "outputId": "a5dcc5f5-10a6-4135-f415-f962b432341d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "init()\n",
    "schedule = sched.scheduler(time.time, time.sleep)\n",
    "while(1):\n",
    "    runner()\n",
    "    print('Next episode')\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# Look into Time Series Split (skforecast)\n",
    "# Add volatility indicator per coin/symbol \n",
    "#"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "f1rbiuNnTOAt",
    "jOlkyfhOWYPz",
    "xGyza51MbQ8i",
    "F8t4j-VCVPv_",
    "TZMtPNjERlzE",
    "sjsTJIZxAlzA",
    "rwAVJm55CSR5",
    "f1uHH3AlgtLF",
    "Zhk559ZXlIPx",
    "6HtKD9Wrmxi0",
    "9WPpdhuugYQd",
    "dFk0gn6wjwRx",
    "wKOMrV86wxf6",
    "lEkAlPZfk7cZ",
    "eiBXDbMQlU49",
    "C2TD04LYP0V2",
    "OnK91M6QN-0Z"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m97"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff03dcfaa4ea4c7dbcc7a6acd2b5152b484988a1b13020911f06ea29377d1915"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
